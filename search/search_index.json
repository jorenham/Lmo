{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#lmo-trimmed-l-moments-and-l-comoments","title":"Lmo - Trimmed L-moments and L-comoments","text":"<pre><code>Is your tail too heavy? \nCan't find a moment? \nAre the swans black? \nThe distribution pathological?\n\n... then look no further: Lmo's got you covered!\n\nUniform or multi-dimensional, Lmo can summarize it all with one quick glance!\n</code></pre> <p>Unlike the legacy moments, L-moments uniquely describe a  probability distribution. The \"L\" stands for Linear; it is a linear combination of order statistics. So Lmo is as fast as sorting your samples (in terms of time-complexity).</p> <p>Even if your data is pathological like Cauchy,  and the L-moments are not defined, the trimmed L-moments (TL-moments) can be  used instead:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; rng = np.random.default_rng(1980)\n&gt;&gt;&gt; x = rng.standard_cauchy(96)  # pickle me, Lmo\n&gt;&gt;&gt; x.mean(), x.std()  # don't try this at home\n(-1.7113440959133905, 19.573507308373326)\n&gt;&gt;&gt; lmo.l_loc(x, trim=(1, 1)), lmo.l_scale(x, (1, 1)) \n(-0.17937038148581977, 0.6828766469913776)\n</code></pre> <p>For reference; the theoretical TL-location and TL-scale of the standard  Cauchy distribution are \\(\\lambda^{(1, 1)}_{1} = 0\\) and  \\(\\lambda^{(1, 1)}_2 \\approx 0.7\\)  (Elamir &amp; Seheult, 2003).</p>"},{"location":"#key-features","title":"Key Features:","text":"<ul> <li>Calculates trimmed L-moments and L-comoments, from data and distributions.</li> <li>Exact non-parametric variance structure of the sample estimates.</li> <li>Coming soon: ~Robust distribution fitting; the method of L-moments~.</li> <li>Complete docs, including overly    complex \\(\\TeX\\) spaghetti equations.</li> <li>Clean Pythonic syntax for ease of use.</li> <li>Vectorized functions for very fast fitting.</li> <li>Fully typed, tested, and tickled.</li> </ul> <p>See the documentation for usage examples and code reference.</p>"},{"location":"#installation","title":"Installation","text":"<p>Lmo is on PyPI, so you can do something like:</p> <pre><code>pip install lmo\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<ul> <li><code>python &gt;= 3.10</code></li> <li><code>numpy &gt;= 1.22</code></li> <li><code>scipy &gt;= 1.9</code></li> </ul>"},{"location":"#foundational-literature","title":"Foundational Literature","text":"<ul> <li>J.R.M. Hosking (1990) \u2013 L-moments: Analysis and Estimation of    Distributions using Linear Combinations of Order Statistics   </li> <li>E.A.H. Elamir &amp; A.H. Seheult (2003) \u2013 Trimmed L-moments   </li> <li>E.A.H. Elamir &amp; A.H. Seheult (2004) \u2013 Exact variance structure of    sample L-moments</li> <li>J.R.M. Hosking (2007) \u2013 Some theory and practical uses of trimmed    L-moments</li> <li>R. Ser\ufb02ing &amp; P. Xiao (2007) \u2013 A contribution to multivariate    L-moments: L-comoment matrices</li> <li>W.H. Asquith (2011) \u2013 Univariate Distributional Analysis with    L-moment Statistics</li> <li>C. Dutang (2017) \u2013 Theoretical L-moments and TL-moments Using   Combinatorial Identities and Finite Operators   </li> </ul>"},{"location":"contributing/","title":"Contributing to Lmo","text":"<p>Any contributions to Lmo are appreciated!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as issues.</p> <p>When reporting a bug, make sure to include the versions of <code>lmo</code>, <code>python</code>,  <code>numpy</code> and <code>scipy</code> you are using, and provide a reproducible example of  the bug.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>Ensure you have poetry  installed, then clone your fork, and install with</p> <pre><code>poetry install --sync\n</code></pre> <p>It can help to use Lmo's lowest-supported Python version, so that you don't accidentally use those bleeding-edge Python features that you shouldn't,  <code>poetry env use python3.x</code></p> <p>Now you can go ahead and do your thing.  And don't forget the type annotations, add tests, and to lint it all. </p> <p>If you're a 10x developer that doesn't wait on CI workflows, you can use the  following 1337 shellscript (keep in mind that the CI runs this on all supported Python versions):</p> <pre><code>poetry run ruff check lmo\npoetry run pyright\npoetry run py.test\n</code></pre> <p>If your change involves documentation updates, you can conjure up a live  preview:</p> <pre><code>poetry run mkdocs serve\n</code></pre> <p>But don't worry about building the docs, or bumping the version; Lmo's personal assistant will do that on release.</p>"},{"location":"reference/","title":"Lmo reference","text":""},{"location":"reference/#high-level-api","title":"High-level API","text":""},{"location":"reference/#sample-l-moments","title":"Sample L-moments","text":""},{"location":"reference/#lmo.l_moment","title":"<code>lmo.l_moment(a, r, /, trim=0, 0, axis=None, dtype=np.float_, *, fweights=None, aweights=None, sort='stable', cache=False)</code>","text":"<p>Estimates the generalized trimmed L-moment \\(\\lambda^{(t_1, t_2)}_r\\) from the samples along the specified axis. By default, this will be the regular L-moment, \\(\\lambda_r = \\lambda^{(0, 0)}_r\\).</p> PARAMETER  DESCRIPTION <code>a</code> <p>Array containing numbers whose L-moments is desired. If <code>a</code> is not an array, a conversion is attempted.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>The L-moment order(s), non-negative integer or array.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((t_1, t_2)\\), non-negative integers that are bound by \\(t_1 + t_2 &lt; n - r\\).</p> <p>Some special cases include:</p> <ul> <li>\\((0, 0)\\): The original L-moment, introduced by Hosking (1990).     Useful for fitting the e.g. log-normal and generalized extreme     value (GEV) distributions.</li> <li>\\((0, m)\\): LL-moment (Linear combination of Lowest     order statistics), instroduced by Bayazit &amp; Onoz (2002).     Assigns more weight to smaller observations.</li> <li>\\((s, 0)\\): LH-moment (Linear combination of Higher     order statistics), by Wang (1997).     Assigns more weight to larger observations.</li> <li>\\((t, t)\\): TL-moment (Trimmed L-moment) \\(\\lambda_r^t\\),     with symmetric trimming. First introduced by     Elamir &amp; Seheult (2003).     Generally more robust than L-moments.     Useful for fitting heavy-tailed distributions, such as the     Cauchy distribution.</li> </ul> <p> TYPE: <code>tuple[int, int]</code> DEFAULT: <code>0, 0</code> </p> <code>axis</code> <p>Axis along wich to calculate the moments. If <code>None</code> (default), all samples in the array will be used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Floating type to use in computing the L-moments. Default is <code>numpy.float64</code>.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>fweights</code> <p>1-D array of integer frequency weights; the number of times each observation vector should be repeated.</p> <p> TYPE: <code>IntVector | None</code> DEFAULT: <code>None</code> </p> <code>aweights</code> <p>An array of weights associated with the values in <code>a</code>. Each value in <code>a</code> contributes to the average according to its associated weight. The weights array can either be 1-D (in which case its length must be the size of a along the given axis) or of the same shape as <code>a</code>. If <code>aweights=None</code> (default), then all data in <code>a</code> are assumed to have a weight equal to one.</p> <p>All <code>aweights</code> must be <code>&gt;=0</code>, and the sum must be nonzero.</p> <p>The algorithm is similar to that for weighted quantiles.</p> <p> TYPE: <code>npt.ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | stable | heap</code> DEFAULT: <code>'stable'</code> </p> <code>cache</code> <p>Set to <code>True</code> to speed up future L-moment calculations that have the same number of observations in <code>a</code>, equal <code>trim</code>, and equal or smaller <code>r</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>l</code> <p>The L-moment(s) of the input This is a scalar iff a is 1-d and r is a scalar. Otherwise, this is an array with <code>np.ndim(r) + np.ndim(a) - 1</code> dimensions and shape like <code>(*np.shape(r), *(d for d in np.shape(a) if d != axis))</code>.</p> <p> TYPE: <code>T | npt.NDArray[T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_normal(20)\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2, 3, 4])\narray([0.00106117, 0.65354263, 0.01436636, 0.04280225])\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2, 3, 4], trim=(1, 1))\narray([-0.0133052 ,  0.36644423, -0.00823471, -0.01034343])\n</code></pre> See Also <ul> <li>L-moment - Wikipedia</li> <li><code>scipy.stats.moment</code></li> </ul> References <ul> <li>J.R.M. Hosking (1990)</li> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"reference/#lmo.l_moment_cov","title":"<code>lmo.l_moment_cov(a, r_max, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Non-parmateric auto-covariance matrix of the generalized trimmed L-moment point estimates with orders <code>r = 1, ..., r_max</code>.</p> RETURNS DESCRIPTION <code>S_l</code> <p>Variance-covariance matrix/tensor of shape <code>(r_max, r_max, ...)</code></p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <p>Fitting of the cauchy distribution with TL-moments. The location is equal to the TL-location, and scale should be \\(0.698\\) times the TL(1)-scale, see Elamir &amp; Seheult (2003).</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(1337)\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1, 1))\narray([0.08142405, 0.68884917])\n</code></pre> <p>The L-moment estimates seem to make sense. Let's check their standard errors, by taking the square root of the variances (the diagnoal of the covariance matrix):</p> <pre><code>&gt;&gt;&gt; lmo.l_moment_cov(x, 2, trim=(1, 1))\narray([[ 4.89407076e-03, -4.26419310e-05],\n       [-4.26419310e-05,  1.30898414e-03]])\n&gt;&gt;&gt; np.sqrt(_.diagonal())\narray([0.06995764, 0.03617989])\n</code></pre> See Also <ul> <li><code>lmo.l_moment</code></li> <li>Covariance matrix - Wikipedia</li> </ul> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>E. Elamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul>"},{"location":"reference/#lmo.l_ratio","title":"<code>lmo.l_ratio(a, r, s, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Estimates the generalized L-moment ratio:</p> \\[ \\tau^{(t_1, t_2)}_{rs} = \\frac{     \\lambda^{(t_1, t_2)}_r }{     \\lambda^{(t_1, t_2)}_s } \\] <p>Equivalent to <code>lmo.l_moment(a, r, *, **) / lmo.l_moment(a, s, *, **)</code>.</p> Notes <p>The L-moment with <code>r=0</code> is <code>1</code>, so the <code>l_ratio(a, r, 0, *, **)</code> is equivalent to <code>l_moment(a, r, *, **)</code></p> <p>Examples:</p> <p>Estimate the L-location, L-scale, L-skewness and L-kurtosis simultaneously:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).lognormal(size=99)\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2])\narray([1.53196368, 0.77549561, 0.4463163 , 0.29752178])\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(0, 1))\narray([0.75646807, 0.32203446, 0.23887609, 0.07917904])\n</code></pre> See Also <ul> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"reference/#lmo.l_ratio_se","title":"<code>lmo.l_ratio_se(a, r, s, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Non-parametric estimates of the Standard Error (SE) in the L-ratio estimates from <code>lmo.l_ratio</code>.</p> <p>Examples:</p> <p>Estimate the values and errors of the TL-loc, scale, skew and kurtosis for Cauchy-distributed samples. The theoretical values are <code>[0.0, 0.698, 0.0, 0.343]</code> (Elamir &amp; Seheult, 2003), respectively.</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(42)\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(1, 1))\narray([-0.25830513,  0.61738638, -0.03069701,  0.25550176])\n&gt;&gt;&gt; lmo.l_ratio_se(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(1, 1))\narray([0.32857302, 0.12896501, 0.13835403, 0.07188138])\n</code></pre> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>lmo.l_moment_cov</code></li> <li>Propagation of uncertainty</li> </ul> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>E. Elamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul>"},{"location":"reference/#lmo.l_loc","title":"<code>lmo.l_loc(a, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>L-location (or L-loc): unbiased estimator of the first L-moment, \\(\\lambda^{(t_1, t_2)}_1\\).</p> <p>Alias for <code>lmo.l_moment(a, 1, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_cauchy(99)\n&gt;&gt;&gt; x.mean()\n-7.56485034...\n&gt;&gt;&gt; lmo.l_loc(x)\n-7.56485034...\n&gt;&gt;&gt; lmo.l_loc(x, trim=(1, 1))\n-0.15924180...\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), the L-location is equivalent to the arithmetic mean.</p> See Also <ul> <li><code>lmo.l_moment</code></li> <li><code>numpy.average</code></li> </ul>"},{"location":"reference/#lmo.l_scale","title":"<code>lmo.l_scale(a, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>L-scale: unbiased estimator of the second L-moment, \\(\\lambda^{(t_1, t_2)}_2\\)</p> <p>Alias for <code>lmo.l_moment(a, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_cauchy(99)\n&gt;&gt;&gt; x.std()\n72.87715244...\n&gt;&gt;&gt; lmo.l_scale(x)\n9.501123995...\n&gt;&gt;&gt; lmo.l_scale(x, trim=(1, 1))\n0.658993279...\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), the L-scale is equivalent to half the Gini mean difference (GMD).</p> See Also <ul> <li><code>lmo.l_moment</code></li> <li><code>numpy.std</code></li> </ul>"},{"location":"reference/#lmo.l_variation","title":"<code>lmo.l_variation(a, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>The coefficient of L-variation (or L-CV) unbiased sample estimator:</p> \\[ \\tau^{(t_1, t_2)} = \\frac{     \\lambda^{(t_1, t_2)}_2 }{     \\lambda^{(t_1, t_2)}_1 } \\] <p>Alias for <code>lmo.l_ratio(a, 2, 1, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).pareto(4.2, 99)\n&gt;&gt;&gt; x.std() / x.mean()\n1.32161112...\n&gt;&gt;&gt; lmo.l_variation(x)\n0.59073639...\n&gt;&gt;&gt; lmo.l_variation(x, trim=(0, 1))\n0.55395044...\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), this is equivalent to the Gini coefficient, and lies within the interval \\((0, 1)\\).</p> See Also <ul> <li>Gini coefficient - Wikipedia</li> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.variation.l_ratio</code></li> </ul>"},{"location":"reference/#lmo.l_skew","title":"<code>lmo.l_skew(a, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Unbiased sample estimator of the coefficient of L-skewness, or L-skew for short:</p> \\[ \\tau^{(t_1, t_2)}_3     = \\frac{         \\lambda^{(t_1, t_2)}_3     }{         \\lambda^{(t_1, t_2)}_2     } \\] <p>Alias for <code>lmo.l_ratio(a, 3, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_exponential(99)\n&gt;&gt;&gt; lmo.l_skew(x)\n0.38524343...\n&gt;&gt;&gt; lmo.l_skew(x, trim=(0, 1))\n0.27116139...\n</code></pre> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.skew</code></li> </ul>"},{"location":"reference/#lmo.l_kurtosis","title":"<code>lmo.l_kurtosis(a, /, trim=0, 0, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>L-kurtosis coefficient; the 4th sample L-moment ratio.</p> \\[ \\tau^{(t_1, t_2)}_4     = \\frac{         \\lambda^{(t_1, t_2)}_4     }{         \\lambda^{(t_1, t_2)}_2     } \\] <p>Alias for <code>lmo.l_ratio(a, 4, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_t(2, 99)\n&gt;&gt;&gt; lmo.l_kurtosis(x)\n0.28912787...\n&gt;&gt;&gt; lmo.l_kurtosis(x, trim=(1, 1))\n0.19928182...\n</code></pre> Notes <p>The L-kurtosis \\(\\tau_4\\) lies within the interval \\([-\\frac{1}{4}, 1)\\), and by the L-skewness \\(\\tau_3\\) as \\(5 \\tau_3^2 - 1 \\le 4 \\tau_4\\).</p> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.kurtosis</code></li> </ul>"},{"location":"reference/#sample-l-comoments","title":"Sample L-comoments","text":""},{"location":"reference/#lmo.l_comoment","title":"<code>lmo.l_comoment(a, r, /, trim=0, 0, rowvar=True, dtype=np.float_, *, sort='stable', cache=False)</code>","text":"<p>Multivariate extension of <code>lmo.l_moment</code>. Estimates the L-comoment matrix:</p> \\[ \\Lambda_{r}^{(t_1, t_2)} =     \\left[         \\lambda_{r [ij]}^{(t_1, t_2)}     \\right]_{m \\times m} \\] <p>Whereas the L-moments are calculated using the order statistics of the observations, i.e. by sorting, the L-comoment sorts \\(x_i\\) using the order of \\(x_j\\). This means that in general, \\(\\lambda_{r [ij]}^{(t_1, t_2)} \\neq \\lambda_{r [ji]}^{(t_1, t_2)}\\), i.e. \\(\\Lambda_{r}^{(t_1, t_2)}\\) is not symmetric.</p> <p>The \\(r\\)-th L-comoment \\(\\lambda_{r [ij]}^{(t_1, t_2)}\\) reduces to the L-moment if \\(i=j\\), and can therefore be seen as a generalization of the (univariate) L-moments. Similar to how the diagonal of a covariance matrix contains the variances, the diagonal of the L-comoment matrix contains the L-moments.</p> <p>Based on the proposed definition by Serfling &amp; Xiao (2007) for L-comoments. Extended to allow for generalized trimming.</p> PARAMETER  DESCRIPTION <code>a</code> <p>1-D or 2-D array-like containing <code>m</code> variables and <code>n</code> observations. Each row of <code>a</code> represents a variable, and each column a single observation of all those variables. Also see <code>rowvar</code> below. If <code>a</code> is not an array, a conversion is attempted.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>The L-moment order(s), non-negative integer or array.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((t_1, t_2)\\), non-negative integers that are bound by \\(t_1 + t_2 &lt; n - r\\).</p> <p>Some special cases include:</p> <ul> <li>\\((0, 0)\\): The original L-moment, introduced by Hosking (1990).     Useful for fitting the e.g. log-normal and generalized extreme     value (GEV) distributions.</li> <li>\\((0, m)\\): LL-moment (Linear combination of Lowest     order statistics), instroduced by Bayazit &amp; Onoz (2002).     Assigns more weight to smaller observations.</li> <li>\\((s, 0)\\): LH-moment (Linear combination of Higher     order statistics), by Wang (1997).     Assigns more weight to larger observations.</li> <li>\\((t, t)\\): TL-moment (Trimmed L-moment) \\(\\lambda_r^t\\),     with symmetric trimming. First introduced by     Elamir &amp; Seheult (2003).     Generally more robust than L-moments.     Useful for fitting heavy-tailed distributions, such as the     Cauchy distribution.</li> </ul> <p> TYPE: <code>tuple[int, int]</code> DEFAULT: <code>0, 0</code> </p> <code>rowvar</code> <p>If <code>rowvar</code> is True (default), then each row (axis 0) represents a variable, with observations in the columns (axis 1). Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>dtype</code> <p>Floating type to use in computing the L-moments. Default is <code>numpy.float64</code>.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | stable | heap</code> DEFAULT: <code>'stable'</code> </p> <code>cache</code> <p>Set to <code>True</code> to speed up future L-moment calculations that have the same number of observations in <code>a</code>, equal <code>trim</code>, and equal or smaller <code>r</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>L</code> <p>Array of shape <code>(*r.shape, m, m)</code> with r-th L-comoments.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <p>Estimation of the second L-comoment (the L-coscale) from biviariate normal samples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_comoment(x, 2)\narray([[ 1.2766793 , -0.83299947],\n       [-0.71547941,  1.05990727]])\n</code></pre> <p>The diagonal contains the univariate L-moments:</p> <pre><code>&gt;&gt;&gt; lmo.l_moment(x, 2, axis=-1)\narray([1.2766793 , 1.05990727])\n</code></pre> References <ul> <li>R. Serfling &amp; P. Xiao (2007) - A Contribution to Multivariate     L-Moments: L-Comoment Matrices</li> </ul>"},{"location":"reference/#lmo.l_coratio","title":"<code>lmo.l_coratio(a, r, s, /, trim=0, 0, rowvar=True, dtype=np.float_, **kwargs)</code>","text":"<p>Estimate the generalized matrix of L-comoment ratio's:</p> \\[ \\tilde \\Lambda_{rs}^{(t_1, t_2)} =     \\left[         \\left. \\lambda_{r [ij]}^{(t_1, t_2)} \\right/         \\lambda_{s [jj]}^{(t_1, t_2)}     \\right]_{m \\times m} \\] See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"reference/#lmo.l_coloc","title":"<code>lmo.l_coloc(a, /, trim=0, 0, rowvar=True, dtype=np.float_, **kwargs)</code>","text":"<p>L-colocation matrix of 1st L-comoment estimates, \\(\\Lambda^{(t_1, t_2)}_1\\).</p> <p>Alias for <code>lmo.l_comoment(a, 1, *, **)</code>.</p> Notes <p>If <code>trim = (0, 0)</code> (default), the L-colocation for \\([ij]\\) is the L-location \\(\\lambda_1\\) of \\(x_i\\), independent of \\(x_j\\).</p> <p>Examples:</p> <p>Without trimming, the L-colocation only provides marginal information:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_loc(x, axis=-1)\narray([-0.02678225,  0.03008309])\n&gt;&gt;&gt; lmo.l_coloc(x)\narray([[-0.02678225, -0.02678225],\n       [ 0.03008309,  0.03008309]])\n</code></pre> <p>But the trimmed L-locations are a different story...</p> <pre><code>&gt;&gt;&gt; lmo.l_loc(x, trim=(1, 1), axis=-1)\narray([-0.10488868, -0.00625729])\n&gt;&gt;&gt; lmo.l_coloc(x, trim=(1, 1))\narray([[-0.10488868, -0.03797989],\n       [ 0.03325074, -0.00625729]])\n</code></pre> <p>What this tells us, is somehwat of a mystery: trimmed L-comoments have been only been briefly mentioned once or twice in the literature.</p> See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_loc</code></li> <li><code>numpy.mean</code></li> </ul>"},{"location":"reference/#lmo.l_coscale","title":"<code>lmo.l_coscale(a, /, trim=0, 0, rowvar=True, dtype=np.float_, **kwargs)</code>","text":"<p>L-coscale matrix of 2nd L-comoment estimates, \\(\\Lambda^{(t_1, t_2)}_2\\).</p> <p>Alias for <code>lmo.l_comoment(a, 2, *, **)</code>.</p> <p>Analogous to the (auto-) variance-covariance matrix, the L-coscale matrix is positive semi-definite, and its main diagonal contains the L-scale's. conversely, the L-coscale matrix is inherently assymmetric, thus yielding more information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_scale(x, trim=(1, 1), axis=-1)\narray([0.66698774, 0.54440895])\n&gt;&gt;&gt; lmo.l_coscale(x, trim=(1, 1))\narray([[ 0.66698774, -0.41025416],\n       [-0.37918065,  0.54440895]])\n</code></pre> See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_scale</code></li> <li><code>numpy.cov</code></li> </ul>"},{"location":"reference/#lmo.l_corr","title":"<code>lmo.l_corr(a, /, trim=0, 0, rowvar=True, dtype=np.float_, **kwargs)</code>","text":"<p>Sample L-correlation coefficient matrix \\(\\tilde\\Lambda^{(t_1, t_2)}_2\\); the ratio of the L-coscale matrix over the L-scale column-vectors.</p> <p>Alias for <code>lmo.l_coratio(a, 2, 2, *, **)</code>.</p> <p>The diagonal consists of all 1's.</p> <p>Where the pearson correlation coefficient measures linearity, the (T)L-correlation coefficient measures monotonicity.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; cov = np.array([[6, -3], [-3, 3.5]])\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_corr(x)\narray([[ 1.        , -0.65247355],\n       [-0.67503962,  1.        ]])\n</code></pre> <p>Let's compare this with the theoretical correlation</p> <pre><code>&gt;&gt;&gt; cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n-0.6546536707079772\n</code></pre> <p>and the (Pearson) correlation coefficient matrix:</p> <pre><code>&gt;&gt;&gt; np.corrcoef(x)\narray([[ 1.        , -0.66383285],\n       [-0.66383285,  1.        ]])\n</code></pre> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>numpy.corrcoef</code></li> </ul>"},{"location":"reference/#lmo.l_coskew","title":"<code>lmo.l_coskew(a, /, trim=0, 0, rowvar=True, dtype=np.float_, **kwargs)</code>","text":"<p>Sample L-coskewness coefficient matrix \\(\\tilde\\Lambda^{(t_1, t_2)}_3\\).</p> <p>Alias for <code>lmo.l_coratio(a, 3, 2, *, **)</code>.</p> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>lmo.l_skew</code></li> </ul>"},{"location":"reference/#lmo.l_cokurtosis","title":"<code>lmo.l_cokurtosis(a, /, trim=0, 0, rowvar=True, dtype=np.float_, **kwargs)</code>","text":"<p>Sample L-cokurtosis coefficient matrix \\(\\tilde\\Lambda^{(t_1, t_2)}_4\\).</p> <p>Alias for <code>lmo.l_coratio(a, 4, 2, *, **)</code>.</p> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>lmo.l_kurtosis</code></li> </ul>"},{"location":"reference/#population-l-moments","title":"Population L-moments","text":"<p>Theoretical L-moments of known and unknown probability distributions.</p>"},{"location":"reference/#lmo.theoretical.l_moment_from_cdf","title":"<code>lmo.theoretical.l_moment_from_cdf(cdf, r, /, trim=0, 0, support=-np.inf, np.inf)</code>","text":"<p>Evaluate the population L-moment of a continuous probability distribution, using its Cumulative Distribution Function (CDF) \\(F_X(x) = P(X \\le x)\\).</p> Notes <p>Numerical integration is performed with <code>scipy.integrate.quad</code>, which cannot verify whether the integral exists and is finite. If it returns an error message, an <code>IntegrationWarning</code> is issues, and <code>nan</code> is returned (even if <code>quad</code> returned a finite result).</p> PARAMETER  DESCRIPTION <code>cdf</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> <p> TYPE: <code>Callable[[float], float]</code> </p> <code>r</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right- trim. Must be a tuple of two non-negative ints or floats (!).</p> <p> TYPE: <code>tuple[AnyFloat, AnyFloat]</code> DEFAULT: <code>0, 0</code> </p> <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>.</p> <p> TYPE: <code>tuple[AnyFloat, AnyFloat]</code> DEFAULT: <code>-np.inf, np.inf</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p><code>r</code> is not integer-valued</p> <code>ValueError</code> <p><code>r</code> is empty or negative</p> RETURNS DESCRIPTION <code>lmbda</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>. If <code>nan</code>, consult the related <code>IntegrationWarning</code> message.</p> <p> TYPE: <code>float | npt.NDArray[np.float_]</code> </p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul> See Also <ul> <li><code>theoretical.l_moment_from_ppf</code>:   population L-moment, using the inverse CDF</li> <li><code>l_moment</code>: sample L-moment</li> </ul> TODO <ul> <li>The equations used for the r=0, r=1, and r&gt;1 cases.</li> <li>Optional cdf args and kwargs with ParamSpec.</li> </ul>"},{"location":"reference/#lmo.theoretical.l_moment_from_ppf","title":"<code>lmo.theoretical.l_moment_from_ppf(ppf, r, /, trim=0, 0, support=0, 1)</code>","text":"<p>Evaluate the population L-moment of a continuous probability distribution, using its Percentile Function (PPF) \\(Q_X(p) = F^{-1}_X(p)\\), i.e. the inverse of the CDF, commonly known as the quantile function.</p> Notes <p>Numerical integration is performed with <code>scipy.integrate.quad</code>, which cannot verify whether the integral exists and is finite. If it returns an error message, an <code>IntegrationWarning</code> is issues, and <code>nan</code> is returned (even if <code>quad</code> returned a finite result).</p> PARAMETER  DESCRIPTION <code>ppf</code> <p>The quantile function, a monotonically continuous increasing function with signature <code>(float) -&gt; float</code>, that maps a probability in \\([0, 1]\\), to the domain of the distribution.</p> <p> TYPE: <code>Callable[[float], float]</code> </p> <code>r</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right- trim. Must be a tuple of two non-negative ints or floats (!).</p> <p> TYPE: <code>tuple[AnyFloat, AnyFloat]</code> DEFAULT: <code>0, 0</code> </p> <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>.</p> <p> TYPE: <code>tuple[AnyFloat, AnyFloat]</code> DEFAULT: <code>0, 1</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p><code>r</code> is not integer-valued</p> <code>ValueError</code> <p><code>r</code> is empty or negative</p> RETURNS DESCRIPTION <code>lmbda</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>. If <code>nan</code>, consult the related <code>IntegrationWarning</code> message.</p> <p> TYPE: <code>float | npt.NDArray[np.float_]</code> </p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul> See Also <ul> <li><code>theoretical.l_moment_from_cdf</code>:   population L-moment, using the CDF (i.e. the inverse PPF)</li> <li><code>l_moment</code>: sample L-moment</li> </ul> TODO <ul> <li>The equations used for the r=0, r&gt;0 cases.</li> <li>Optional ppf args and kwargs with ParamSpec.</li> </ul>"},{"location":"reference/#statistical-test-and-tools","title":"Statistical test and tools","text":""},{"location":"reference/#lmo.diagnostic.normaltest","title":"<code>lmo.diagnostic.normaltest(a, /, axis=None)</code>","text":"<p>Test the null hypothesis that a sample comes from a normal distribution. Based on the Harri &amp; Coble (2011) test, and includes Hosking's correction.</p> PARAMETER  DESCRIPTION <code>a</code> <p>The array-like data.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>axis</code> <p>Axis along which to compute the test.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>statistic</code> <p>The \\(\\tau^2_{3, 4}\\) test statistic.</p> <p> TYPE: <code>NormaltestResult</code> </p> <code>pvalue</code> <p>A 2-sided chi squared probability for the hypothesis test.</p> <p> TYPE: <code>NormaltestResult</code> </p> <p>Examples:</p> <p>Compare the testing power with <code>scipy.stats.normaltest</code> given 10.000 samples from a contaminated normal distribution.</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from lmo.diagnostic import normaltest\n&gt;&gt;&gt; from scipy.stats import normaltest as normaltest_scipy\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; n = 10_000\n&gt;&gt;&gt; x = 0.9 * rng.normal(0, 1, n) + 0.1 * rng.normal(0, 9, n)\n&gt;&gt;&gt; normaltest(x)[1]\n0.04806618...\n&gt;&gt;&gt; normaltest_scipy(x)[1]\n0.08435627...\n</code></pre> References <p>A. Harri &amp; K.H. Coble (2011) - Normality testing: Two new tests using L-moments</p>"},{"location":"reference/#low-level-api","title":"Low-level API","text":""},{"location":"reference/#lmo.l_weights","title":"<code>lmo.l_weights(r, n, /, trim=0, 0, dtype=np.float_, *, cache=False)</code>","text":"<p>Projection matrix of the first \\(r\\) (T)L-moments for \\(n\\) samples.</p> <p>The matrix is a linear combination of the Power Weighted Moment (PWM) weight matrix (the sample estimator of \\(beta_{r_1}\\)), and the shifted Legendre polynomials.</p> <p>If <code>trim != (0, 1)</code>, a linearized (and corrected) adaptation of the recurrence relations from Hosking (2007) are applied, as well.</p> \\[ (2k + t_1 + t_2 - 1) \\lambda^{(t_1, t_2)}_k     = (k + t_1 + t_2) \\lambda^{(t_1 - 1, t_2)}_k     + \\frac{1}{k} (k + 1) (k + t_2) \\lambda^{(t_1 - 1, t_2)}_{k+1} \\] <p>for \\(t_1 &gt; 0\\), and</p> \\[ (2k + t_1 + t_2 - 1) \\lambda^{(t_1, t_2)}_k     = (k + t_1 + t_2) \\lambda^{(t_1, t_2 - 1)}_k     - \\frac{1}{k} (k + 1) (k + t_1) \\lambda^{(t_1, t_2 - 1)}_{k+1} \\] <p>for \\(t_2 &gt; 0\\).</p> TLDR <p>This matrix (linearly) transforms \\(x_{i:n}\\) (i.e. the sorted observation vector(s) of size \\(n\\)), into (an unbiased estimate of) the generalized trimmed L-moments, with orders \\(\\le r\\).</p> RETURNS DESCRIPTION <code>P_r</code> <p>2-D array of shape <code>(r, n)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; lmo.l_weights(3, 4)\narray([[ 0.25      ,  0.25      ,  0.25      ,  0.25      ],\n       [-0.25      , -0.08333333,  0.08333333,  0.25      ],\n       [ 0.25      , -0.25      , -0.25      ,  0.25      ]])\n&gt;&gt;&gt; _ @ [-1, 0, 1 / 2, 3 / 2]\narray([0.25      , 0.66666667, 0.        ])\n</code></pre> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"reference/#linalg","title":"<code>linalg</code>","text":""},{"location":"reference/#lmo.linalg.sandwich","title":"<code>lmo.linalg.sandwich(A, X, /, dtype=np.float_)</code>","text":"<p>Calculates the \"sandwich\" matrix product (<code>A @ X @ A.T</code>) along the specified <code>X</code> axis.</p> PARAMETER  DESCRIPTION <code>A</code> <p>2-D array of shape <code>(s, r)</code>, the \"bread\".</p> <p> TYPE: <code>npt.NDArray[np.number[Any]]</code> </p> <code>dtype</code> <p>The data type of the result.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>X</code> <p>Array of shape <code>(r, r, ...)</code>.</p> <p> TYPE: <code>npt.NDArray[T | np.number[Any]]</code> </p> RETURNS DESCRIPTION <code>C</code> <p>Array of shape <code>(s, s, ...)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> See Also <ul> <li>https://wikipedia.org/wiki/Covariance_matrix</li> </ul>"},{"location":"reference/#lmo.linalg.sh_legendre","title":"<code>lmo.linalg.sh_legendre(k, /, dtype=np.int_)</code>","text":"<p>Shifted Legendre polynomial coefficient matrix \\(\\widetilde{P}\\) of shape <code>(k, k)</code>, where the \\(j\\)-th coefficient of the shifted Legendre polynomial of degree \\(k\\) is at \\((k, j)\\):</p> \\[ \\widetilde{p}_{k, j} = (-1)^{k - j} \\binom{k}{j} \\binom{k + j}{j} \\] <p>Useful for transforming probability-weighted moments into L-moments.</p> PARAMETER  DESCRIPTION <code>k</code> <p>The size of the matrix, and the max degree of the shifted Legendre polynomial.</p> <p> TYPE: <code>int</code> </p> <code>dtype</code> <p>Desired output data type, e.g, <code>numpy.float64</code>. Default is <code>numpy.int64</code>.</p> <p> TYPE: <code>type[T]</code> DEFAULT: <code>np.int_</code> </p> RETURNS DESCRIPTION <code>P</code> <p>2-D array of the lower-triangular square matrix of size \\(k^2\\)`.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <p>Calculate \\(\\widetilde{P}_{4 \\times 4}\\):</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import sh_legendre\n&gt;&gt;&gt; sh_legendre(4)\narray([[  1,   0,   0,   0],\n       [ -1,   2,   0,   0],\n       [  1,  -6,   6,   0],\n       [ -1,  12, -30,  20]])\n</code></pre> See Also <ul> <li>https://wikipedia.org/wiki/Legendre_polynomials</li> <li>https://wikipedia.org/wiki/Pascal_matrix</li> </ul>"},{"location":"reference/#lmo.linalg.sh_jacobi","title":"<code>lmo.linalg.sh_jacobi(k, a, b, /, dtype=None)</code>","text":"<p>Shifted Jacobi polynomial coefficient matrix \\(\\widetilde{P}^{(a,b)}\\) of shape <code>(k, k)</code>, where the \\(j\\)-th coefficient of the shifted Jacobi polynomial of degree \\(k\\) is at \\((k, j)\\):</p> <p>The \"shift\" refers to the change of variables \\(x \\mapsto 2x - 1\\) in the (unshifted) Jacobi (or hypergeometric) polynomials.</p> <p>The (shifted) Jacobi polynomials \\(\\widetilde{P}^{(a,b)}\\) generalize  the (shifted) Legendre polynomials \\(\\widetilde{P}\\): \\(\\widetilde{P}^{(0, 0)} = \\widetilde{P}\\)</p> Notes <p>Analogous to the shifted Legendre polynomials, this implementation</p> PARAMETER  DESCRIPTION <code>k</code> <p>The size of the matrix, and the max degree of the polynomial.</p> <p> TYPE: <code>AnyInt</code> </p> <code>a</code> <p>The \\(\\alpha\\) parameter, must be \\(\\ge 0\\).</p> <p> TYPE: <code>T | int</code> </p> <code>b</code> <p>The \\(\\beta\\) parameter, must be \\(\\ge 0\\).</p> <p> TYPE: <code>T | int</code> </p> <code>dtype</code> <p>Desired output data type, e.g, <code>numpy.float64</code>. Default is <code>numpy.int64</code> if <code>a</code> and <code>b</code> are integers, otherwise <code>np.float64</code>.</p> <p> TYPE: <code>type[T] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>P</code> <p>2-D array of the lower-triangular square matrix of size \\(k^2\\)`.</p> <p> TYPE: <code>npt.NDArray[T | np.int_]</code> </p> <p>Examples:</p> <p>Calculate \\(\\widetilde{P}^{(1, 1)}_{4 \\times 4}\\):</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import sh_jacobi\n&gt;&gt;&gt; sh_jacobi(4, 1, 1)\narray([[  1,   0,   0,   0],\n       [ -2,   4,   0,   0],\n       [  3, -15,  15,   0],\n       [ -4,  36, -84,  56]])\n</code></pre> <p>Let's compare \\(\\widetilde{P}^(1, \\pi)_3\\) with the scipy Jacobi poly1d. This requires manual shifting \\(x \\mapsto f(x)\\), with \\(f(x) = 2x - 1\\):</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scipy.special as sc\n&gt;&gt;&gt; f_x = np.poly1d([2, -1])  # f(x) = 2*x + 1\n&gt;&gt;&gt; sc.jacobi(3, 1, np.pi)(f_x)\npoly1d([ 125.80159497, -228.55053774,  128.54584648,  -21.79690371])\n&gt;&gt;&gt; sh_jacobi(4, 1, np.pi)[3]\narray([ -21.79690371,  128.54584648, -228.55053774,  125.80159497])\n</code></pre> <p>Apart from the reversed coefficients of <code>numpy.poly1d</code> (an awkward design choice, but it's fixed in the new <code>numpy.polynomial</code> module.)</p> See Also <ul> <li>https://mathworld.wolfram.com/JacobiPolynomial.html</li> <li><code>scipy.special.jacobi</code></li> </ul>"},{"location":"reference/#lmo.linalg.succession_matrix","title":"<code>lmo.linalg.succession_matrix(c)</code>","text":"<p>A toeplitz-like transformation matrix construction, that prepends \\(i\\) zeroes to \\(i\\)-th row, so that the input shape is mapped from <code>(n, k)</code> to <code>(n, k + n)</code>.</p> <p>So all values \\(i &gt; j \\vee i + j \\ge k\\) are zero in the succession matrix.</p> PARAMETER  DESCRIPTION <code>c</code> <p>Dense matrix of shape <code>(n, k)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> RETURNS DESCRIPTION <code>S</code> <p>Matrix of shape <code>(n, k + n)</code></p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import succession_matrix\n&gt;&gt;&gt; succession_matrix(np.arange(1, 9).reshape(4, 2))\narray([[1, 2, 0, 0, 0],\n       [0, 3, 4, 0, 0],\n       [0, 0, 5, 6, 0],\n       [0, 0, 0, 7, 8]])\n</code></pre>"},{"location":"reference/#lmo.linalg.trim_matrix","title":"<code>lmo.linalg.trim_matrix(r, /, trim, dtype=np.float_)</code>","text":"<p>Linearization of the trimmed L-moment recurrence relations, following the (corrected) derivation by Hosking (2007) from the (shifted) Jacobi Polynomials.</p> <p>This constructs a \\(r \\times r + t_1 + t_2\\) matrix \\(T^{(t_1, t_2)}\\) that \"trims\" conventional L-moments. E.g. the first 3 \\((1, 1)\\) trimmed L-moments can be obtained from the first \\(3+1+1=5\\) (untrimmed) L-moments (assuming they exist) with <code>trim_matrix(3, (1, 1)) @ l_moment(x, np.ogrid[:5] + 1)</code>.</p> <p>The big \"L\" in \"L-moment\", referring to it being a Linear combination of order statistics, has been prominently put in the name by Hosking (1990) for a good reason. It means that transforming order statistics to a bunch of L-moments, can be done using a single matrix multiplication (see <code>lmo.linalg.sh_legendre</code>). By exploiting liniarity, it can easily be chained with this trim matrix, to obtain a re-usable order-statistics -&gt; trimmed L-moments transformation (matrix).</p> <p>Note that these linear transformations can be used in exactly the same way to e.g. calculate several population TL-moments of some random varianble, using nothing but its theoretical probablity-weighted moments (PWMs).</p> PARAMETER  DESCRIPTION <code>r</code> <p>The max (trimmed) L-moment order.</p> <p> TYPE: <code>int</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((t_1, t_2)\\), integers \\(\\ge 0\\). If set to (0, 0), the identity matrix is returned.</p> <p> TYPE: <code>tuple[int, int]</code> </p> <code>dtype</code> <p>Desired output data type, e.g, <code>numpy.float64</code> (default).</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> RETURNS DESCRIPTION <code>npt.NDArray[np.floating[Any]]</code> <p>Toeplitz-like matrix of shape \\((r, r + t_1 + t_2)\\).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import trim_matrix\n&gt;&gt;&gt; trim_matrix(3, (0, 1))\narray([[ 1.        , -1.        ,  0.        ,  0.        ],\n       [ 0.        ,  0.75      , -0.75      ,  0.        ],\n       [ 0.        ,  0.        ,  0.66666667, -0.66666667]])\n&gt;&gt;&gt; trim_matrix(3, (1, 0))\narray([[1.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.75      , 0.75      , 0.        ],\n       [0.        , 0.        , 0.66666667, 0.66666667]])\n</code></pre> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"}]}