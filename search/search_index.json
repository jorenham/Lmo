{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lmo - Trimmed L-moments and L-comoments","text":"<p>Unlike the legacy product-moments, the L-moments uniquely describe a probability distribution, and are more robust and efficient.</p> <p>The \u201cL\u201d stands for Linear; it is a linear combination of order statistics. So Lmo is as fast as sorting your samples (in terms of time-complexity).</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Calculates trimmed L-moments and L-comoments, from samples or any   <code>scipy.stats</code> distribution.</li> <li>Full support for trimmed L-moment (TL-moments), e.g.   <code>lmo.l_moment(..., trim=(1/137, 3.1416))</code>.</li> <li>Generalized Method of L-moments: robust distribution fitting that beats MLE.</li> <li>Fast estimation of L-comoment matrices from your multidimensional data   or multivariate distribution.</li> <li>Goodness-of-fit test, using L-moment or L-moment ratio\u2019s.</li> <li>Exact (co)variance structure of the sample- and population L-moments.</li> <li>Theoretical &amp; empirical influence functions of L-moments &amp; L-ratio\u2019s.</li> <li>Complete docs, including detailed API reference with usage examples and with mathematical \\(\\TeX\\) definitions.</li> <li>Clean Pythonic syntax for ease of use.</li> <li>Vectorized functions for very fast fitting.</li> <li>Fully typed, tested, and tickled.</li> <li>Optional Pandas integration.</li> </ul>"},{"location":"#quick-example","title":"Quick example","text":"<p>Even if your data is pathological like Cauchy, and the L-moments are not defined, the trimmed L-moments (TL-moments) can be used instead.</p> <p>Let\u2019s calculate the first two TL-moments (the TL-location and the TL-scale) of a small amount of samples drawn from the standard Cauchy distribution:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; rng = np.random.default_rng(1980)\n&gt;&gt;&gt; data = rng.standard_cauchy(96)\n&gt;&gt;&gt; lmo.l_moment(data, [1, 2], trim=1)\narray([-0.17937038,  0.68287665])\n</code></pre> <p>Compared with the theoretical standard Cauchy TL-moments, that pretty close!</p> <pre><code>&gt;&gt;&gt; from scipy.stats import cauchy\n&gt;&gt;&gt; cauchy.l_moment([1, 2], trim=1)\narray([0.        , 0.69782723])\n</code></pre> <p>Now let\u2019s try this again using the first two conventional moments, i.e. the mean and the standard deviation:</p> <pre><code>&gt;&gt;&gt; from scipy.stats import moment\n&gt;&gt;&gt; np.r_[data.mean(), data.std()]\narray([-1.7113441 , 19.57350731])\n</code></pre> <p>So even though the <code>data</code> was drawn from the standard Cauchy distribution, we can immediately see that this look standard at all.</p> <p>The reason is that the Cauchy distribution doesn\u2019t have a mean or standard deviation:</p> <pre><code>&gt;&gt;&gt; np.r_[cauchy.mean(), cauchy.std()]\narray([nan, nan])\n</code></pre> <p>See the documentation for more examples and the API reference.</p>"},{"location":"#installation","title":"Installation","text":"<p>Lmo is available on PyPI, and can be installed with:</p> <pre><code>pip install lmo\n</code></pre> <p>If you care about static typing, then it is recommended to install Lmo as <code>Lmo[typing]</code>, i.e.:</p> <pre><code>pip install Lmo[typing]\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>Automatic trim-length selection.</li> <li>Plotting utilities (deps optional), e.g. for L-moment ratio diagrams.</li> </ul>"},{"location":"#dependencies","title":"Dependencies","text":"<p>These are automatically installed by your package manager when installing Lmo.</p> version <code>python</code> <code>&gt;=3.11</code> <code>numpy</code> <code>&gt;=1.24</code> <code>scipy</code> <code>&gt;=1.10</code> <p>Additionally, Lmo supports the following optional packages:</p> version <code>pip install _</code> extra requirements <code>scipy-stubs</code> <code>&gt;=1.14.1.0</code> <code>Lmo[typing]</code> <code>scipy &gt;= 1.14.1</code> <code>pandas</code> <code>&gt;=2.0</code> <code>Lmo[pandas]</code> <p>See SPEC 0 for more information.</p>"},{"location":"#foundational-literature","title":"Foundational Literature","text":"<ul> <li>J.R.M. Hosking (1990) \u2013 L-moments: Analysis and Estimation of Distributions using Linear Combinations of Order Statistics</li> <li>E.A.H. Elamir &amp; A.H. Seheult (2003) \u2013 Trimmed L-moments</li> <li>J.R.M. Hosking (2007) \u2013 Some theory and practical uses of trimmed L-moments</li> <li>R. Ser\ufb02ing &amp; P. Xiao (2007) \u2013 A contribution to multivariate L-moments: L-comoment matrices</li> </ul>"},{"location":"contributing/","title":"Contributing to Lmo","text":"<p>Any contributions to Lmo are appreciated!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as issues.</p> <p>When reporting a bug, make sure to include the versions of <code>lmo</code>, <code>python</code>, <code>numpy</code> and <code>scipy</code> you are using, and provide a reproducible example of the bug.</p>"},{"location":"contributing/#environment-setup","title":"Environment setup","text":"<p>Ensure you have poetry installed. It can help to use Lmo\u2019s lowest-supported Python version, so that you don\u2019t accidentally use those bleeding-edge Python features that you shouldn\u2019t, e.g.</p> <pre><code>poetry env use python3.10\n</code></pre> <p>Now you can install the dev dependencies using</p> <pre><code>poetry install --sync\n</code></pre>"},{"location":"contributing/#pre-commit","title":"pre-commit","text":"<p>Lmo uses pre-commit to ensure that the code is formatted and typed correctly when committing the changes.</p> <pre><code>poetry run pre-commit install\n</code></pre> <p>It can also be manually run:</p> <pre><code>poetry run pre-commit --all-files\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Lmo uses pytest and hypothesis as testing framework.</p> <p>The tests can be run using</p> <pre><code>poetry run pytest\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>If your change involves documentation updates, you can conjure up a live preview:</p> <pre><code>poetry run mkdocs serve\n</code></pre> <p>This will require <code>pandoc</code> and <code>pandoc-citeproc</code> to be installed on your system (e.g. using the conda-forge <code>pypandoc</code> package, on <code>apt-get install pandoc pandoc-citeproc</code> on Ubuntu).</p> <p>This will make the site available at <code>http://127.0.0.1:8000/</code>. It automatically reloads when changes are made to the source code or the documentation.</p> <p>But don\u2019t worry about building the docs, or bumping the version; Lmo\u2019s personal assistant will do that on release.</p>"},{"location":"distributions/","title":"Exact L-moments of probability distributions","text":"<p>This page lists theoretical L-moments <sup>1</sup> of popular probability distributions.</p> <p>All distributions are in the \u201cstandardized\u201d form, similar to the convention used in the <code>scipy.stats</code> distribution documentation. Shifting a distribution only affects the L-location \\( \\tlmoment{s,t}{1} \\), just like the expectation and the median. Scaling a distribution simply scales all L-moments \\( \\tlmoment{s,t}{r}, \\; r \\ge 1 \\) analogous to e.g. the standard deviation or MAD. Note that neither shifting nor scaling affects the L-moment ratio\u2019s  \\( \\tlratio{s,t}{r} \\).</p> <p>Each of the listed expressions have been validated, both numerically and symbolically (with either Wolfram Alpha, SymPy, or pen and paper).</p> <p>Most of the closed-form expressions that are listed here, have been previously reported in the literature. But for the sake of interpretability, several have been algebraically rearranged.</p> <p>Due to the exploratory use of symbolic computation software, this listing is likely to include some novel solutions. This is also the reason for the lack of references. But this should pose no problems in practise, since Lmo makes it trivial to check if they aren\u2019t incorrect.</p>"},{"location":"distributions/#simple-distributions","title":"Simple distributions","text":"<p>Tip</p> <p>Numerical calculation of these L-statistics using <code>scipy.stats</code> distributions, refer to <code>rv_continuous.l_stats</code>.</p> <p>For direct calculation of the L-stats from a CDF or PPF function, see</p> <ul> <li><code>lmo.theoretical.l_stats_from_cdf</code></li> <li><code>lmo.theoretical.l_stats_from_ppf</code></li> </ul> <p>An overview of the exact L-location, L-scale, L-skewness and L-kurtosis of some well-known (univariate) probability distributions.</p>"},{"location":"distributions/#l-stats","title":"L-stats","text":"Distribution Shape \\( \\lmoment{1} \\) \\( \\lmoment{2} \\) \\( \\lratio{3} = \\lmoment{3}/\\lmoment{2} \\) \\( \\lratio{4} = \\lmoment{4}/\\lmoment{2} \\) Uniform <code>uniform()</code> \\( \\dfrac 1 2 \\\\ = 0.5 \\) \\( \\dfrac 1 6 \\\\ = 0.16\\overline{6} \\dots \\) \\( 0 \\) \\( 0 \\) Normal <code>norm()</code> \\( 0 \\) \\( \\dfrac{1}{\\sqrt \\pi} \\\\ \\approx 0.5642 \\) \\( 0 \\) \\(                 30 \\dfrac{\\href{#const-theta_m}{\\theta_m}}{\\pi} - 9 \\\\                 \\approx 0.1226             \\) Logistic <code>logistic()</code> \\( 0 \\) \\( 1 \\) \\( 0 \\) \\( \\dfrac 1 6 \\\\ = 0.16\\overline{6} \\dots \\) Laplace <code>laplace()</code> \\( 0 \\) \\( \\dfrac 3 4 \\\\ = 0.75 \\) \\( 0 \\) \\( \\dfrac{17}{72} \\\\ \\approx 0.2361 \\) Student\u2019s t <code>t(2)</code> \\( \\nu = 2 \\) \\( 0 \\) \\( \\dfrac{\\pi}{2 \\sqrt 2} \\\\ \\approx 1.1107 \\) \\( 0 \\) \\( \\dfrac 3 8 \\\\ = 0.375 \\) Student\u2019s t <code>t(3)</code> \\( \\nu = 3 \\) \\( 0 \\) \\( \\dfrac{3 \\sqrt 3}{2 \\pi} \\\\ \\approx 0.8270 \\) \\( 0 \\) \\( 1 - \\dfrac{175}{24 \\pi^2} \\\\ \\approx 0.2612 \\) Student\u2019s t <code>t(4)</code> \\( \\nu = 4 \\) \\( 0 \\) \\( \\dfrac{15}{64} \\pi \\\\ \\approx 0.7363 \\) \\( 0 \\) \\( \\dfrac{111}{512} \\\\ \\approx 0.2168 \\) Exponential <code>expon()</code> \\( 1 \\) \\( \\dfrac 1 2 \\\\ = 0.5 \\) \\( \\dfrac 1 3 \\\\ = 0.3\\overline{3} \\dots \\) \\( \\dfrac 1 6 \\\\ = 0.16\\overline{6} \\dots \\) Half-normal <code>halfnorm()</code> \\( 1 \\) \\( \\sqrt 2 - 1 \\\\ \\approx 0.4142 \\) \\(                 7                 + 4 \\sqrt 2                 - 12 (2 - \\sqrt 2) \\dfrac{\\href{#const-theta_m}{\\theta_m}}{\\pi}                 \\\\                 \\approx 0.1983             \\) \\( \\approx 0.09732 \\) Half-logistic <code>halflogistic()</code> \\( 2 \\ln 2 \\\\ \\approx 1.386 \\) \\( 1 \\) \\( \\dfrac{1}{1 - \\ln 2} - 3 \\\\ \\approx 0.2589 \\) \\( 11 - \\dfrac{10}{3 - \\ln 8} \\\\ \\approx 0.1370 \\) Rayleigh <code>rayleigh()</code> \\( \\sqrt{\\pi / 2} \\\\ \\approx 1.253 \\) \\(                 \\sqrt{\\pi / 2} - \\sqrt{\\pi / 4} \\\\                 \\approx 0.3671             \\) \\(                 \\dfrac{2 + \\sqrt 2}{\\sqrt 3} - \\dfrac{4 + \\sqrt 2}{\\sqrt 2} \\\\                 \\approx 0.1140             \\) \\(                 10 \\dfrac{2 + \\sqrt 2}{\\sqrt 3}                 - 3 \\dfrac{5 + 3 \\sqrt 2}{\\sqrt 2} \\\\                 \\approx 0.1054             \\) Gumbel <code>gumbel_r()</code> \\( \\href{#const-euler}{\\gamma_e} \\\\ \\approx 0.5772 \\) \\( \\ln{2} \\\\ \\approx 0.6931 \\) \\( 2 \\log_2(3) - 3 \\\\ \\approx 0.1699 \\) \\( 16 - 10 \\log_2(3) \\\\ \\approx 0.1504 \\) \\( \\chi^2 \\) <code>chi2(2)</code> \\( k = 2 \\) \\( 2 \\) \\( 1 \\) \\( \\dfrac 1 3 \\\\ = 0.3\\overline{3} \\dots \\) \\( \\dfrac 1 6 \\\\ = 0.16\\overline{6} \\dots \\) \\( \\chi^2 \\) <code>chi2(4)</code> \\( k = 4 \\) \\( 4 \\) \\( \\dfrac 3 2 \\\\ = 1.5 \\) \\( \\dfrac{19}{81} \\\\ \\approx 0.2346 \\) \\( \\dfrac{367}{2^5 \\cdot 3^4} \\\\ \\approx 0.1416 \\) \\( \\chi^2 \\) <code>chi2(6)</code> \\( k = 6 \\) \\( 6 \\) \\( \\dfrac{15}{8} \\\\ = 1.875  \\) \\( \\dfrac{139}{729} \\\\ \\approx 0.1907 \\) \\( \\dfrac{200\\ 827}{2^{11} \\cdot 3^6} \\\\ \\approx 0.1345 \\)"},{"location":"distributions/#tl-stats","title":"TL-stats","text":"<p>Symmetrically trimmed TL-stats of some symmetric distributions.</p> Distribution Shape \\( \\tlmoment{1}{1} \\) \\( \\tlmoment{1}{2} \\) \\( \\tlratio{1}{3} \\) \\( \\tlratio{1}{4} \\) Uniform <code>uniform()</code> \\( \\dfrac 1 2 \\\\ = 0.5 \\) \\( \\dfrac{1}{10} \\\\ = 0.1 \\) \\( 0 \\) \\( 0 \\) Normal <code>norm()</code> \\( 0 \\) \\(                 \\dfrac{6}{\\sqrt \\pi} \\left(                     1 - 3 \\dfrac{\\href{#const-theta_m}{\\theta_m}}{\\pi}\\right                 ) \\\\                 \\approx 0.2970             \\) \\( 0 \\) \\( \\approx 0.06248 \\) Logistic <code>logistic()</code> \\( 0 \\) \\( \\dfrac 1 2 \\\\ = 0.5 \\) \\( 0 \\) \\( \\dfrac{1}{12} \\\\ = 0.083\\overline{3} \\dots \\) Laplace <code>laplace()</code> \\( 0 \\) \\( \\dfrac{11}{32} \\\\ = 0.34375 \\) \\( 0 \\) \\( \\dfrac{3}{22} \\\\ = 0.136\\overline{36} \\dots \\) Cauchy <code>cauchy()</code> \\( 0 \\) \\( \\dfrac{18}{\\pi^3} \\ \\zeta(3) \\\\ \\approx 0.6978 \\) \\( 0 \\) \\(                 \\dfrac{25}{6}                 - \\dfrac{175}{4 \\pi^2} \\frac \\zeta(5) \\zeta(3) \\\\                 \\approx 0.3428             \\) Student\u2019s t <code>t(2)</code> \\( \\nu = 2 \\) \\( 0 \\) \\( \\dfrac{3 \\pi}{16 \\sqrt 2} \\\\ \\approx 0.4165 \\) \\( 0 \\) \\( \\dfrac{5}{32} \\\\ = 0.15625 \\) Student\u2019s t <code>t(3)</code> \\( \\nu = 3 \\) \\( 0 \\) \\( \\dfrac{105 \\sqrt 3}{16 \\pi^3} \\\\ \\approx 0.3666 \\) \\( 0 \\) \\(                 \\dfrac{25}{6} -  \\frac{23 \\ 023}{(24 \\pi)^2} \\\\                 \\approx 0.1168             \\) Student\u2019s t <code>t(4)</code> \\( \\nu = 4 \\) \\( 0 \\) \\( \\dfrac{3\\ 609\\ \\pi}{32\\ 768} \\\\ \\approx 0.3460 \\) \\( 0 \\) \\( \\dfrac{164 \\ 975}{1 \\ 642 \\ 496} \\\\ \\approx 0.1004 \\) Gumbel <code>gumbel_r()</code> \\(                 \\href{#const-euler}{\\gamma_e} - 2 \\ln 3 + 3 \\ln 2 \\\\                 \\approx 0.4594             \\) \\( 6 \\ln 3 - 9 \\ln 2 \\\\ \\approx 0.3533 \\) \\(                 - \\dfrac{10}{9} \\dfrac{5 - 2 \\log_2(5)}{3 - 2 \\log_2(3)}                 - \\frac{20}{9} \\\\                 \\approx 0.1065             \\) \\(                 \\dfrac{35}{6} \\dfrac{7 - 3 \\log_2(5)}{3 - 2 \\log_2(3)}                 + \\dfrac{5}{4} \\\\                 \\approx 0.07541             \\)"},{"location":"distributions/#ll-stats","title":"LL-stats","text":"<p>Right-trimmed LL-stats of some simple left-bound distributions.</p> Distribution Shape \\( \\tlmoment{0, 1}{1} \\) \\( \\tlmoment{0, 1}{2} \\) \\( \\tlratio{0, 1}{3} \\) \\( \\tlratio{0, 1}{4} \\) Exponential <code>expon()</code> \\( \\dfrac 1 2 \\\\ = 0.5 \\) \\( \\dfrac 1 4 \\\\ = 0.25 \\) \\( \\dfrac 2 9 \\\\ = 0.2\\overline{2} \\dots  \\) \\( \\dfrac{1}{12} \\\\ = 0.083\\overline{3} \\dots  \\) Half-normal <code>halfnorm()</code> \\( 2 - \\sqrt 2 \\\\ \\approx 0.5858 \\) \\(                 9 \\sqrt 2 \\ \\dfrac{\\href{#const-theta_m}{\\theta_m}}{\\pi}                 - 3 \\dfrac{1 + \\sqrt 2}{2} \\\\                 \\approx 0.2491             \\) \\( \\approx 0.1119 \\) \\( \\approx 0.04489 \\) Half-logistic <code>halflogistic()</code> \\( 4 \\ln 2 - 2 \\\\ \\approx 0.7726 \\) \\( 1 \\) \\(                 \\dfrac{4}{27} \\left( \\dfrac{5}{3 - 4 \\ln 2} - 21 \\right) \\\\                 \\approx 0.1462             \\) \\(                 \\dfrac{5}{36}                 \\left( \\dfrac{-19}{3 - 4 \\ln 2} + 84 \\right) \\\\                 \\approx 0.06263             \\) Half-Cauchy <code>halfcauchy()</code> \\( \\dfrac{4 \\ln 2}{\\pi} \\\\ \\approx 0.8825 \\) \\(                 \\dfrac{63 \\href{#const-zeta}{\\mathop{\\zeta}}(3)}{2 \\pi^3}                 - \\dfrac{3 \\ln 2}{\\pi} \\\\                 \\approx 0.5593             \\) \\(                 \\dfrac                     {40 \\mathop{\\zeta}(3)}                     {63 \\mathop{\\zeta}(3) - 9 \\pi^2 \\ln 2}                 - \\frac 8 9 \\\\                 \\approx 0.4974             \\) \\(                 \\dfrac{155}{2}                 \\dfrac                     {3 \\mathop{\\zeta}(3) - 35 \\pi^{-2} \\mathop{\\zeta}(5)}                     {21 \\mathop{\\zeta}(3) - 2 \\pi^2 \\ln 2}                 + \\dfrac 5 6 \\\\                 \\approx 0.3572             \\) Rayleigh <code>rayleigh()</code> \\( \\dfrac{\\sqrt \\pi}{2} \\\\ \\approx 0.8862 \\) \\( \\dfrac{3 - \\sqrt 6}{4} \\sqrt \\pi \\\\ \\approx 0.2439 \\) \\(                 \\dfrac{10}{9}  \\left( 3 \\sqrt 2 + 2 \\sqrt 3 - 2 \\sqrt 6 \\right)                 - \\frac{28}{9}  \\\\                 \\approx 0.008\\ 625             \\) \\(                 \\dfrac 1 4 \\dfrac{80 - 75 \\sqrt 2 + 14 \\sqrt{10}}{\\sqrt 6 - 3}                 + \\dfrac{25}{3} \\\\                 \\approx 0.06561             \\) Gumbel <code>gumbel_r()</code> \\( \\href{#const-euler}{\\gamma_e} - \\ln 2 \\\\ \\approx -0.1159 \\) \\( 3 \\ln 2 - \\dfrac 3 2 \\ln 3 \\\\ \\approx 0.4315 \\) \\(                 \\dfrac 4 9 \\left( \\dfrac{5}{2 - \\log_2(3)} - 12 \\right) \\\\                 \\approx 0.02094             \\) \\(                 \\dfrac 5 6                 \\left( \\dfrac{8 - 7 \\log_2(5)}{2 - \\log_2(3)} + 20 \\right) \\\\                 \\approx 0.09488             \\) \\( \\chi^2 \\) <code>chi2(2)</code> \\( k = 2 \\) \\( 1 \\) \\( \\dfrac 1 2 \\\\ = 0.5 \\) \\( \\dfrac 2 9 \\\\ = 0.2\\overline{2}\\ldots \\) \\( \\dfrac{1}{12} \\\\ = 0.083\\overline{3}\\ldots \\) \\( \\chi^2 \\) <code>chi2(4)</code> \\( k = 4 \\) \\( \\dfrac 5 2 \\\\ = 2.5 \\) \\( \\dfrac{31}{36} \\\\ = 0.861\\overline{1}\\dots \\) \\( \\dfrac{241}{2\\ 232} \\\\ \\approx 0.1080 \\) \\( \\dfrac{282\\ 127}{372 \\cdot 10^4} \\\\ \\approx 0.07584 \\) \\( \\chi^2 \\) <code>chi2(6)</code> \\( k = 6 \\) \\( \\dfrac{33}{8} \\\\ = 4.125 \\) \\( \\dfrac{1\\ 475}{1\\ 296} \\\\ \\approx 1.138 \\) \\( \\dfrac{16\\ 769}{271\\ 872} \\\\ \\approx 0.06168 \\) \\(                 \\dfrac{550\\ 465\\ 668\\ 887}{708 \\cdot 10^{10}} \\\\                 \\approx 0.07775             \\)"},{"location":"distributions/#general-l-moments","title":"General L-moments","text":"<p>Lmo derived a bunch of closed-form solutions for L-moments of several distributions. The proofs are not published, but it isn\u2019t difficult to validate their correctness, e.g. numerically, or symbolically with sympy or wolfram alpha / mathematica.</p>"},{"location":"distributions/#bernoulli","title":"Bernoulli","text":"<p>Surprisingly, the L-moments of the discrete Bernoulli distribution <sup>2</sup>, can\u2019t be expressed as easily as the distribution itself:</p> \\[ \\tlmoment{s, t}{r} =     \\frac{(-1)^r}{r}     (1 - p)^{s + 1}     \\jacobi{r + t - 1}{s + 1}{-t - 1}{2p - 1}     + \\ffact{1}{r} \\] <p>Here, \\( \\jacobi{n}{\\alpha}{\\beta}{x} \\) is a Jacobi polynomial (although it\u2019s not orthogonal for \\( t &gt;= 0 \\), since \\( \\beta &gt; -1 \\) does not hold).</p>"},{"location":"distributions/#pfd","title":"PFD","text":"<p>With support on the interval \\( (0, 1] \\) and shape parameter \\( \\alpha &gt; 0 \\), the power function distribution has the following CDF and PPF:</p> \\[ \\begin{align*}     F(x) &amp;= x^\\alpha \\\\     x(F) &amp;= F^{\\frac 1 \\alpha} \\end{align*} \\] <p>The trimmed L-moments of order \\( r \\in \\naturals \\setminus \\{ 0 \\} \\) and trim \\( (s, t) \\in \\naturals^2 \\) are</p> \\[ \\tlmoment{s, t}{r} =     \\frac{\\ffact{\\frac 1 \\alpha}{r - 1}}{r}     \\frac{\\rfact{r + s}{1 + t}}{\\rfact{\\frac 1 \\alpha + s}{r + t}} , \\] <p>where \\( \\ffact{x}{n} \\) and \\( \\rfact{x}{n} \\) are pochhammer symbols for the falling and rising factorials, respectively.</p> <p>See <code>scipy.stats.powerlaw</code> for an Lmo-compatible implementation.</p>"},{"location":"distributions/#gompertz","title":"Gompertz","text":"<p>The Gompertz distribution <sup>3</sup> with shape parameter \\( \\alpha &gt; 0 \\) and \\( x \\ge 0 \\), has the following CDF and PPF:</p> \\[ \\begin{align*}     F(x) &amp;= 1 - e^{\\alpha (1 - e^x)} \\\\     x(F) &amp;= \\ln\\left( 1 - \\frac{\\ln(1-F)}{\\alpha} \\right) \\end{align*} \\] <p>The general trimmed L-moments of the Gompertz distribution are:</p> \\[ \\tlmoment{s, t}{r} =     \\frac{1}{r}     \\sum_{k = t + 1}^{r + s + t}         (-1)^{k - t - 1}         \\binom{r + k - 2}{r + t - 1}         \\binom{r + s + t}{k}         e^{\\alpha k} \\         \\Gamma_{\\alpha k}(0) \\]"},{"location":"distributions/#gev","title":"GEV","text":"<p>The GEV distribution <sup>4</sup> unifies the Gumbel, Fr\u00e9chet, and Weibull distributions. It has one shape parameter \\( \\alpha \\in \\mathbb{R} \\), and the following distribution functions:</p> \\[ \\begin{align*}     F(x) &amp;= e^{-\\qexp{1 - \\alpha}{-x}} \\\\     x(F) &amp;= -\\qlog{1 - \\alpha}{-\\ln(F)} \\end{align*} \\] <p>Here, \\( \\qexp{q}{y} \\) and \\( \\qlog{q}{y} \\) are the Tsallis \\( q \\)-exponential and the \\( q \\)-logarithm, respectively.</p> <p>An alternative parametrization is sometimes used, e.g. on Wikipedia, where \\( \\xi = -\\alpha \\). The convention that is used here, is the same as in <code>scipy.stats.genextreme</code>, where <code>c</code> corresponds to \\( \\alpha \\).</p> <p>The trimmed L-moments of the GEV are</p> \\[ \\tlmoment{s, t}{r} =     \\frac{(-1)^{r}}{r}     \\sum_{k = s + 1}^{r + s + t}         (-1)^{k - s}         \\binom{r + k - 2}{r + s - 1}         \\binom{r + s + t}{k}         \\left(         \\begin{cases}             \\gamma_e + \\ln(k)                 &amp; \\text{if } \\alpha = 0 \\\\             1 / \\alpha - \\Gamma(\\alpha) \\ k^{-\\alpha}                 &amp; \\text{if } \\alpha \\neq 0         \\end{cases}         \\right) \\] <p>Note that the GEV is effectively a reparametrized \\( q \\)-Gumbel Tsallis distribution, with \\( q = 1 - \\alpha \\).</p>"},{"location":"distributions/#glo","title":"GLO","text":"<p>The GLO <sup>5</sup>, also known as the shifted log-logistic distribution , with shape parameter \\( \\alpha \\in \\mathbb{R} \\), is characterized by the following distribution functions:</p> \\[ \\begin{align*}     F(x) &amp;= \\frac{1}{1 + \\qexp{1 - \\alpha}{x}} \\\\     x(F) &amp;= -\\qlog{1 - \\alpha}{\\frac{1 - F}{F}} \\end{align*} \\] <p>For \\( -1 &lt; \\alpha &lt; 1 \\), the general trimmed L-moments of the GLO are:</p> \\[ \\tlmoment{s, t}{r} = \\begin{cases}     \\displaystyle         \\digamma(s + 1) - \\digamma(t + 1)     &amp; \\text{if } \\alpha = 0 \\wedge r = 1 \\\\     \\displaystyle         \\frac{(-1)^r}{r} \\B(r - 1,\\ s + 1)         + \\frac 1 r \\B(r - 1,\\ t + 1)     &amp; \\text{if } \\alpha = 0 \\\\     \\displaystyle         \\frac{\\ffact{1}{r}}{\\alpha}         + \\sum_{k = s + 1}^{r + s + t}             (-1)^{r + s - k }             \\binom{r + k - 2}{r + s - 1}             \\binom{r + s + t}{k}             \\B(\\alpha,\\ k - \\alpha)     &amp; \\text{if } -1 &lt; \\alpha &lt; 1 \\end{cases} \\] <p>Where \\( \\digamma(z) \\) is the digamma function.</p> <p>The corresponding <code>scipy.stats</code> implementation is <code>kappa4</code>, with <code>h = -1</code> and <code>k</code> set to \\( \\alpha \\); not <code>genlogistic</code>.</p> <p>Note that the GLO is effectively a reparametrized \\( q \\)-logistic Tsallis distribution, with \\( q = 1 - \\alpha \\).</p>"},{"location":"distributions/#gpd","title":"GPD","text":"<p>The GPD <sup>6</sup>, with shape parameter \\( \\alpha \\in \\mathbb{R} \\), has for \\( x \\ge 0 \\) the distribution functions:</p> \\[ \\begin{align*}     F(x) &amp;= 1 - \\qexp{1 + \\alpha}{-x} \\\\     x(F) &amp;= -\\qlog{1 + \\alpha}{1 - F} \\end{align*} \\] <p>The L-moments of the GPD exist when \\( \\alpha &lt; 1 + t \\), and can be compactly expressed as</p> \\[ \\tlmoment{s,t}{r} = \\begin{cases}     \\displaystyle H_{s + t + 1} - H_t         &amp; \\text{if } \\alpha = 0 \\wedge r = 1 \\\\     \\displaystyle \\frac{1}{\\alpha r} \\left[         \\frac             {\\B(r + \\alpha - 1,\\ t - \\alpha + 1)}             {\\B(\\alpha,\\ r + s + t - \\alpha + 1)}         - \\ffact{1}{r}     \\right]         &amp; \\text{otherwise,} \\end{cases} \\] <p>where \\( H_n \\) is a harmonic number.</p> <p>See <code>scipy.stats.genpareto</code> for an Lmo-compatible implementation.</p> <p>Special cases</p> <p>There are several notable special cases of the GPD:</p> \\( q \\)-Exponential When \\( \\alpha &gt; -1 \\), GPD is \\( q \\)-exponential with shape \\( q = 2 - 1 / (1 + \\alpha) \\) and rate (inverse scale) \\( \\lambda = \\alpha + 1 \\). Exponential When \\( \\alpha = 0 \\), GPD is standard exponential. Uniform When \\( \\alpha = 1 \\) GPD is uniform on \\( [0, 1] \\). <p>Generalizations</p> Wakeby\u2019s distribution Implemented as <code>lmo.distributions.wakeby</code>. See below for details, including the general L-moments in closed-form. Kappa distribution Implemented in as <code>scipy.stats.kappa4</code>."},{"location":"distributions/#burr-iii-dagum","title":"Burr III / Dagum","text":"<p>The Burr III distribution <sup>7</sup>, also known as the Dagum distribution, has two shape parameters \\( \\alpha \\) and \\( \\beta \\), both restricted to the positive reals</p> <p>For \\( x &gt; 0 \\), the distribution functions are:</p> \\[ \\begin{align*}     F(x) &amp;=         (1 + x^{-\\alpha})^{-\\beta} \\\\     x(F) &amp;=         (F^{-1 / \\beta} - 1)^{-1 / \\alpha} \\end{align*} \\] <p>For \\( \\alpha &gt; 1 \\), the general L-moments are:</p> \\[ \\tlmoment{s,t}{r} =     (-1)^{t - 1 / \\alpha} \\     \\beta \\     \\frac{r + s + t}{r}     \\sum_{k = s}^{r + s + t - 1}         (-1)^{k}         \\binom{k + r - 1}{k - s}         \\binom{r + s + t - 1}{k}         \\B(1 - 1 / \\alpha, -\\beta - k \\beta) \\] <p>The Burr III distribution is implemented in <code>scipy.stats.burr</code>, where the shape parameters <code>c</code> and <code>d</code> correspond to  \\( \\alpha \\) and \\( \\beta \\), respectively. Equivalently, <code>scipy.stats.mielke</code> can be used, by setting <code>k</code> and <code>s</code> to \\( \\alpha \\beta \\) and \\( \\alpha \\), respectively.</p> <p>Special cases</p> Log-logistic / Fisk With \\( \\beta = 1 \\) Burr III is Log-logistic with shape \\( \\gamma \\equiv \\alpha \\) and scale \\( \\sigma = 1 \\)."},{"location":"distributions/#burr-xii-pareto-iv","title":"Burr XII / Pareto IV","text":"<p>The Burr XII distribution <sup>7</sup> has two shape parameters \\( \\alpha \\) and \\( \\beta \\), both restricted to the positive reals. It is also known as the Singh-Maddala distribution. The alternative parametrization \\( \\alpha \\mapsto 1 / \\gamma \\), where \\( \\gamma &gt; 0 \\), is known as the (standard) type IV Pareto distribution</p> <p>The distribution functions for \\( x &gt; 0 \\) are defined as:</p> \\[ \\begin{align*}     F(x) &amp;= 1 - (1 + x^\\alpha)^{-\\beta} \\\\     x(F) &amp;= \\bigl((1 - F)^{-1/\\beta} - 1 \\bigr)^{1/\\alpha} \\end{align*} \\] <p></p> <p>When \\( \\beta &gt; 1 / \\alpha \\), the general \\( r \\)-th trimmed L-moment is:</p> \\[ \\tlmoment{s,t}{r} =     \\beta \\     \\frac{r + s + t}{r}     \\sum_{k = t}^{r + s + t - 1}         (-1)^k         \\binom{k + r - 1}{k - t}         \\binom{r + s + t - 1}{k}         \\B\\bigl(1 + 1 / \\alpha,\\ \\beta + k \\beta - 1 / \\alpha \\bigr) \\] <p>This distribution is implemented in <code>scipy.stats.burr12</code>, where the shape parameters <code>c</code> and <code>d</code> correspond to  \\( \\alpha \\) and \\( \\beta \\), respectively.</p> <p>The Burr XII and Burr III distributions are related as \\( Y = 1 / X \\), where \\( X \\) and \\( Y \\) are RV\u2019s with Burr XII \\( (\\alpha, \\beta) \\) and Burr III \\( (1 / \\alpha, \\beta) \\) distributions (or vice-versa), respectively.</p> <p>Special cases</p> <p>There are several notable special cases of the Burr XII distribution:</p> Pareto IV Burr XII is a reparametrized standard Pareto type IV distribution with shapes \\( \\gamma \\equiv 1 / \\alpha \\) and \\( \\alpha^{\\prime} \\equiv \\beta \\), location \\( \\mu = 0 \\), and scale \\( \\sigma = 1 \\). Lomax With \\( \\alpha = 1 \\) Burr XII is Lomax with shape \\( \\alpha^{\\prime} \\equiv \\beta \\) and scale \\( \\sigma = 1 \\). Log-logistic / Fisk With \\( \\beta = 1 \\) Burr XII is Log-logistic with shape \\( \\gamma \\equiv \\alpha \\) and scale \\( \\sigma = 1 \\)."},{"location":"distributions/#kumaraswamy","title":"Kumaraswamy","text":"<p>For Kumaraswamy\u2019s distribution  <sup>8</sup> with parameters \\( \\alpha \\in \\mathbb{R}_{&gt;0} \\) and \\( \\beta \\in \\mathbb{R}_{&gt;0} \\), the general solution for the \\( r \\)th untrimmed L-moment has been derived by M.C. Jones in 2009 <sup>9</sup>. Lmo has extended these results for the general trimmed L-moments.</p> <p>The distribution functions are for \\( 0 \\le x \\le 1 \\) defined as:</p> \\[ \\begin{align*}     F(x) &amp;= 1 - (1 - x^\\alpha)^\\beta \\\\     x(F) &amp;= \\bigl(1 - (1 - F)^{1/\\beta} \\bigr)^{1/\\alpha} \\end{align*} \\] <p></p> <p>Its general \\( r \\)-th trimmed L-moment are:</p> \\[ \\tlmoment{s,t}{r} =     \\frac{1}{r}     \\sum_{k = t + 1}^{r + s + t}         (-1)^{k - t - 1}         \\binom{r + k - 2}{r + t - 1}         \\binom{r + s + t}{k}         \\frac{\\B\\bigl(1 / \\alpha,\\ 1 + k \\beta \\bigr)}{\\alpha} \\] <p>The Kumaraswamy distribution is implemented in <code>lmo.distributions.kumaraswamy</code>.</p> <p>Special cases</p> <p>There are several notable special cases of the Kumaraswamy distribution:</p> Beta With \\( \\alpha = 1 \\) or \\( \\beta = 1 \\) Kumaraswamy is \\( \\text{Beta}(1, \\beta) \\) or \\( \\text{Beta}(\\alpha, 1) \\), respectively. Uniform With \\( \\alpha = \\beta = 1 \\) Kumaraswamy is uniform on \\( [0, 1] \\)."},{"location":"distributions/#wakeby","title":"Wakeby","text":"<p>The Wakeby distribution <sup>10</sup> is quantile-based \u2013 the CDF and PDF are not analytically expressible for the general case. Without loss of generality, Lmo uses a 3-parameter \u201cstandardized\u201d paremetrization, with shape parameters \\( \\beta,\\ \\delta,\\ \\phi \\).</p> <p>See <code>lmo.distributions.wakeby</code> for the implementation.</p> <p>Each of the following restrictions apply:</p> <ul> <li>\\( \\beta + \\delta \\ge 0 \\)</li> <li>\\( 0 \\le \\phi \\le 1 \\)</li> <li>if \\( \\beta + \\delta = 0 \\), then \\( \\phi = 1 \\)</li> <li>if \\( \\phi = 0 \\), then \\( \\beta = 0 \\)</li> <li>if \\( \\phi = 1 \\), then \\( \\delta = 0 \\)</li> </ul> <p>The domain of the distribution is</p> \\[ 0 \\le x \\le \\begin{cases}     \\displaystyle \\frac \\phi \\beta - \\frac{1 - \\phi}{\\delta}         &amp; \\text{if } \\delta &lt; 0 \\\\     \\displaystyle \\frac 1 \\beta         &amp; \\text{if } \\beta &gt; 0 \\wedge \\phi = 1 \\\\     \\displaystyle \\infty         &amp; \\text{otherwise} \\end{cases} \\] <p>The PPF is defined to be</p> \\[ x(F) = -\\phi \\qlog{1 - \\beta}{1 - F} - (1 - \\phi) \\qlog{1 + \\delta}{1 - F} \\] <p>or, if \\( \\beta \\neq 0 \\) and \\( \\delta \\neq 0 \\), this is equivalent to</p> \\[ x(F) =     \\frac{\\phi}{\\beta} (1 - (1 - F)^\\beta)     - \\frac{1 - \\phi}{\\delta} (1 - (1 - F)^{-\\delta}) \\] <p></p> <p>Alternative parametrization</p> <p>This 3-parameter Wakeby distribution is equivalent to the 5-parameter variant that is generally used, after scaling by \\( \\sigma \\) and shifting by \\( \\xi \\). The shape parameters \\( \\beta \\) and \\( \\delta \\) are (intentionally) equivalent, the scale parameters are related by \\( \\alpha \\equiv \\sigma \\phi \\) and \\( gamma \\equiv \\sigma (1 - \\phi) \\), and the location parameter is precisely \\( \\xi \\).</p> <p>Conversely, Lmo\u2019s \u201cstandard\u201d Wakeby distribution can by obtained from 5-Wakeby, by shifting and scaling s.t. \\( \\xi = 0 \\) and \\( \\alpha + \\gamma = 1 \\). Finally, \\( \\phi \\equiv \\alpha = 1 - \\gamma \\) effectively combines the two scale parameters.</p> <p>Lmo figured out that when \\( \\delta &lt; t + 1 \\), all of Wakeby\u2019s (trimmed) L-moments can be expressed as</p> \\[ \\begin{align*}     \\tlmoment{s,t}{1}     &amp;= \\phi \\left(     \\begin{cases}         \\displaystyle H_{s + t + 1} - H_t             &amp; \\text{if } \\beta = 0 \\\\         \\displaystyle \\frac{1}{\\beta} - \\frac             {\\rfact{t + 1}{s + 1}}             {\\beta \\ \\rfact{t + 1 + \\beta }{s + 1}}             &amp; \\text{if } \\beta \\neq 0     \\end{cases}     \\right)     + (1 - \\phi) \\left(     \\begin{cases}         \\displaystyle H_{s + t + 1} - H_t             &amp; \\text{if } \\delta = 0 \\\\         \\displaystyle \\frac             {\\rfact{t + 1}{s + 1}}             {\\delta \\rfact{t + 1 - \\delta}{s + 1}}         - \\frac{1}{\\delta}             &amp; \\text{if } \\delta \\neq 0     \\end{cases}     \\right) \\\\     \\tlmoment{s,t}{r}     &amp;= \\frac{\\rfact{r + t}{s + 1}}{r} \\left(         \\phi \\frac             {\\rfact{1 - \\beta}{r - 2}}             { \\rfact{1 + \\beta + t}{r + s}}         + (1 - \\phi) \\frac             {\\rfact{1 + \\delta}{r - 2}}             {\\rfact{1 - \\delta + t}{r + s}}     \\right) \\quad \\text{for } r &gt; 1 \\end{align*} \\] <p>where \\( H_n \\) is a harmonic number.</p> <p>Special cases</p> <p>There are several notable special cases of the Wakeby distribution:</p> GPD \u2013 Generalized Pareto <p>With \\( \\phi = 0 \\), Wakeby is the standard GPD, and \\( \\delta \\) its shape parameter.</p> <p>Conversely, \\( \\phi = 1 \\) yields a bounded GPD variant, with shape parameter \\( -\\beta \\), and \\( 1 / \\beta \\) the upper bound.</p> Exponential With \\( \\beta = \\delta = 0 \\) and \\( \\phi = 1 \\), Wakeby is standard exponential. Uniform With \\( \\beta = \\phi = 1 \\) (and therefore \\( \\delta = 0 \\)) Wakeby is uniform on \\( [0, 1] \\)."},{"location":"distributions/#gld","title":"GLD","text":"<p>The GLD <sup>11</sup> is a flexible generalization of the Tukey lambda distribution. Lmo uses an unconventional \u201cstandardized\u201d paremetrization, with shape parameters \\( \\beta,\\ \\delta,\\ \\phi \\), where \\( \\phi \\in [-1, 1] \\) replaces the more commonly used shape parameters \\( \\alpha \\mapsto 1 + \\phi \\) and \\( \\gamma \\mapsto 1 - \\phi \\).</p> <p>The GLD is implemented as <code>lmo.distributions.genlamda</code>.</p> <p>As with the Wakeby distribution, the PDF and CDF of the GLD are not analytically expressible. Instead, the GLD is defined through its PPF:</p> \\[ x(F) = (1 + \\phi) \\qlog{1 - \\beta}{F} - (1 - \\phi) \\qlog{1 - \\delta}{1 - F} \\] <p>The domain is</p> \\[ \\left. \\begin{array}{ll}     \\text{if } \\beta \\le 0: &amp; \\displaystyle -\\infty \\\\     \\text{if } \\beta &gt; 0:  &amp; \\displaystyle -\\frac{1 + \\phi}{\\beta} \\end{array} \\right\\} \\le x \\le \\left\\{ \\begin{array}{ll}     \\displaystyle \\infty \\ , &amp; \\text{if } \\delta \\le 0 \\\\     \\displaystyle \\frac{1 - \\phi}{\\delta} \\ , &amp; \\text{if } \\delta &gt; 0 \\end{array} \\right. \\] <p></p> <p>Unlike GLD\u2019s central product-moments, which have no general closed-form expression, its trimmed L-moments can be compactly expressed. When \\( \\beta &gt; -s - 1 \\) and \\( \\delta &gt; -t - 1 \\), the L-moments are defined for \\( r = 2, 3, \\ldots \\) and \\( s, t \\ge 0 \\) as</p> \\[ r \\tlmoment{s, t}{r}     = (-1)^r \\frac{1 + \\phi}{\\beta + r + s + t}     \\frac         {\\B(\\beta + s + 1 ,\\ r - 1 - \\beta)}         {\\B(\\beta + s + t + r,\\ 1 - \\beta)}     + \\frac{1 - \\phi}{\\delta + r + s + t}     \\frac         {\\B(\\delta + 1 + t ,\\ r - 1 - \\delta)}         {\\B(\\delta + s + t + r,\\ 1 - \\delta)} \\ , \\] <p>and the arbitrarily-trimmed L-location is</p> \\[ \\tlmoment{s, t}{1}     = -(1 + \\phi) \\mathfrak{L}_{1}^{(s)}(\\beta)     + (1 - \\phi) \\mathfrak{L}_{1}^{(t)}(\\delta) \\, \\] <p>where</p> \\[ \\mathfrak{L}_{1}^{(k)}(\\theta) = \\begin{cases}     \\displaystyle H_{s + t + 1} - H_k         &amp; \\text{if } \\theta = 0 \\\\     \\displaystyle \\frac{1}{\\theta}\\left(         1 - \\frac             {\\B(1 + k + \\theta,\\ 2 + s + t)}             {\\B(1 + k,\\ \\theta + 2 + s + t)}     \\right)         &amp; \\text{otherwise.} \\end{cases} \\] <p>These equations look scarier that they actually are. To see why, take a look at the first 4 L-moment, with 4 styles of trimming:</p> L-momentsLL-momentsLH-momentsTL-moments <p>If \\( \\beta &gt; -1 \\) and \\( \\delta &gt; -1 \\):</p> \\[ \\begin{align*}     \\lmoment{1}         &amp;= -(1 + \\phi) \\frac             {1}             {1 + \\beta}         &amp;&amp;+ (1 - \\phi) \\frac             {1}             {1 + \\delta}     \\\\     \\lmoment{2}         &amp;= \\hphantom{-}(1 + \\phi) \\frac             {1}             {(1 + \\beta)(2 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {1}             {(1 + \\delta)(2 + \\delta)}     \\\\     \\lmoment{3}         &amp;= -(1 + \\phi) \\frac             {1 - \\beta}             {(1 + \\beta)(2 + \\beta)(3 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {1 - \\delta}             {(1 + \\delta)(2 + \\delta)(3 + \\delta)}     \\\\     \\lmoment{4}         &amp;= \\hphantom{-}(1 + \\phi) \\frac             {(1 - \\beta)(2 - \\beta)}             {(1 + \\beta)(2 + \\beta)(3 + \\beta)(4 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {(1 - \\delta)(2 - \\delta)}             {(1 + \\delta)(2 + \\delta)(3 + \\delta)(4 + \\delta)} \\end{align*} \\] <p>If \\( \\beta &gt; -1 \\) and \\( \\delta &gt; -2 \\):</p> \\[ \\begin{align*}     \\tlmoment{0, 1}{1}         &amp;= -(1 + \\phi) \\frac             {3 + \\beta}             {(1 + \\beta)(2 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {1}             {2 + \\delta}     \\\\     \\frac{1}{3}\\tlmoment{0, 1}{2}         &amp;= \\hphantom{-} (1 + \\phi) \\frac             {1}             {(1 + \\beta)(2 + \\beta)(3 + \\beta)}         &amp;&amp;+ \\frac{1 - \\phi}{2} \\frac             {1}             {(2 + \\delta)(3 + \\delta)}     \\\\      \\frac{1}{4} \\tlmoment{0, 1}{3}         &amp;= -(1 + \\phi) \\frac             {1 - \\beta}             {(1 + \\beta)(2 + \\beta)(3 + \\beta)(4 + \\beta)}         &amp;&amp;+ \\frac{1 - \\phi}{3} \\frac             {(1 - \\delta)}             {(2 + \\delta)(3 + \\delta)(4 + \\delta)}     \\\\      \\frac{1}{5} \\tlmoment{0, 1}{4}         &amp;= \\hphantom{-} (1 + \\phi) \\frac             {(1 - \\beta)(2 - \\beta)}             {(1 + \\beta)(2 + \\beta)(3 + \\beta)(4 + \\beta)(5 + \\beta)}         &amp;&amp;+ \\frac{1 - \\phi}{4} \\frac             {(1 - \\delta)(2 - \\delta)}             {(2 + \\delta)(3 + \\delta)(4 + \\delta)(5 + \\delta)} \\end{align*} \\] <p>If \\( \\beta &gt; -2 \\) and \\( \\delta &gt; -1 \\):</p> \\[ \\begin{align*}     \\tlmoment{1, 0}{1}         &amp;= -(1 + \\phi) \\frac             {1}             {(2 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {3 + \\beta}             {(1 + \\delta)(2 + \\delta)}     \\\\     \\frac{1}{3}\\tlmoment{1, 0}{2}         &amp;= \\hphantom{-} \\frac{1 + \\phi}{2} \\frac             {1}             {(2 + \\beta)(3 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {1}             {(1 + \\delta)(2 + \\delta)(3 + \\delta)}     \\\\      \\frac{1}{4} \\tlmoment{1, 0}{3}         &amp;= -\\frac{1 + \\phi}{3} \\frac             {1 - \\beta}             {(2 + \\beta)(3 + \\beta)(4 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {(1 - \\delta)}             {(1 + \\delta)(2 + \\delta)(3 + \\delta)(4 + \\delta)}     \\\\      \\frac{1}{5} \\tlmoment{1, 0}{4}         &amp;= \\hphantom{-} \\frac{1 + \\phi}{4} \\frac             {(1 - \\beta)(2 - \\beta)}             {(2 + \\beta)(3 + \\beta)(4 + \\beta)(5 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {(1 - \\delta)(2 - \\delta)}             {(1 + \\delta)(2 + \\delta)(3 + \\delta)(4 + \\delta)(5 + \\delta)} \\end{align*} \\] <p>If \\( \\beta &gt; -2 \\) and \\( \\delta &gt; -2 \\):</p> \\[ \\begin{align*}     \\tlmoment{1}{1}         &amp;= -(1 + \\phi) \\frac             {5 + \\beta}             {(2 + \\beta)(3 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {5 + \\delta}             {(2 + \\delta)(3 + \\delta)}     \\\\     \\frac{2}{3 \\cdot 4} \\tlmoment{1}{2}         &amp;= \\hphantom{-} (1 + \\phi) \\frac             {1}             {(2 + \\beta)(3 + \\beta)(4 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {1}             {(2 + \\delta)(3 + \\delta)(4 + \\delta)}     \\\\     \\frac{3}{4 \\cdot 5} \\tlmoment{1}{3}         &amp;= -(1 + \\phi) \\frac             {(1 - \\beta)}             {(2 + \\beta)(3 + \\beta)(4 + \\beta)(5 + \\beta)}         &amp;&amp;+ (1 - \\phi)  \\frac             {(1 - \\delta)}             {(2 + \\delta)(3 + \\delta)(4 + \\delta)(5 + \\delta)}     \\\\     \\frac{4}{5 \\cdot 6} \\tlmoment{1}{4}         &amp;= \\hphantom{-} (1 + \\phi) \\frac             {(1 - \\beta)(2 - \\beta)}             {(2 + \\beta)(3 + \\beta)(4 + \\beta)(5 + \\beta)(6 + \\beta)}         &amp;&amp;+ (1 - \\phi) \\frac             {(1 - \\delta)(2 - \\delta)}             {(2 + \\delta)(3 + \\delta)(4 + \\delta)(5 + \\delta)(6 + \\delta)} \\end{align*} \\] <p>Special cases</p> <p>There are several notable special cases of the GLD:</p> GPD With \\( \\phi = -1 \\), GLD is GPD with shape \\( \\alpha \\equiv -\\delta \\) and scale \\( \\sigma = 2 \\). Lomax With \\( \\phi = -1 \\) and \\( \\delta &lt; 0 \\), GLD is the Lomax distribution with shape \\( \\alpha = -1 / \\delta \\) and scale \\( \\sigma = -2 / \\delta \\). Exponential With \\( \\beta = \\delta = 0 \\) and \\( \\phi = -1 \\), GLD is exponential with rate \\( \\lambda = \\frac 1 2 \\), or scale \\( \\sigma = 2 \\). Tukey-Lambda With \\( \\lambda \\equiv \\beta = \\delta \\) and \\( \\phi = 0 \\), GLD is the standard Tukey-lambda distribution, and \\( \\lambda \\) its shape parameter. Logistic With \\( \\beta = \\delta = 0 \\) and \\( \\phi = 0 \\), GLD is standard logistic. Uniform <p>With \\( \\beta = \\delta = 1 \\), GLD is uniform on \\( [-1 - \\phi,\\ 1 - \\phi] \\).</p> <p>With \\( \\beta = \\delta = 2 \\) and \\( \\phi = 0 \\) GLD is uniform on \\( \\left[-\\frac 1 2,\\ \\frac 1 2\\right] \\).</p> <p>With \\( \\delta = 1 \\) and \\( \\phi = -1 \\), GLD is uniform on \\( [0,\\ 2] \\)</p>"},{"location":"distributions/#constants-and-special-functions","title":"Constants and special functions","text":"<p>An overview of the (non-obvious) mathematical notation of special functions and constants.</p> Name Notation Definition Python Euler\u2013Mascheroni constant              \\( \\gamma_e \\) \\(                 \\displaystyle                 = \\lim_{x \\to 0}                     \\left( {1 \\over x} - \\Gamma(x) \\right) \\\\                 = \\int_1^\\infty                     \\left( {1 \\over \\lfloor x \\rfloor} - {1 \\over x} \\right)                     \\dd{x} \\\\                 \\approx 0.5772 \\vphantom{\\frac 1 1}             \\) <code>numpy.euler_gamma</code> Magic angle \\( \\theta_m \\) \\(                 = \\arctan \\sqrt 2 \\\\                 = \\arccos \\dfrac{1}{\\sqrt 3} \\\\                 \\approx 0.9553             \\) <code>lmo.constants.theta_m</code> Incomplete Gamma function              \\( \\Gamma_a(z) \\) \\(                 \\displaystyle                 = \\int_a^\\infty t^{z - 1} \\ e^{-t} \\dd{t}             \\) <code>lmo.special.gamma2</code> Gamma function \\( \\Gamma(z) \\) \\( = \\Gamma_0(z) \\) <code>math.gamma</code> <code>scipy.special.gamma</code> Digamma function             (a.k.a. \\( \\psi(z) \\ \\), yet             \u201cpsi\u201d \\( \\neq \\) \u201cdigamma\u201d)          \\( \\digamma(z) \\) \\(                 \\displaystyle                 = \\frac                     {\\Gamma^{\\prime}(z)}                     {\\Gamma(z)} \\\\                 = \\int_{\\lbrack 0, 1 \\rbrack}                     \\frac                         {1 - t^z}                         {1 - t^{\\hphantom{1}}}                     \\dd{t}                 - \\gamma_e             \\) <code>scipy.special.digamma</code> Beta function \\( \\B(x,\\ y) \\) \\(                 \\displaystyle                 = \\frac                     {\\Gamma(x) \\ \\Gamma(y)}                     {\\Gamma(x + y)} \\\\                 = \\int_{\\lbrack 0, 1 \\rbrack}                     t^{x - 1} \\ (1 - t)^{y - 1} \\dd{t}             \\) <code>scipy.special.beta</code> Riemann zeta function              \\( \\zeta(z) \\) \\(                 = \\displaystyle \\sum_{n = 1}^{\\infty} n^{-z}             \\) <code>scipy.special.zeta</code> Factorial \\( n! \\vphantom{\\prod_{k=1}^n k} \\) \\(                 = \\displaystyle \\prod_{k = 1}^n n \\\\                 = \\Gamma(n - 1)             \\) <code>math.factorial</code> <code>scipy.special.factorial</code> Falling factorial                          (a.k.a. the falling power)          \\( \\ffact{x}{n} \\) \\(                 \\displaystyle                 = \\frac{x!}{(x - n)!} \\\\                 = \\frac{\\Gamma(x + 1)}{\\Gamma(x - n + 1)} \\\\                 = \\rfact{x - n + 1}{n} \\\\             \\) <code>lmo.special.fpow</code> Rising factorial                           (a.k.a. the pochhammer symbol)          \\( \\rfact{x}{n} \\) \\(                 \\displaystyle                 = \\frac{\\Gamma(x + n)}{\\Gamma(x)} \\\\                 = \\frac{(x + n - 1)!}{(x - 1)!} \\\\                 = \\ffact{x + n - 1}{n}             \\) <code>scipy.special.poch</code> Binomial coefficient              \\( \\displaystyle \\binom n k \\) \\(                 \\displaystyle                 = \\frac{n!}{k! \\ (n - k)!} \\\\                 = \\frac{1}{k \\ \\B(k,\\ n - k + 1)}             \\) <code>math.comb</code> <code>scipy.special.comb</code> Harmonic number              \\( H_n \\) \\(                 = \\begin{cases}                     \\displaystyle \\sum_{k=1}^n \\frac 1 k                         &amp; \\text{if } n \\in \\naturals \\\\                     \\digamma(n + 1) + \\gamma_e                         &amp; \\text{otherwise}                 \\end{cases}             \\) <code>lmo.special.harmonic</code> Jacobi polynomial \\( \\jacobi{n}{\\alpha}{\\beta}{x} \\) \\(                 = \\displaystyle                 \\frac{1}{2^n}                 \\sum_{k=0}^n                     \\binom{n + \\alpha}{k}                     \\binom{n + \\beta}{n - k}                     (x + 1)^{n + k}                     (x - 1)^{n - k}             \\) <code>scipy.special.eval_jacobi</code> q-exponential \\( \\qexp{1 - q}{x} \\) \\(                 = \\begin{cases}                     e^x                         &amp; \\text{if } q = 0 \\\\                     (1 + q x)^{\\frac{1}{q}}     &amp; \\text{otherwise}                 \\end{cases}             \\) <code>scipy.special.inv_boxcox</code> q-logarithm             (a.k.a. the             Box-Cox transform)          \\( \\qlog{1 - q}{y} \\) \\(                 = \\begin{cases}                     \\ln y           &amp; \\text{if } q = 0 \\\\                     (y^q - 1) / q   &amp; \\text{otherwise}             \\end{cases}             \\) <code>scipy.special.boxcox</code> <ol> <li> <p>Jonathan RM Hosking. L-moments: analysis and estimation of distributions using linear combinations of order statistics. Journal of the Royal Statistical Society Series B: Statistical Methodology, 52(1):105\u2013124, 1990.\u00a0\u21a9</p> </li> <li> <p>James Victor Uspensky. Introduction to mathematical probability. 1937.\u00a0\u21a9</p> </li> <li> <p>Benjamin Gompertz. On the nature of the function expressive of the law of human mortality, and on a new mode of determining the value of life contingencies. in a letter to francis baily, esq. frs &amp;c. by benjamin gompertz, esq. fr s. In Abstracts of the Papers Printed in the Philosophical Transactions of the Royal Society of London, number 2, 252\u2013253. The Royal Society London, 1833.\u00a0\u21a9</p> </li> <li> <p>Arthur F Jenkinson. The frequency distribution of the annual maximum (or minimum) values of meteorological elements. Quarterly Journal of the Royal meteorological society, 81(348):158\u2013171, 1955.\u00a0\u21a9</p> </li> <li> <p>Jonathan RM Hosking. The theory of probability weighted moments. IBM Research Division, TJ Watson Research Center New York, USA, 1986. URL: https://dominoweb.draco.res.ibm.com/reports/RC12210.pdf.\u00a0\u21a9</p> </li> <li> <p>Jonathan RM Hosking and James R Wallis. Parameter and quantile estimation for the generalized pareto distribution. Technometrics, 29(3):339\u2013349, 1987.\u00a0\u21a9</p> </li> <li> <p>Irving W Burr. Cumulative frequency functions. The Annals of mathematical statistics, 13(2):215\u2013232, 1942.\u00a0\u21a9\u21a9</p> </li> <li> <p>Ponnambalam Kumaraswamy. A generalized probability density function for double-bounded random processes. Journal of hydrology, 46(1-2):79\u201388, 1980.\u00a0\u21a9</p> </li> <li> <p>MC Jones. Kumaraswamy\u2019s distribution: a beta-type distribution with some tractability advantages. Statistical methodology, 6(1):70\u201381, 2009.\u00a0\u21a9</p> </li> <li> <p>John C Houghton. Birth of a parent: the wakeby distribution for modeling flood flows. Water Resources Research, 14(6):1105\u20131109, 1978.\u00a0\u21a9</p> </li> <li> <p>John S Ramberg and Bruce W Schmeiser. An approximate method for generating asymmetric random variables. Communications of the ACM, 17(2):78\u201382, 1974.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/L-comoments/","title":"Sample L-comoments","text":"<p>Unbiased sample estimators of L-comoment matrices <sup>1</sup> and generalized trimmed L-comoment matrices <sup>[unpublished work by @jorenham]</sup>.</p>"},{"location":"api/L-comoments/#l-comoment-matrix-estimators","title":"L-comoment matrix estimators","text":""},{"location":"api/L-comoments/#lmo.l_comoment","title":"<code>lmo.l_comoment(a, r, /, trim=0, *, dtype=np.float64, rowvar=None, sort=None, cache=None)</code>","text":"<p>Multivariate extension of <code>lmo.l_moment</code>.</p> <p>Estimates the L-comoment matrix:</p> \\[ \\Lambda_{r}^{(s, t)} =     \\left[         \\lambda_{r [ij]}^{(s, t)}     \\right]_{m \\times m} \\] <p>Whereas the L-moments are calculated using the order statistics of the observations, i.e. by sorting, the L-comoment sorts \\(x_i\\) using the order of \\(x_j\\). This means that in general, \\(\\lambda_{r [ij]}^{(s, t)} \\neq \\lambda_{r [ji]}^{(s, t)}\\), i.e. \\(\\Lambda_{r}^{(s, t)}\\) is not symmetric.</p> <p>The \\(r\\)-th L-comoment \\(\\lambda_{r [ij]}^{(s, t)}\\) reduces to the L-moment if \\(i=j\\), and can therefore be seen as a generalization of the (univariate) L-moments. Similar to how the diagonal of a covariance matrix contains the variances, the diagonal of the L-comoment matrix contains the L-moments.</p> <p>Based on the proposed definition by Serfling &amp; Xiao (2007) for L-comoments. Extended to allow for generalized trimming.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>AnyVectorFloat | AnyMatrixFloat</code> <p>1-D or 2-D array-like containing <code>m</code> variables and <code>n</code> observations.  Each row of <code>a</code> represents a variable, and each column a single observation of all those variables. Also see <code>rowvar</code> below.  If <code>a</code> is not an array, a conversion is attempted.</p> required <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>The L-moment order(s), non-negative integer or array.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right-trim orders \\((s, t)\\), non-negative ints or floats that are bound by \\(s + t &lt; n - r\\).</p> <code>0</code> <code>rowvar</code> <code>bool | None</code> <p>If <code>True</code>, then each row (axis 0) represents a variable, with observations in the columns (axis 1). If <code>False</code>, the relationship is transposed: each column represents a variable, while the rows contain observations. If <code>None</code> (default), it is determined from the shape of <code>a</code>.</p> <code>None</code> <code>dtype</code> <code>_DType[_T_float]</code> <p>Floating type to use in computing the L-moments. Default is <code>numpy.float64</code>.</p> <code>float64</code> <code>sort</code> <code>'quick' | 'heap' | 'stable'</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <code>None</code> <code>cache</code> <code>bool | None</code> <p>Set to <code>True</code> to speed up future L-moment calculations that have the same number of observations in <code>a</code>, equal <code>trim</code>, and equal or smaller <code>r</code>. By default, it will cache i.f.f. the trim is integral, and \\(r + s + t \\le 24\\). Set to <code>False</code> to always disable caching.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>L</code> <code>Array[Any, _T_float]</code> <p>Array of shape <code>(*r.shape, m, m)</code> with r-th L-comoments.</p> <p>Examples:</p> <p>Estimation of the second L-comoment (the L-coscale) from biviariate normal samples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99)\n&gt;&gt;&gt; lmo.l_comoment(x, 2)\narray([[ 1.2766793 , -0.83299947],\n       [-0.71547941,  1.05990727]])\n</code></pre> <p>The diagonal contains the univariate L-moments:</p> <pre><code>&gt;&gt;&gt; lmo.l_moment(x, 2, axis=0)\narray([1.2766793 , 1.05990727])\n</code></pre> <p>The orientation (<code>rowvar</code>) is automatically determined, unless explicitly specified.</p> <pre><code>&gt;&gt;&gt; lmo.l_comoment(x, 2).shape\n(2, 2)\n&gt;&gt;&gt; lmo.l_comoment(x.T, 2).shape\n(2, 2)\n&gt;&gt;&gt; lmo.l_comoment(x, 2, rowvar=False).shape\n(2, 2)\n&gt;&gt;&gt; lmo.l_comoment(x.T, 2, rowvar=True).shape\n(2, 2)\n</code></pre> References <ul> <li>R. Serfling &amp; P. Xiao (2007) - A Contribution to Multivariate   L-Moments: L-Comoment Matrices</li> </ul>"},{"location":"api/L-comoments/#lmo.l_coratio","title":"<code>lmo.l_coratio(a, r, s, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>Estimate the generalized matrix of L-comoment ratio\u2019s.</p> \\[ \\tilde \\Lambda_{rk}^{(s, t)} =     \\left[         \\left. \\lambda_{r [ij]}^{(s, t)} \\right/         \\lambda_{k [ii]}^{(s, t)}     \\right]_{m \\times m} \\] See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/L-comoments/#lmo.l_costats","title":"<code>lmo.l_costats(a, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>Calculates the L-coscale, L-corr(elation), L-coskew(ness) and L-cokurt(osis).</p> <p>Equivalent to <code>lmo.l_coratio(a, [2, 2, 3, 4], [0, 2, 2, 2], *, **)</code>.</p> See Also <ul> <li><code>lmo.l_stats</code></li> <li><code>lmo.l_coratio</code></li> </ul>"},{"location":"api/L-comoments/#shorthand-aliases","title":"Shorthand aliases","text":""},{"location":"api/L-comoments/#lmo.l_coloc","title":"<code>lmo.l_coloc(a, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>L-colocation matrix of 1st L-comoment estimates, \\(\\Lambda^{(s, t)}_1\\).</p> <p>Alias for <code>lmo.l_comoment(a, 1, *, **)</code>.</p> Notes <p>If <code>trim = (0, 0)</code> (default), the L-colocation for \\([ij]\\) is the L-location \\(\\lambda_1\\) of \\(x_i\\), independent of \\(x_j\\).</p> <p>Examples:</p> <p>Without trimming, the L-colocation only provides marginal information:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_loc(x, axis=-1)\narray([-0.02678225,  0.03008309])\n&gt;&gt;&gt; lmo.l_coloc(x)\narray([[-0.02678225, -0.02678225],\n       [ 0.03008309,  0.03008309]])\n</code></pre> <p>But the trimmed L-locations are a different story\u2026</p> <pre><code>&gt;&gt;&gt; lmo.l_loc(x, trim=(1, 1), axis=-1)\narray([-0.10488868, -0.00625729])\n&gt;&gt;&gt; lmo.l_coloc(x, trim=(1, 1))\narray([[-0.10488868, -0.03797989],\n       [ 0.03325074, -0.00625729]])\n</code></pre> <p>What this tells us, is somewhat of a mystery: trimmed L-comoments have been only been briefly mentioned once or twice in the literature.</p> See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_loc</code></li> <li><code>numpy.mean</code></li> </ul>"},{"location":"api/L-comoments/#lmo.l_coscale","title":"<code>lmo.l_coscale(a, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>L-coscale matrix of 2nd L-comoment estimates, \\(\\Lambda^{(s, t)}_2\\).</p> <p>Alias for <code>lmo.l_comoment(a, 2, *, **)</code>.</p> <p>Analogous to the (auto-) variance-covariance matrix, the L-coscale matrix is positive semi-definite, and its main diagonal contains the L-scale\u2019s. conversely, the L-coscale matrix is inherently asymmetric, thus yielding more information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_scale(x, trim=(1, 1), axis=-1)\narray([0.66698774, 0.54440895])\n&gt;&gt;&gt; lmo.l_coscale(x, trim=(1, 1))\narray([[ 0.66698774, -0.41025416],\n       [-0.37918065,  0.54440895]])\n</code></pre> See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_scale</code></li> <li><code>numpy.cov</code></li> </ul>"},{"location":"api/L-comoments/#lmo.l_corr","title":"<code>lmo.l_corr(a, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>Sample L-correlation coefficient matrix \\(\\tilde\\Lambda^{(s, t)}_2\\); the ratio of the L-coscale matrix over the L-scale column-vectors.</p> <p>Alias for <code>lmo.l_coratio(a, 2, 2, *, **)</code>.</p> <p>The diagonal consists of all 1\u2019s.</p> <p>Where the pearson correlation coefficient measures linearity, the (T)L-correlation coefficient measures monotonicity.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; cov = np.array([[6, -3], [-3, 3.5]])\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_corr(x)\narray([[ 1.        , -0.65247355],\n       [-0.67503962,  1.        ]])\n</code></pre> <p>Let\u2019s compare this with the theoretical correlation</p> <pre><code>&gt;&gt;&gt; cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n-0.6546536707079772\n</code></pre> <p>and the (Pearson) correlation coefficient matrix:</p> <pre><code>&gt;&gt;&gt; np.corrcoef(x)\narray([[ 1.        , -0.66383285],\n       [-0.66383285,  1.        ]])\n</code></pre> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>numpy.corrcoef</code></li> </ul>"},{"location":"api/L-comoments/#lmo.l_coskew","title":"<code>lmo.l_coskew(a, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>Sample L-coskewness coefficient matrix \\(\\tilde\\Lambda^{(s, t)}_3\\).</p> <p>Alias for <code>lmo.l_coratio(a, 3, 2, *, **)</code>.</p> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>lmo.l_skew</code></li> </ul>"},{"location":"api/L-comoments/#lmo.l_cokurt","title":"<code>lmo.l_cokurt = l_cokurtosis</code>  <code>module-attribute</code>","text":"<p>Alias for <code>lmo.l_cokurtosis</code>.</p>"},{"location":"api/L-comoments/#lmo.l_cokurtosis","title":"<code>lmo.l_cokurtosis(a, /, trim=0, *, dtype=np.float64, **kwds)</code>","text":"<p>Sample L-cokurtosis coefficient matrix \\(\\tilde\\Lambda^{(s, t)}_4\\).</p> <p>Alias for <code>lmo.l_coratio(a, 4, 2, *, **)</code>.</p> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>lmo.l_kurtosis</code></li> </ul>"},{"location":"api/L-comoments/#references","title":"References","text":"<ol> <li> <p>Robert Serfling and Peng Xiao. A contribution to multivariate l-moments: l-comoment matrices. Journal of Multivariate Analysis, 98(9):1765\u20131781, 2007.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/L-moments/","title":"Sample L-moments","text":"<p>Estimation of (trimmed) L-moments from sample data.</p>"},{"location":"api/L-moments/#l-moment-estimators","title":"L-moment Estimators","text":"<p>Unbiased sample estimators of the L-moments and the (generalized) trimmed L-moments.</p>"},{"location":"api/L-moments/#lmo.l_moment","title":"<code>lmo.l_moment(a, r, /, trim=0, *, axis=None, dtype=np.float64, fweights=None, aweights=None, sort=True, cache=None)</code>","text":"<pre><code>l_moment(\n    a: lnpt.AnyArrayFloat,\n    r: AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_moment(\n    a: lnpt.AnyMatrixFloat | lnpt.AnyTensorFloat,\n    r: AnyOrder | AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre><pre><code>l_moment(\n    a: lnpt.AnyVectorFloat,\n    r: AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_moment(\n    a: lnpt.AnyArrayFloat,\n    r: AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int | None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre> <p>Estimates the generalized trimmed L-moment \\(\\lambda^{(s, t)}_r\\) from the samples along the specified axis. By default, this will be the regular L-moment, \\(\\lambda_r = \\lambda^{(0, 0)}_r\\).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>AnyArrayFloat</code> <p>Array containing numbers whose L-moments is desired. If <code>a</code> is not an array, a conversion is attempted.</p> required <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>The L-moment order(s), non-negative integer or array.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right-trim orders \\((s, t)\\), non-negative ints or floats that are bound by \\(s + t &lt; n - r\\). A single scalar \\(t\\) can be proivided as well, as alias for \\((t, t)\\).</p> <p>Some special cases include:</p> <ul> <li>\\((0, 0)\\) or \\((0)\\): The original L-moment, introduced by     Hosking in 1990.</li> <li>\\((t, t)\\) or \\((t)\\): TL-moment (Trimmed L-moment)     \\(\\lambda_r^{(t)}\\), with symmetric trimming. First introduced by     Elamir &amp; Seheult in 2003, and refined by Hosking in 2007.     Generally more robust than L-moments. Useful for fitting     pathological distributions, such as the Cauchy distribution.</li> <li>\\((0, t)\\): LL-moment (Linear combination of Lowest     order statistics), introduced by Bayazit &amp; Onoz in 2002.     Assigns more weight to smaller observations.</li> <li>\\((s, 0)\\): LH-moment (Linear combination of Higher     order statistics), as described by Wang in 1997.     Assigns more weight to larger observations.</li> </ul> <code>0</code> <code>axis</code> <code>int | None</code> <p>Axis along which to calculate the moments. If <code>None</code> (default), all samples in the array will be used.</p> <code>None</code> <code>dtype</code> <code>_DType[_SCT_f]</code> <p>Floating type to use in computing the L-moments. Default is <code>numpy.float64</code>.</p> <code>float64</code> <code>fweights</code> <code>AnyFWeights | None</code> <p>1-D array of integer frequency weights; the number of times each observation vector should be repeated.</p> <code>None</code> <code>aweights</code> <code>AnyAWeights | None</code> <p>An array of weights associated with the values in <code>a</code>. Each value in <code>a</code> contributes to the average according to its associated weight. The weights array can either be 1-D (in which case its length must be the size of a along the given axis) or of the same shape as <code>a</code>. If <code>aweights=None</code> (default), then all data in <code>a</code> are assumed to have a weight equal to one.</p> <p>All <code>aweights</code> must be <code>&gt;=0</code>, and the sum must be nonzero.</p> <p>The algorithm is similar to that for weighted quantiles.</p> <code>None</code> <code>sort</code> <code>True | False | 'quick' | 'heap' | 'stable'</code> <p>Sorting algorithm, see <code>numpy.sort</code>. Set to <code>False</code> if the array is already sorted.</p> <code>True</code> <code>cache</code> <code>bool | None</code> <p>Set to <code>True</code> to speed up future L-moment calculations that have the same number of observations in <code>a</code>, equal <code>trim</code>, and equal or smaller <code>r</code>. By default, it will cache i.f.f. the trim is integral, and \\(r + s + t \\le 24\\). Set to <code>False</code> to always disable caching.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>l</code> <code>_Vectorized[_SCT_f]</code> <p>The L-moment(s) of the input This is a scalar iff a is 1-d and r is a scalar. Otherwise, this is an array with <code>np.ndim(r) + np.ndim(a) - 1</code> dimensions and shape like <code>(*np.shape(r), *(d for d in np.shape(a) if d != axis))</code>.</p> <p>Examples:</p> <p>Calculate the L-location and L-scale from student-T(2) samples, for different (symmetric) trim-lengths.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_t(2, 99)\n</code></pre> <pre><code>&gt;&gt;&gt; lmo.l_moment(x, [1, 2])\narray([-0.01412282,  0.94063132])\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=1)\narray([-0.0124483 ,  0.40120115])\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1, 1))\narray([-0.0124483 ,  0.40120115])\n</code></pre> <p>The theoretical L- and TL-location is <code>0</code>, the L-scale is <code>1.1107</code>, and the TL-scale is <code>0.4165</code>, respectively.</p> See Also <ul> <li>L-moment - Wikipedia</li> <li><code>scipy.stats.moment</code></li> </ul> References <ul> <li>J.R.M. Hosking (1990)</li> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/L-moments/#lmo.l_ratio","title":"<code>lmo.l_ratio(a, r, s, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<pre><code>l_ratio(\n    a: lnpt.AnyVectorFloat,\n    r: AnyOrder,\n    s: AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int | None,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_ratio(\n    a: lnpt.AnyMatrixFloat | lnpt.AnyTensorFloat,\n    r: AnyOrder,\n    s: AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre><pre><code>l_ratio(\n    a: lnpt.AnyArrayFloat,\n    r: AnyOrder,\n    s: AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_ratio(\n    a: lnpt.AnyArrayFloat,\n    r: AnyOrder,\n    s: AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int | None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre><pre><code>l_ratio(\n    a: lnpt.AnyArrayFloat,\n    r: AnyOrderND,\n    s: AnyOrder | AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int | None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre> <p>Estimates the generalized L-moment ratio.</p> \\[ \\tau^{(s, t)}_{rs} = \\frac     {\\lambda^{(s, t)}_r}     {\\lambda^{(s, t)}_s} \\] <p>Equivalent to <code>lmo.l_moment(a, r, *, **) / lmo.l_moment(a, s, *, **)</code>.</p> <p>The L-moment with <code>r=0</code> is <code>1</code>, so the <code>l_ratio(a, r, 0, *, **)</code> is equivalent to <code>l_moment(a, r, *, **)</code>.</p> Notes <p>Often, when referring to the \\(r\\)th L-ratio, the L-moment ratio with \\(k=2\\) is implied, i.e. \\(\\tau^{(s, t)}_r\\) is short-hand notation for \\(\\tau^{(s, t)}_{r,2}\\).</p> <p>The L-variation (L-moment Coefficient of Variation, or L-CB) is another special case of the L-moment ratio, \\(\\tau^{(s, t)}_{2,1}\\). It is sometimes denoted in the literature by dropping the subscript indices: \\(\\tau^{(s, t)}\\). Note that this should only be used with strictly positive distributions.</p> <p>Examples:</p> <p>Estimate the L-location, L-scale, L-skewness and L-kurtosis simultaneously:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.lognormal(size=99)\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2])\narray([1.53196368, 0.77549561, 0.4463163 , 0.29752178])\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(0, 1))\narray([0.75646807, 0.32203446, 0.23887609, 0.07917904])\n</code></pre> See Also <ul> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"api/L-moments/#lmo.l_stats","title":"<code>lmo.l_stats(a, /, trim=0, num=4, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<p>Calculates the L-loc(ation), L-scale, L-skew(ness) and L-kurtosis.</p> <p>Equivalent to <code>lmo.l_ratio(a, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code> by default.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, scipy.stats\n&gt;&gt;&gt; x = scipy.stats.gumbel_r.rvs(size=99, random_state=12345)\n&gt;&gt;&gt; lmo.l_stats(x)\narray([0.79014773, 0.68346357, 0.12207413, 0.12829047])\n</code></pre> <p>The theoretical L-stats of the standard Gumbel distribution are <code>[0.577, 0.693, 0.170, 0.150]</code>.</p> See Also <ul> <li><code>lmo.l_stats_se</code></li> <li><code>lmo.l_ratio</code></li> <li><code>lmo.l_costats</code></li> </ul>"},{"location":"api/L-moments/#shorthand-aliases","title":"Shorthand aliases","text":"<p>Some of the commonly used L-moment and L-moment ratio\u2019s have specific names, analogous to the named raw-, central-, and standard product-moments:</p> \\(\\lambda_r / \\lambda_s\\) \\(s = 0\\) \\(r = 2\\) \\(r=1\\) \\(\\lambda_1\\) \u2013 \u201cL-loc[ation]\u201d \\(\\tau\\) \u2013 \u201cL-variation\u201d or \u201cL-CV\u201d \\(r=2\\) \\(\\lambda_2\\) \u2013 \u201cL-scale\u201d \\(1\\) \u2013 \u201cL-one\u201d or \u201cL-unit\u201d \\(r=3\\) \\(\\lambda_3\\) \\(\\tau_3\\) \u2013 \u201cL-skew[ness]\u201d \\(r=4\\) \\(\\lambda_4\\) \\(\\tau_4\\) \u2013 \u201cL-kurt[osis]\u201d <p>Note</p> <p>The \u201cL-\u201d prefix often refers to untrimmed L-moments, i.e. \\((s, t) = (0, 0)\\).</p> <p>For some of the trimmed L-moments trim-lengths, specific alternative prefixes are used:</p> \\(\\lambda_r^{(s, t)}\\) \\(t = 0\\) \\(t = 1\\) \\(s = 0\\) L-moment LL-moment \\(s = 1\\) LH-moment TL-moment <p>The \u201cL-\u201d prefix refers to \u201cLinear\u201d, i.e. an L-moment is a \u201cLinear combination of order statistics\u201d <sup>1</sup>. Usually \u201cTL-moments\u201d are used to describe symmetrically Trimmed L-moments, in most cases those with a trim-length of 1 <sup>2</sup><sup>3</sup>. Similarly, \u201cLH-moments\u201d describe \u201clinear combinations of order of higher-order statistics\u201d <sup>4</sup>, and \u201cLL-moments\u201d that of \u201c\u2026 the lowest order statistics\u201d <sup>5</sup>.</p> <p>Lmo supports all possible trim-lengths. Technically, these are the \u201cgeneralized trimmed L-moments\u201d. But for the sake of brevity Lmo abbreviates this \u201cL-moments\u201d.</p>"},{"location":"api/L-moments/#lmo.l_loc","title":"<code>lmo.l_loc(a, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<pre><code>l_loc(\n    a: lnpt.AnyMatrixFloat | lnpt.AnyTensorFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre><pre><code>l_loc(\n    a: lnpt.AnyVectorFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_loc(\n    a: lnpt.AnyArrayFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre> <p>L-location (or L-loc): unbiased estimator of the first L-moment, \\(\\lambda^{(s, t)}_1\\).</p> <p>Alias for <code>lmo.l_moment(a, 1, *, **)</code>.</p> <p>Examples:</p> <p>The first moment (i.e. the mean) of the Cauchy distribution does not exist. This means that estimating the location of a Cauchy distribution from its samples, cannot be done using the traditional average (i.e. the arithmetic mean). Instead, a robust location measure should be used, e.g. the median, or the TL-location.</p> <p>To illustrate, let\u2019s start by drawing some samples from the standard Cauchy distribution, which is centered around the origin.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(200)\n</code></pre> <p>The mean and the untrimmed L-location (which are equivalent) give wrong results, so don\u2019t do this:</p> <pre><code>&gt;&gt;&gt; np.mean(x)\n-3.6805\n&gt;&gt;&gt; lmo.l_loc(x)\n-3.6805\n</code></pre> <p>Usually, the answer to this problem is to use the median. However, the median only considers one or two samples (depending on whether the amount of samples is odd or even, respectively). So the median ignores most of the available information.</p> <pre><code>&gt;&gt;&gt; np.median(x)\n0.096825\n&gt;&gt;&gt; lmo.l_loc(x, trim=(len(x) - 1) // 2)\n0.096825\n</code></pre> <p>Luckily for us, Lmo knows how to deal with longs tails, as well \u2013 trimming them (specifically, by skipping the first \\(s\\) and last \\(t\\) expected order statistics).</p> <p>Let\u2019s try the TL-location (which is equivalent to the median)</p> <pre><code>&gt;&gt;&gt; lmo.l_loc(x, trim=1)  # equivalent to `trim=(1, 1)`\n0.06522\n</code></pre> Notes <p>The trimmed L-location naturally unifies the arithmetic mean, the median, the minimum and the maximum. In particular, the following are equivalent, given <code>n = len(x)</code>:</p> <ul> <li><code>l_loc(x, trim=0)</code> / <code>statistics.mean(x)</code> / <code>np.mean(x)</code></li> <li><code>l_loc(x, trim=(n-1) // 2)</code> / <code>statistics.median(x)</code> / <code>np.median(x)</code></li> <li><code>l_loc(x, trim=(0, n-1))</code> / <code>min(x)</code> / <code>np.min(x)</code></li> <li><code>l_loc(x, trim=(n-1, 0))</code> / <code>max(x)</code> / <code>np.max(x)</code></li> </ul> <p>Note that numerical noise might cause slight differences between their results.</p> <p>Even though <code>lmo</code> is built with performance in mind, the equivalent <code>numpy</code> functions are always faster, as they don\u2019t need to sort all samples. Specifically, the time complexity of <code>lmo.l_loc</code> (and <code>l_moment</code> in general) is \\(O(n \\log n)\\), whereas that of <code>numpy.{mean,median,min,max}</code> is <code>O(n)</code></p> See Also <ul> <li><code>lmo.l_moment</code></li> <li><code>numpy.average</code></li> </ul>"},{"location":"api/L-moments/#lmo.l_scale","title":"<code>lmo.l_scale(a, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<pre><code>l_scale(\n    a: lnpt.AnyMatrixFloat | lnpt.AnyTensorFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre><pre><code>l_scale(\n    a: lnpt.AnyVectorFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_scale(\n    a: lnpt.AnyArrayFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre> <p>L-scale unbiased estimator for the second L-moment, \\(\\lambda^{(s, t)}_2\\).</p> <p>Alias for <code>lmo.l_moment(a, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_cauchy(99)\n&gt;&gt;&gt; x.std()\n72.87715244\n&gt;&gt;&gt; lmo.l_scale(x)\n9.501123995\n&gt;&gt;&gt; lmo.l_scale(x, trim=(1, 1))\n0.658993279\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), the L-scale is equivalent to half the Gini mean difference (GMD).</p> See Also <ul> <li><code>lmo.l_moment</code></li> <li><code>numpy.std</code></li> </ul>"},{"location":"api/L-moments/#lmo.l_variation","title":"<code>lmo.l_variation(a, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<pre><code>l_variation(\n    a: lnpt.AnyMatrixFloat | lnpt.AnyTensorFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; onpt.Array[Any, _SCT_f]\n</code></pre><pre><code>l_variation(\n    a: lnpt.AnyVectorFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: int,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre><pre><code>l_variation(\n    a: lnpt.AnyArrayFloat,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    axis: None = ...,\n    dtype: _DType[_SCT_f] = np.float64,\n    **kwds: Unpack[lmt.LMomentOptions],\n) -&gt; _SCT_f\n</code></pre> <p>The coefficient of L-variation (or L-CV) unbiased sample estimator:</p> \\[ \\tau^{(s, t)} = \\frac     {\\lambda^{(s, t)}_2}     {\\lambda^{(s, t)}_1} \\] <p>Alias for <code>lmo.l_ratio(a, 2, 1, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).pareto(4.2, 99)\n&gt;&gt;&gt; x.std() / x.mean()\n1.32161112\n&gt;&gt;&gt; lmo.l_variation(x)\n0.59073639\n&gt;&gt;&gt; lmo.l_variation(x, trim=(0, 1))\n0.55395044\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), this is equivalent to the Gini coefficient, and lies within the interval \\((0, 1)\\).</p> See Also <ul> <li>Gini coefficient - Wikipedia</li> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.variation.l_ratio</code></li> </ul>"},{"location":"api/L-moments/#lmo.l_skew","title":"<code>lmo.l_skew(a, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<p>Unbiased sample estimator for the L-skewness coefficient.</p> \\[ \\tau^{(s, t)}_3 = \\frac     {\\lambda^{(s, t)}_3}     {\\lambda^{(s, t)}_2} \\] <p>Alias for <code>lmo.l_ratio(a, 3, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_exponential(99)\n&gt;&gt;&gt; lmo.l_skew(x)\n0.38524343\n&gt;&gt;&gt; lmo.l_skew(x, trim=(0, 1))\n0.27116139\n</code></pre> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.skew</code></li> </ul>"},{"location":"api/L-moments/#lmo.l_kurt","title":"<code>lmo.l_kurt = l_kurtosis</code>  <code>module-attribute</code>","text":"<p>Alias for <code>lmo.l_kurtosis</code>.</p>"},{"location":"api/L-moments/#lmo.l_kurtosis","title":"<code>lmo.l_kurtosis(a, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<p>L-kurtosis coefficient; the 4th sample L-moment ratio.</p> \\[ \\tau^{(s, t)}_4 = \\frac     {\\lambda^{(s, t)}_4}     {\\lambda^{(s, t)}_2} \\] <p>Alias for <code>lmo.l_ratio(a, 4, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_t(2, 99)\n&gt;&gt;&gt; lmo.l_kurtosis(x)\n0.28912787\n&gt;&gt;&gt; lmo.l_kurtosis(x, trim=(1, 1))\n0.19928182\n</code></pre> Notes <p>The L-kurtosis \\(\\tau_4\\) lies within the interval \\([-\\frac{1}{4}, 1)\\), and by the L-skewness \\(\\\\tau_3\\) as \\(5 \\tau_3^2 - 1 \\le 4 \\tau_4\\).</p> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.kurtosis</code></li> </ul>"},{"location":"api/L-moments/#l-moment-accuracy","title":"L-moment Accuracy","text":""},{"location":"api/L-moments/#lmo.l_moment_cov","title":"<code>lmo.l_moment_cov(a, r_max, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<p>Non-parmateric auto-covariance matrix of the generalized trimmed L-moment point estimates with orders <code>r = 1, ..., r_max</code>.</p> <p>Returns:</p> Name Type Description <code>S_l</code> <code>NDArray[_SCT_f]</code> <p>Variance-covariance matrix/tensor of shape <code>(r_max, r_max, ...)</code></p> <p>Examples:</p> <p>Fitting of the cauchy distribution with TL-moments. The location is equal to the TL-location, and scale should be \\(0.698\\) times the TL(1)-scale, see Elamir &amp; Seheult (2003).</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(1337)\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1, 1))\narray([0.08142405, 0.68884917])\n</code></pre> <p>The L-moment estimates seem to make sense. Let\u2019s check their standard errors, by taking the square root of the variances (the diagonal of the covariance matrix):</p> <pre><code>&gt;&gt;&gt; lmo.l_moment_cov(x, 2, trim=(1, 1))\narray([[ 4.89407076e-03, -4.26419310e-05],\n       [-4.26419310e-05,  1.30898414e-03]])\n&gt;&gt;&gt; np.sqrt(_.diagonal())\narray([0.06995764, 0.03617989])\n</code></pre> See Also <ul> <li><code>lmo.l_moment</code></li> <li>Covariance matrix - Wikipedia</li> </ul> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>E. Elamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul> Todo <ul> <li>Use the direct (Jacobi) method from Hosking (2015).</li> </ul>"},{"location":"api/L-moments/#lmo.l_ratio_se","title":"<code>lmo.l_ratio_se(a, r, s, /, trim=0, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<p>Non-parametric estimates of the Standard Error (SE) in the L-ratio estimates from <code>lmo.l_ratio</code>.</p> <p>Examples:</p> <p>Estimate the values and errors of the TL-loc, scale, skew and kurtosis for Cauchy-distributed samples. The theoretical values are <code>[0.0, 0.698, 0.0, 0.343]</code> (Elamir &amp; Seheult, 2003), respectively.</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(42)\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(1, 1))\narray([-0.25830513,  0.61738638, -0.03069701,  0.25550176])\n&gt;&gt;&gt; lmo.l_ratio_se(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(1, 1))\narray([0.32857302, 0.12896501, 0.13835403, 0.07188138])\n</code></pre> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>lmo.l_moment_cov</code></li> <li>Propagation of uncertainty</li> </ul> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>E. Elamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul>"},{"location":"api/L-moments/#lmo.l_stats_se","title":"<code>lmo.l_stats_se(a, /, trim=0, num=4, *, axis=None, dtype=np.float64, **kwds)</code>","text":"<p>Calculates the standard errors (SE\u2019s) of the <code>L-stats</code>.</p> <p>Equivalent to <code>lmo.l_ratio_se(a, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code> by default.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, scipy.stats\n&gt;&gt;&gt; x = scipy.stats.gumbel_r.rvs(size=99, random_state=12345)\n&gt;&gt;&gt; lmo.l_stats(x)\narray([0.79014773, 0.68346357, 0.12207413, 0.12829047])\n&gt;&gt;&gt; lmo.l_stats_se(x)\narray([0.12305147, 0.05348839, 0.04472984, 0.03408495])\n</code></pre> <p>The theoretical L-stats of the standard Gumbel distribution are <code>[0.577, 0.693, 0.170, 0.150]</code>. The corresponding relative z-scores are <code>[-1.730, 0.181, 1.070, 0.648]</code>.</p> See Also <ul> <li><code>lmo.l_stats</code></li> <li><code>lmo.l_ratio_se</code></li> </ul>"},{"location":"api/L-moments/#sensitivity-robustness","title":"Sensitivity &amp; Robustness","text":"<p>Wikipedia describes the empirical influence function (EIF) as follows:</p> <p>The empirical influence function is a measure of the dependence of the estimator on the value of any one of the points in the sample. It is a model-free measure in the sense that it simply relies on calculating the estimator again with a different sample.</p> <p>Tip</p> <p>The EIF can be used to calculate some useful properties related to the robustness of the estimate.</p> <ul> <li><code>lmo.diagnostic.rejection_point</code></li> <li><code>lmo.diagnostic.error_sensitivity</code></li> <li><code>lmo.diagnostic.shift_sensitivity</code></li> </ul>"},{"location":"api/L-moments/#lmo.l_moment_influence","title":"<code>lmo.l_moment_influence(a, r, /, trim=0, *, sort=True, tol=1e-08)</code>","text":"<p>Calculate the Empirical Influence Function (EIF) for a sample L-moment estimate.</p> Notes <p>This function is not vectorized, and can only be used for a single L-moment order <code>r</code>. However, the returned (empirical influence) function is vectorized.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>AnyVectorFloat</code> <p>1-D array-like containing observed samples.</p> required <code>r</code> <code>AnyOrder</code> <p>L-moment order. Must be a non-negative integer.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int (or float).</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>sort</code> <code>True | False | 'quick' | 'heap' | 'stable'</code> <p>Sorting algorithm, see <code>numpy.sort</code>. Set to <code>False</code> if the array is already sorted.</p> <code>tol</code> <code>float</code> <p>Zero-roundoff absolute threshold.</p> <p>Returns:</p> Name Type Description <code>influence_function</code> <code>Callable[[_T_x], _T_x]</code> <p>The (vectorized) empirical influence function.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>a</code> is not 1-D array-like.</p> <code>TypeError</code> <p>If <code>a</code> is not a floating-point type.</p>"},{"location":"api/L-moments/#lmo.l_ratio_influence","title":"<code>lmo.l_ratio_influence(a, r, s=2, /, trim=0, *, sort=True, tol=1e-08)</code>","text":"<p>Calculate the Empirical Influence Function (EIF) for a sample L-moment ratio estimate.</p> Notes <p>This function is not vectorized, and can only be used for a single L-moment order <code>r</code>. However, the returned (empirical influence) function is vectorized.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>AnyVectorFloat</code> <p>1-D array-like containing observed samples.</p> required <code>r</code> <code>AnyOrder</code> <p>L-moment ratio order. Must be a non-negative integer.</p> required <code>s</code> <code>AnyOrder</code> <p>Denominator L-moment order, defaults to 2.</p> <code>2</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>sort</code> <code>True | False | 'quick' | 'heap' | 'stable'</code> <p>Sorting algorithm, see <code>numpy.sort</code>. Set to <code>False</code> if the array is already sorted.</p> <code>tol</code> <code>float</code> <p>Zero-roundoff absolute threshold.</p> <p>Returns:</p> Name Type Description <code>influence_function</code> <code>Callable[[_T_x], _T_x]</code> <p>The (vectorized) empirical influence function.</p>"},{"location":"api/L-moments/#l-moment-sample-weights","title":"L-moment sample weights","text":""},{"location":"api/L-moments/#lmo.l_weights","title":"<code>lmo.l_weights(r_max, n, /, trim=0, *, dtype=np.float64, cache=None)</code>","text":"<p>Projection matrix of the first \\(r\\) (T)L-moments for \\(n\\) samples.</p> <p>For integer trim is the matrix is a linear combination of the Power Weighted Moment (PWM) weights (the sample estimator of \\(\\beta_{r_1}\\)), and the shifted Legendre polynomials.</p> <p>If the trimmings are nonzero and integers, a linearized (and corrected) adaptation of the recurrence relations from Hosking (2007) are applied, as well.</p> \\[ (2k + s + t - 1) \\lambda^{(s, t)}_k     = (k + s + t) \\lambda^{(s - 1, t)}_k     + \\frac{1}{k} (k + 1) (k + t) \\lambda^{(s - 1, t)}_{k+1} \\] <p>for \\(s &gt; 0\\), and</p> \\[ (2k + s + t - 1) \\lambda^{(s, t)}_k     = (k + s + t) \\lambda^{(s, t - 1)}_k     - \\frac{1}{k} (k + 1) (k + s) \\lambda^{(s, t - 1)}_{k+1} \\] <p>for \\(t &gt; 0\\).</p> <p>If the trim values are floats instead, the weights are calculated directly from the (generalized) order statistics. At the time of writing (07-2023), these \u201cgeneralized trimmed L-moments\u201d have not been discussed in the literature or the R-packages. It\u2019s probably a good idea to publish this\u2026</p> TLDR <p>This matrix (linearly) transforms \\(x_{i:n}\\) (i.e. the sorted observation vector(s) of size \\(n\\)), into (an unbiased estimate of) the generalized trimmed L-moments, with orders \\(\\le r\\).</p> <p>Parameters:</p> Name Type Description Default <code>r_max</code> <code>_OrderT</code> <p>The amount L-moment orders.</p> required <code>n</code> <code>_SizeT</code> <p>The number of samples.</p> required <code>trim</code> <code>AnyTrim</code> <p>A scalar or 2-tuple with the trim orders. Defaults to 0.</p> <code>0</code> <code>dtype</code> <code>_DType[_SCT_f]</code> <p>The datatype of the returned weight matrix.</p> <code>float64</code> <code>cache</code> <code>bool | None</code> <p>Whether to cache the weights. By default, it\u2019s enabled i.f.f the trim values are integers, and <code>r_max + sum(trim) &lt; 24</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>P_r</code> <code>Array[tuple[_OrderT, _SizeT], _SCT_f]</code> <p>2-D array of shape <code>(r_max, n)</code>, readonly if <code>cache=True</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; lmo.l_weights(3, 4)\narray([[ 0.25      ,  0.25      ,  0.25      ,  0.25      ],\n       [-0.25      , -0.08333333,  0.08333333,  0.25      ],\n       [ 0.25      , -0.25      , -0.25      ,  0.25      ]])\n&gt;&gt;&gt; _ @ [-1, 0, 1 / 2, 3 / 2]\narray([0.25      , 0.66666667, 0.        ])\n</code></pre> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/L-moments/#references","title":"References","text":"<ol> <li> <p>Jonathan RM Hosking. L-moments: analysis and estimation of distributions using linear combinations of order statistics. Journal of the Royal Statistical Society Series B: Statistical Methodology, 52(1):105\u2013124, 1990.\u00a0\u21a9</p> </li> <li> <p>Elsayed AH Elamir and Allan H Seheult. Trimmed l-moments. Computational Statistics &amp; Data Analysis, 43(3):299\u2013314, 2003.\u00a0\u21a9</p> </li> <li> <p>JRM Hosking. Some theory and practical uses of trimmed l-moments. Journal of Statistical Planning and Inference, 137(9):3024\u20133039, 2007.\u00a0\u21a9</p> </li> <li> <p>Qi J Wang. Lh moments for statistical analysis of extreme events. Water Resources Research, 33(12):2841\u20132848, 1997.\u00a0\u21a9</p> </li> <li> <p>Mehmetcik Bayazit and Bihrat \u00d6n\u00f6z. Ll-moments for estimating low flow quantiles. Hydrological sciences journal, 47(5):707\u2013720, 2002.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/diagnostic/","title":"Statistical test and tools","text":""},{"location":"api/diagnostic/#lmo.diagnostic","title":"<code>lmo.diagnostic</code>","text":"<p>Hypothesis tests, estimator properties, and performance metrics.</p>"},{"location":"api/diagnostic/#lmo.diagnostic.HypothesisTestResult","title":"<code>lmo.diagnostic.HypothesisTestResult</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Results of a hypothesis test.</p>"},{"location":"api/diagnostic/#lmo.diagnostic.HypothesisTestResult.is_valid","title":"<code>is_valid: np.bool_ | npt.NDArray[np.bool_]</code>  <code>property</code>","text":"<p>Check if the statistic is finite and not <code>nan</code>.</p>"},{"location":"api/diagnostic/#lmo.diagnostic.HypothesisTestResult.is_significant","title":"<code>is_significant(level=0.05)</code>","text":"<p>Whether or not the null hypothesis can be rejected, with a certain confidence level (5% by default).</p>"},{"location":"api/diagnostic/#lmo.diagnostic.normaltest","title":"<code>lmo.diagnostic.normaltest(a, /, *, axis=None)</code>","text":"<p>Statistical hypothesis test for non-normality, using the L-skewness and L-kurtosis coefficients on the sample data..</p> <p>Adapted from Harri &amp; Coble (2011), and includes Hosking\u2019s correction.</p> Definition <ul> <li>H0: The data was drawn from a normal distribution.</li> <li>H1: The data was drawn from a non-normal distribution.</li> </ul> <p>Examples:</p> <p>Compare the testing power with <code>scipy.stats.normaltest</code> given 10.000 samples from a contaminated normal distribution.</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from lmo.diagnostic import normaltest\n&gt;&gt;&gt; from scipy.stats import normaltest as normaltest_scipy\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; n = 10_000\n&gt;&gt;&gt; x = 0.9 * rng.normal(0, 1, n) + 0.1 * rng.normal(0, 9, n)\n&gt;&gt;&gt; normaltest(x)[1]\n0.04806618\n&gt;&gt;&gt; normaltest_scipy(x)[1]\n0.08435627\n</code></pre> <p>At a 5% significance level, Lmo\u2019s test is significant (i.e. indicating non-normality), whereas scipy\u2019s test isn\u2019t (i.e. inconclusive).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>AnyArrayFloat</code> <p>Array-like of sample data.</p> required <code>axis</code> <code>int | None</code> <p>Axis along which to compute the test.</p> <code>None</code> <p>Returns:</p> Type Description <code>HypothesisTestResult</code> <p>A named tuple with:</p> <ul> <li><code>statistic</code>: The \\(\\tau^2_{3, 4}\\) test statistic.</li> <li><code>pvalue</code>: Two-sided chi squared probability for \\(H_0\\).</li> </ul> References <p>A. Harri &amp; K.H. Coble (2011) - Normality testing: Two new tests using L-moments</p>"},{"location":"api/diagnostic/#lmo.diagnostic.l_moment_gof","title":"<code>lmo.diagnostic.l_moment_gof(rv_or_cdf, l_moments, n_obs, /, trim=0, **kwargs)</code>","text":"<p>Goodness-of-fit (GOF) hypothesis test for the null hypothesis that the observed L-moments come from a distribution with the given <code>scipy.stats</code> distribution or cumulative distribution function (CDF).</p> <ul> <li><code>H0</code>: The theoretical probability distribution, with the given CDF,     is a good fit for the observed L-moments.</li> <li><code>H1</code>: The distribution is not a good fit for the observed L-moments.</li> </ul> <p>The test statistic is the squared Mahalanobis distance between the \\(n\\) observed L-moments, and the theoretical L-moments. It asymptically (in sample size) follows the \\(\\chi^2\\) distribution, with \\(n\\) degrees of freedom.</p> <p>The sample L-moments are expected to be of consecutive orders \\(r = 1, 2, \\dots, n\\). Generally, the amount of L-moments \\(n\\) should not be less than the amount of parameters of the distribution, including the location and scale parameters. Therefore, it is required to have \\(n \\ge 2\\).</p> Notes <p>The theoretical L-moments and their covariance matrix are calculated from the CDF using numerical integration (<code>scipy.integrate.quad</code> and <code>scipy.integrate.nquad</code>). Undefined or infinite integrals cannot be detected, in which case the results might be incorrect.</p> <p>If an <code>IntegrationWarning</code> is issued, or the function is very slow, then the results are probably incorrect, and larger degrees of trimming should be used.</p> <p>Examples:</p> <p>Test if the samples are drawn from a normal distribution.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from lmo.diagnostic import l_moment_gof\n&gt;&gt;&gt; from scipy.stats import norm\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; X = norm(13.12, 1.66)\n&gt;&gt;&gt; n = 1_000\n&gt;&gt;&gt; x = X.rvs(n, random_state=rng)\n&gt;&gt;&gt; x_lm = lmo.l_moment(x, [1, 2, 3, 4])\n&gt;&gt;&gt; l_moment_gof(X, x_lm, n).pvalue\n0.82597\n</code></pre> <p>Contaminated samples:</p> <pre><code>&gt;&gt;&gt; y = 0.9 * x + 0.1 * rng.normal(X.mean(), X.std() * 10, n)\n&gt;&gt;&gt; y_lm = lmo.l_moment(y, [1, 2, 3, 4])\n&gt;&gt;&gt; y_lm.round(3)\narray([13.193, 1.286, 0.006, 0.168])\n&gt;&gt;&gt; l_moment_gof(X, y_lm, n).pvalue\n0.0\n</code></pre> See Also <ul> <li><code>l_moment_from_cdf</code></li> <li>\u2018l_moment_cov_from_cdf\u2019</li> </ul>"},{"location":"api/diagnostic/#lmo.diagnostic.l_stats_gof","title":"<code>lmo.diagnostic.l_stats_gof(rv_or_cdf, l_stats, n_obs, /, trim=0, **kwargs)</code>","text":"<p>Analogous to <code>lmo.diagnostic.l_moment_gof</code>, but using the L-stats (see <code>lmo.l_stats</code>).</p>"},{"location":"api/diagnostic/#lmo.diagnostic.l_moment_bounds","title":"<code>lmo.diagnostic.l_moment_bounds(r, /, trim=0, scale=1.0)</code>","text":"<pre><code>l_moment_bounds(r: AnyOrderND, /, trim: AnyTrim = ..., scale: float = ...) -&gt; _ArrF8\n</code></pre><pre><code>l_moment_bounds(r: AnyOrder, /, trim: AnyTrim = ..., scale: float = ...) -&gt; float\n</code></pre> <p>Returns the absolute upper bounds \\(L^{(s,t)}_r\\) on L-moments \\(\\lambda^{(s,t)}_r\\), proportional to the scale \\(\\sigma_X\\) (standard deviation) of the probability distribution of random variable \\(X\\). So \\(\\left| \\lambda^{(s,t)}_r(X) \\right| \\le \\sigma_X \\, L^{(s,t)}_r\\), given that standard deviation \\(\\sigma_X\\) of \\(X\\) exists and is finite.</p> Warning <p>These bounds do not apply to distributions with undefined variance, e.g. the Cauchy distribution, even if trimmed L-moments are used. Distributions with infinite variance (e.g. Student\u2019s t with \\(\\nu=2\\)) are a grey area:</p> <p>For the L-scale (\\(r=2\\)), the corresponding bound will not be a valid one. However, it can still be used to find the L-ratio bounds, because the \\(\\sigma_X\\) terms will cancel out. Doing this is not for the faint of heart, as it requires dividing infinity by infinity. So be sure to wear safety glasses.</p> <p>The bounds are derived by applying the Cauchy-Schwarz inequality to the covariance-based definition of generalized trimmed L-moment, for \\(r &gt; 1\\):</p> \\[ \\lambda^{(s,t)}_r(X) =     \\frac{r+s+t}{r}     \\frac{B(r,\\, r+s+t)}{B(r+s,\\, r+t)}     \\mathrm{Cov}\\left[         X,\\;         F(X)^s         \\big(1 - F(X)\\big)^t         P^{(\\alpha, \\beta)}_r(X)     \\right] \\;, \\] <p>where \\(B\\) is the Beta function, \\(P^{(\\alpha, \\beta)}_r\\) the Jacobi polynomial, and \\(F\\) the cumulative distribution function of random variable \\(X\\).</p> <p>After a lot of work, one can (and one did) derive the closed-form inequality:</p> \\[ \\left| \\lambda^{(s,t)}_r(X) \\right| \\le     \\frac{\\sigma_X}{\\sqrt{2 \\pi}}     \\frac{\\Gamma(r+s+t+1)}{r}     \\sqrt{\\frac{         B(r-\\frac{1}{2}, s+\\frac{1}{2}, t+\\frac{1}{2})     }{         \\Gamma(s+t+1) \\Gamma(r+s) \\Gamma(r+t)     }} \\] <p>for \\(r \\in \\mathbb{N}_{\\ge 2}\\) and \\(s, t \\in \\mathbb{R}_{\\ge 0}\\), where \\(\\Gamma\\) is the Gamma function, and \\(B\\) the multivariate Beta function</p> <p>For the untrimmed L-moments, this simplifies to</p> \\[ \\left| \\lambda_r(X) \\right| \\le \\frac{\\sigma_X}{\\sqrt{2 r - 1}} \\,. \\] Notes <p>For \\(r=1\\) there are no bounds, i.e. <code>float('inf')</code> is returned.</p> <p>There are no references; this novel finding is not (yet..?) published by the author, @jorenham.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>The L-moment order(s), non-negative integer or array-like of integers.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right-trim orders \\((s, t)\\), as a tuple of non-negative ints or floats.</p> <code>0</code> <code>scale</code> <code>float</code> <p>The standard deviation \\(\\sigma_X\\) of the random variable \\(X\\). Defaults to 1.</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>out</code> <code>float | _ArrF8</code> <p>float array or scalar like <code>r</code>.</p> See Also <ul> <li><code>l_ratio_bounds</code></li> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"api/diagnostic/#lmo.diagnostic.l_ratio_bounds","title":"<code>lmo.diagnostic.l_ratio_bounds(r, /, trim=0, *, legacy=False)</code>","text":"<pre><code>l_ratio_bounds(\n    r: AnyOrderND, /, trim: AnyTrim = ..., *, legacy: bool = ...\n) -&gt; _Tuple2[_ArrF8]\n</code></pre><pre><code>l_ratio_bounds(\n    r: AnyOrder, /, trim: AnyTrim = ..., *, legacy: bool = ...\n) -&gt; _Tuple2[float]\n</code></pre> <p>Unlike the standardized product-moments, the L-moment ratio\u2019s with \\( r \\ge 2 \\) are bounded above and below.</p> <p>Specifically, Hosking derived in 2007 that</p> \\[     | \\tlratio{r}{s,t}| \\le         \\frac 2 r         \\frac{\\ffact{r + s + t}{r - 2}}{\\ffact{r - 1 + s \\wedge t}{r - 2}}         . \\] <p>But this derivation relies on unnecessarily loose Jacobi polynomial bounds. If the actual min and max of the Jacobi polynomials are used instead, the following (tighter) inequality is obtained:</p> \\[     \\frac{\\dot{w}_r^{(s, t)}}{\\dot{w}_2^{(s, t)}}     \\min_{u \\in [0, 1]} \\left[ \\shjacobi{r - 1}{t + 1}{s + 1}{u} \\right]     \\le     \\tlratio{s, t}{r}     \\le     \\frac{\\dot{w}_r^{(s, t)}}{\\dot{w}_2^{(s, t)}}     \\max_{0 \\le u \\le 1} \\left[ \\shjacobi{r - 1}{t + 1}{s + 1}{u} \\right], \\] <p>where</p> \\[     \\dot{w}_r^{(s, t)} =         \\frac{\\B(r - 1,\\ r + s + t + 1)}{r \\B(r + s,\\ r + t)}. \\] <p>Examples:</p> <p>Without trim, the lower- and upper-bounds of the L-skewness and L-kurtosis are:</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds(3)\n(-1.0, 1.0)\n&gt;&gt;&gt; l_ratio_bounds(4)\n(-0.25, 1.0)\n</code></pre> <p>For the L-kurtosis, the \u201clegacy\u201d bounds by Hosking (2007) are clearly looser:</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds(4, legacy=True)\n(-1.0, 1.0)\n</code></pre> <p>For the symmetrically trimmed TL-moment ratio\u2019s:</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds(3, trim=3)\n(-1.2, 1.2)\n&gt;&gt;&gt; l_ratio_bounds(4, trim=3)\n(-0.15, 1.5)\n</code></pre> <p>Similarly, those of the LL-ratio\u2019s are</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds(3, trim=(0, 3))\n(-0.8, 2.0)\n&gt;&gt;&gt; l_ratio_bounds(4, trim=(0, 3))\n(-0.233333, 3.5)\n</code></pre> <p>The LH-skewness bounds are \u201cflipped\u201d w.r.t to the LL-skewness, but they are the same for the L*-kurtosis:</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds(3, trim=(3, 0))\n(-2.0, 0.8)\n&gt;&gt;&gt; l_ratio_bounds(4, trim=(3, 0))\n(-0.233333, 3.5)\n</code></pre> <p>The bounds of multiple L-ratio\u2019s can be calculated in one shot:</p> <pre><code>&gt;&gt;&gt; np.stack(l_ratio_bounds([3, 4, 5, 6], trim=(1, 2)))\narray([[-1.        , -0.19444444, -1.12      , -0.14945848],\n       [ 1.33333333,  1.75      ,  2.24      ,  2.8       ]])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>Scalar or array-like with the L-moment ratio order(s).</p> required <code>trim</code> <code>AnyTrim</code> <p>L-moment ratio trim-length(s).</p> <code>0</code> <code>legacy</code> <code>bool</code> <p>If set to <code>True</code>, will use the (looser) by Hosking (2007).</p> <code>False</code> <p>Returns:</p> Type Description <code>_Tuple2[float | _ArrF8]</code> <p>A 2-tuple with arrays or scalars, of the lower- and upper bounds.</p> See Also <ul> <li><code>l_ratio</code></li> <li><code>l_ratio_se</code></li> <li><code>diagnostic.l_moment_bounds</code></li> </ul> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed L-moments</li> </ul>"},{"location":"api/diagnostic/#lmo.diagnostic.rejection_point","title":"<code>lmo.diagnostic.rejection_point(influence_fn, /, rho_min=0, rho_max=np.inf)</code>","text":"<p>Evaluate the approximate rejection point of an influence function \\(\\psi_{T|F}(x)\\) given a statistical functional \\(T\\) (e.g. an L-moment) and cumulative distribution function \\(F(x)\\).</p> \\[ \\rho^*_{T|F} = \\inf_{r&gt;0} \\left\\{     r: | \\psi_{T|F}(x) | \\le \\epsilon, \\, |x| &gt; r \\right\\} \\; \\] <p>with a \\(\\epsilon\\) a small positive number, corresponding to the <code>tol</code> param of e.g. l_moment_influence , which defaults to <code>1e-8</code>.</p> <p>Examples:</p> <p>The untrimmed L-location isn\u2019t robust, e.g. with the standard normal distribution:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from scipy.stats import distributions as dists\n&gt;&gt;&gt; from lmo.diagnostic import rejection_point\n&gt;&gt;&gt; if_l_loc_norm = dists.norm.l_moment_influence(1, trim=0)\n&gt;&gt;&gt; if_l_loc_norm(np.inf)\ninf\n&gt;&gt;&gt; rejection_point(if_l_loc_norm)\nnan\n</code></pre> <p>For the TL-location of the Gaussian distribution, and even for the Student\u2019s t distribution with 4 degrees of freedom (3 also works, but is very slow), they exist.</p> <pre><code>&gt;&gt;&gt; influence_norm = dists.norm.l_moment_influence(1, trim=1)\n&gt;&gt;&gt; influence_t4 = dists.t(4).l_moment_influence(1, trim=1)\n&gt;&gt;&gt; influence_norm(np.inf), influence_t4(np.inf)\n(0.0, 0.0)\n&gt;&gt;&gt; rejection_point(influence_norm), rejection_point(influence_t4)\n(6.0, 206.0)\n</code></pre> Notes <p>Large rejection points (e.g. &gt;1000) are unlikely to be found.</p> <p>For instance, that of the TL-location of the Student\u2019s t distribution with 2 degrees of freedom lies between somewhere <code>1e4</code> and <code>1e5</code>, but will not be found. In this case, using <code>trim=2</code> will return <code>166.0</code>.</p> <p>Parameters:</p> Name Type Description Default <code>influence_fn</code> <code>Callable[[float], float]</code> <p>Univariate influence function.</p> required <code>rho_min</code> <code>float</code> <p>The minimum \\(\\rho^*_{T|F}\\) of the search space. Must be finite and non-negative. Defaults to \\(0\\).</p> <code>0</code> <code>rho_max</code> <code>float</code> <p>The maximum \\(\\rho^*_{T|F}\\) of the search space. Must be larger than <code>rho_min</code>. Defaults to \\(\\infty\\).</p> <code>inf</code> <p>Returns:</p> Type Description <code>float</code> <p>A finite or infinite scalar.</p> See Also <ul> <li><code>lmo.contrib.scipy_stats.l_rv_generic.l_moment_influence</code> </li> <li><code>error_sensitivity</code></li> </ul>"},{"location":"api/diagnostic/#lmo.diagnostic.error_sensitivity","title":"<code>lmo.diagnostic.error_sensitivity(influence_fn, /, domain=(-math.inf, math.inf))</code>","text":"<p>Evaluate the gross-error sensitivity of an influence function \\(\\psi_{T|F}(x)\\) given a statistical functional \\(T\\) (e.g. an L-moment) and cumulative distribution function \\(F(x)\\).</p> \\[ \\gamma^*_{T|F} = \\max_{x} \\left| \\psi_{T|F}(x) \\right| \\] <p>Examples:</p> <p>Evaluate the gross-error sensitivity of the standard exponential distribution\u2019s LL-skewness (\\(\\tau^{(0, 1)}_3\\)) and LL-kurtosis (\\(\\tau^{(0, 1)}_4\\)) coefficients:</p> <pre><code>&gt;&gt;&gt; from lmo.diagnostic import error_sensitivity\n&gt;&gt;&gt; from scipy.stats import expon\n&gt;&gt;&gt; ll_skew_if = expon.l_ratio_influence(3, 2, trim=(0, 1))\n&gt;&gt;&gt; ll_kurt_if = expon.l_ratio_influence(4, 2, trim=(0, 1))\n&gt;&gt;&gt; error_sensitivity(ll_skew_if, domain=(0, float(\"inf\")))\n1.814657\n&gt;&gt;&gt; error_sensitivity(ll_kurt_if, domain=(0, float(\"inf\")))\n1.377743\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>influence_fn</code> <code>Callable[[float], float]</code> <p>Univariate influence function.</p> required <code>domain</code> <code>_Tuple2[float]</code> <p>Domain of the CDF. Defaults to \\((-\\infty, \\infty)\\).</p> <code>(-inf, inf)</code> <p>Returns:</p> Type Description <code>float</code> <p>Gross-error sensitivity \\(\\gamma^*_{T|F}\\) .</p> See Also <ul> <li><code>lmo.contrib.scipy_stats.l_rv_generic.l_moment_influence</code> </li> <li><code>rejection_point</code></li> </ul>"},{"location":"api/diagnostic/#lmo.diagnostic.shift_sensitivity","title":"<code>lmo.diagnostic.shift_sensitivity(influence_fn, /, domain=(-math.inf, math.inf))</code>","text":"<p>Evaluate the local-shift sensitivity of an influence function \\(\\psi_{T|F}(x)\\) given a statistical functional \\(T\\) (e.g. an L-moment) and cumulative distribution function \\(F(x)\\).</p> \\[ \\lambda^*_{T|F} = \\max_{x \\neq y} \\left| \\frac{ \\psi_{T|F}(y) - \\psi_{T|F}(x) }{ y - x } \\right| \\] <p>Represents the effect of shifting an observation slightly from \\(x\\), to a neighbouring point \\(y\\). For instance, adding an observation at \\(y\\) and removing one at \\(x\\).</p> <p>Examples:</p> <p>Evaluate the local-shift sensitivity of the standard exponential distribution\u2019s LL-skewness (\\(\\tau^{(0, 1)}_3\\)) and LL-kurtosis (\\(\\tau^{(0, 1)}_4\\)) coefficients:</p> <pre><code>&gt;&gt;&gt; from lmo.diagnostic import shift_sensitivity\n&gt;&gt;&gt; from scipy.stats import expon\n&gt;&gt;&gt; ll_skew_if = expon.l_ratio_influence(3, 2, trim=(0, 1))\n&gt;&gt;&gt; ll_kurt_if = expon.l_ratio_influence(4, 2, trim=(0, 1))\n&gt;&gt;&gt; domain = 0, float(\"inf\")\n&gt;&gt;&gt; shift_sensitivity(ll_skew_if, domain)\n0.837735\n&gt;&gt;&gt; shift_sensitivity(ll_kurt_if, domain)\n1.442062\n</code></pre> <p>Let\u2019s compare these with the untrimmed ones:</p> <pre><code>&gt;&gt;&gt; shift_sensitivity(expon.l_ratio_influence(3, 2), domain)\n1.920317\n&gt;&gt;&gt; shift_sensitivity(expon.l_ratio_influence(4, 2), domain)\n1.047565\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>influence_fn</code> <code>Callable[[float], float]</code> <p>Univariate influence function.</p> required <code>domain</code> <code>_Tuple2[float]</code> <p>Domain of the CDF. Defaults to \\((-\\infty, \\infty)\\).</p> <code>(-inf, inf)</code> <p>Returns:</p> Type Description <code>float</code> <p>Local-shift sensitivity \\(\\lambda^*_{T|F}\\) .</p> See Also <ul> <li><code>lmo.contrib.scipy_stats.l_rv_generic.l_moment_influence</code> </li> <li><code>error_sensitivity</code></li> </ul> References <ul> <li>Frank R. Hampel (1974) - The Influence Curve and its Role in     Robust Estimation</li> </ul>"},{"location":"api/distributions/","title":"Probability Distributions","text":""},{"location":"api/distributions/#scipystats-integration","title":"<code>scipy.stats</code> integration","text":""},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic","title":"<code>l_rv_generic</code>","text":"<p>Additional methods that are patched into <code>scipy.stats.rv_continuous</code> and <code>scipy.stats.rv_discrete</code>.</p>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_moment","title":"<code>l_moment(r, /, *args, trim=0, quad_opts=None, **kwds)</code>","text":"<pre><code>l_moment(\n    r: lmt.AnyOrderND,\n    /,\n    *args: Any,\n    trim: lmt.AnyTrim = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    **kwds: Any,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_moment(\n    r: lmt.AnyOrder,\n    /,\n    *args: Any,\n    trim: lmt.AnyTrim = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    **kwds: Any,\n) -&gt; np.float64\n</code></pre> <p>Population L-moment(s) \\(\\lambda^{(s,t)}_r\\).</p> \\[ \\lambda^{(s, t)}_r = \\frac{r+s+t}{r} \\frac{B(r,\\,r+s+t)}{B(r+s,\\,r+t)} \\mathbb{E}_X \\left[     U^s     \\left(1 - U\\right)^t     \\,\\tilde{P}^{(t, s)}_{r-1}(U)     \\,X \\right] \\;, \\] <p>with \\(U = F_X(X)\\) the rank of \\(X\\), and \\(\\tilde{P}^{(a,b)}_n(x)\\) the shifted (\\(x \\mapsto 2x-1\\)) Jacobi polynomial.</p> <p>Examples:</p> <p>Evaluate the population L-moments of the normally-distributed IQ test:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import norm\n&gt;&gt;&gt; norm(100, 15).l_moment([1, 2, 3, 4]).round(6)\narray([100.      ,   8.462844,   0.      ,   1.037559])\n&gt;&gt;&gt; _[1] * np.sqrt(np.pi)\n15.0000004\n</code></pre> <p>Discrete distributions are also supported, e.g. the Binomial distribution:</p> <pre><code>&gt;&gt;&gt; from scipy.stats import binom\n&gt;&gt;&gt; binom(10, 0.6).l_moment([1, 2, 3, 4]).round(6)\narray([ 6.      ,  0.862238, -0.019729,  0.096461])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> required <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>0</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> <p>Raises:</p> Type Description <code>TypeError</code> <p><code>r</code> is not integer-valued</p> <code>ValueError</code> <p><code>r</code> is empty or negative</p> <p>Returns:</p> Name Type Description <code>lmbda</code> <code>float64 | _ArrF8</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>.</p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of     trimmed L-moments</li> </ul> See Also <ul> <li><code>lmo.l_moment</code>: sample L-moment</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_ratio","title":"<code>l_ratio(r, k, /, *args, trim=0, quad_opts=None, **kwds)</code>","text":"<pre><code>l_ratio(\n    order: lmt.AnyOrderND,\n    order_denom: lmt.AnyOrder | lmt.AnyOrderND,\n    /,\n    *args: Any,\n    trim: lmt.AnyTrim = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    **kwds: Any,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_ratio(\n    order: lmt.AnyOrder,\n    order_denom: lmt.AnyOrder | lmt.AnyOrderND,\n    /,\n    *args: Any,\n    trim: lmt.AnyTrim = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    **kwds: Any,\n) -&gt; np.float64\n</code></pre> <p>L-moment ratio(\u2019s) \\(\\tau^{(s,t)}_{r,k}\\).</p> \\[ \\tau^{(s,t)}_{r,k} = \\frac{\\lambda^{(s,t)}_r}{\\lambda^{(s,t)}_k} \\] <p>Unless explicitly specified, the r-th (\\(r&gt;2\\)) L-ratio, \\(\\tau^{(s,t)}_r\\) refers to \\(\\tau^{(s,t)}_{r, 2}\\). Another special case is the L-variation, or the L-CV, \\(\\tau^{(s,t)} = \\tau^{(s,t)}_{2, 1}\\). This is the L-moment analogue of the coefficient of variation.</p> <p>Examples:</p> <p>Evaluate the population L-CV and LL-CV (CV = coefficient of variation) of the standard Rayleigh distribution.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.rayleigh()\n&gt;&gt;&gt; X.std() / X.mean()  # legacy CV\n0.5227232\n&gt;&gt;&gt; X.l_ratio(2, 1)\n0.2928932\n&gt;&gt;&gt; X.l_ratio(2, 1, trim=(0, 1))\n0.2752551\n</code></pre> <p>And similarly, for the (discrete) Poisson distribution with rate parameter set to 2, the L-CF and LL-CV evaluate to:</p> <pre><code>&gt;&gt;&gt; X = distributions.poisson(2)\n&gt;&gt;&gt; X.std() / X.mean()\n0.7071067\n&gt;&gt;&gt; X.l_ratio(2, 1)\n0.3857527\n&gt;&gt;&gt; X.l_ratio(2, 1, trim=(0, 1))\n0.4097538\n</code></pre> <p>Note that (untrimmed) L-CV requires a higher (subdivision) limit in the integration routine, otherwise it\u2019ll complain that it didn\u2019t converge (enough) yet. This is because it\u2019s effectively integrating a non-smooth function, which is mathematically iffy, but works fine in this numerical application.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment ratio order(s), non-negative integer or array-like of integers.</p> required <code>k</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order of the denominator, e.g. 2.</p> required <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>0</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> See Also <ul> <li><code>l_rv_generic.l_moment</code> </li> <li><code>lmo.l_ratio</code> - Sample L-moment ratio estimator</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_stats","title":"<code>l_stats(*args, trim=0, moments=4, quad_opts=None, **kwds)</code>","text":"<p>The L-moments (for \\(r \\le 2\\)) and L-ratio\u2019s (for \\(r &gt; 2\\)).</p> <p>By default, the first <code>moments = 4</code> population L-stats are calculated:</p> <ul> <li>\\(\\lambda^{(s,t)}_1\\) - L-location</li> <li>\\(\\lambda^{(s,t)}_2\\) - L-scale</li> <li>\\(\\tau^{(s,t)}_3\\) - L-skewness coefficient</li> <li>\\(\\tau^{(s,t)}_4\\) - L-kurtosis coefficient</li> </ul> <p>This method is equivalent to <code>X.l_ratio([1, 2, 3, 4], [0, 0, 2, 2], *, **)</code>, for with default <code>moments = 4</code>.</p> <p>Examples:</p> <p>Summarize the standard exponential distribution for different trim-orders.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.expon()\n&gt;&gt;&gt; X.l_stats().round(6)\narray([1.      , 0.5     , 0.333333, 0.166667])\n&gt;&gt;&gt; X.l_stats(trim=(0, 1 / 2)).round(6)\narray([0.666667, 0.333333, 0.266667, 0.114286])\n&gt;&gt;&gt; X.l_stats(trim=(0, 1)).round(6)\narray([0.5     , 0.25    , 0.222222, 0.083333])\n</code></pre> Note <p>This should not be confused with the term L-statistic, which is sometimes used to describe any linear combination of order statistics.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>0</code> <code>moments</code> <code>int</code> <p>The amount of L-moments to return. Defaults to 4.</p> <code>4</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> See Also <ul> <li><code>l_rv_generic.l_ratio</code> </li> <li><code>lmo.l_stats</code> - Unbiased sample estimation of   L-stats.</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_loc","title":"<code>l_loc(*args, trim=0, **kwds)</code>","text":"<p>L-location of the distribution, i.e. the 1st L-moment.</p> <p>Alias for <code>X.l_moment(1, ...)</code>.</p>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_scale","title":"<code>l_scale(*args, trim=0, **kwds)</code>","text":"<p>L-scale of the distribution, i.e. the 2nd L-moment.</p> <p>Alias for <code>X.l_moment(2, ...)</code>.</p>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_skew","title":"<code>l_skew(*args, trim=0, **kwds)</code>","text":"<p>L-skewness coefficient of the distribution; the 3rd L-moment ratio.</p> <p>Alias for <code>X.l_ratio(3, 2, ...)</code>.</p>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_kurt","title":"<code>l_kurt(*args, trim=0, **kwds)</code>","text":"<p>L-kurtosis coefficient of the distribution; the 4th L-moment ratio.</p> <p>Alias for <code>X.l_ratio(4, 2, ...)</code>.</p>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_moments_cov","title":"<code>l_moments_cov(r_max, /, *args, trim=0, quad_opts=None, **kwds)</code>","text":"<p>Variance/covariance matrix of the L-moment estimators.</p> <p>L-moments that are estimated from \\(n\\) samples of a distribution with CDF \\(F\\), converge to the multivariate normal distribution as the sample size \\(n \\rightarrow \\infty\\).</p> \\[ \\sqrt{n} \\left(     \\vec{l}^{(s, t)} - \\vec{\\lambda}^{(s, t)} \\right) \\sim \\mathcal{N}(     \\vec{0},     \\mathbf{\\Lambda}^{(s, t)} ) \\] <p>Here, \\(\\vec{l}^{(s, t)} = \\left[l^{(s,t)}_r, \\dots, l^{(s,t)}_{r_{max}}\\right]^T\\) is a vector of estimated sample L-moments, and \\(\\vec{\\lambda}^{(s, t)}\\) its theoretical (\u201ctrue\u201d) counterpart.</p> <p>This function calculates the covariance matrix</p> \\[ \\begin{align} \\bf{\\Lambda}^{(s,t)}_{k, r}     &amp;= \\mathrm{Cov}[l^{(s, t)}_k, l^{(s, t)}_r] \\\\     &amp;= c_k c_r     \\iint\\limits_{x &lt; y} \\Big[         p_k\\big(F(x)\\big) \\, p_r\\big(F(y)\\big) +         p_r\\big(F(x)\\big) \\, p_k\\big(F(y)\\big)     \\Big]     w^{(s+1,\\, t)}\\big(F(x)\\big) \\,     w^{(s,\\, t+1)}\\big(F(y)\\big) \\,     \\mathrm{d}x \\, \\mathrm{d}y     \\;, \\end{align} \\] <p>where</p> \\[ c_n = \\frac{\\Gamma(n) \\Gamma(n+s+t+1)}{n \\Gamma(n+s) \\Gamma(n+t)}\\;, \\] <p>the shifted Jacobi polynomial \\(p_n(u) = P^{(t, s)}_{n-1}(2u - 1)\\), \\(P^{(t, s)}_m\\), and \\(w^{(s,t)}(u) = u^s (1-u)^t\\) its weight function.</p> Notes <p>This function is not vectorized or parallelized.</p> <p>For small sample sizes (\\(n &lt; 100\\)), the covariances of the higher-order L-moments (\\(r &gt; 2\\)) can be biased. But this bias quickly disappears at roughly \\(n &gt; 200\\) (depending on the trim- and L-moment orders).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.expon()  # standard exponential distribution\n&gt;&gt;&gt; X.l_moments_cov(4).round(6)\narray([[1.      , 0.5     , 0.166667, 0.083333],\n    [0.5     , 0.333333, 0.166667, 0.083333],\n    [0.166667, 0.166667, 0.133333, 0.083333],\n    [0.083333, 0.083333, 0.083333, 0.071429]])\n</code></pre> <pre><code>&gt;&gt;&gt; X.l_moments_cov(4, trim=(0, 1)).round(6)\narray([[0.333333, 0.125   , 0.      , 0.      ],\n    [0.125   , 0.075   , 0.016667, 0.      ],\n    [0.      , 0.016667, 0.016931, 0.00496 ],\n    [0.      , 0.      , 0.00496 , 0.0062  ]])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>r_max</code> <code>int</code> <p>The amount of L-moment orders to consider. If for example <code>r_max = 4</code>, the covariance matrix will be of shape <code>(4, 4)</code>, and the columns and rows correspond to the L-moments of order \\(r = 1, \\dots, r_{max}\\).</p> required <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <code>0</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>cov</code> <code>_ArrF8</code> <p>Covariance matrix, with shape <code>(r_max, r_max)</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the covariance matrix is invalid.</p> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of     trimmed L-moments</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_stats_cov","title":"<code>l_stats_cov(*args, moments=4, trim=0, quad_opts=None, **kwds)</code>","text":"<p>Similar to <code>l_moments_cov</code> , but for the <code>l_rv_generic.l_stats</code>.</p> <p>As the sample size \\(n \\rightarrow \\infty\\), the L-moment ratio\u2019s are also distributed (multivariate) normally. The L-stats are defined to be L-moments for \\(r\\le 2\\), and L-ratio coefficients otherwise.</p> <p>The corresponding covariance matrix has been found to be</p> \\[ \\bf{T}^{(s, t)}_{k, r} = \\begin{cases}     \\bf{\\Lambda}^{(s, t)}_{k, r}         &amp; k \\le 2 \\wedge r \\le 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}     }{         \\lambda^{(s,t)}_{2}     }         &amp; k \\le 2 \\wedge r &gt; 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_k \\bf{\\Lambda}^{(s, t)}_{2, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}         + \\tau_k \\tau_r \\bf{\\Lambda}^{(s, t)}_{2, 2}     }{         \\Big( \\lambda^{(s,t)}_{2} \\Big)^2     }         &amp; k &gt; 2 \\wedge r &gt; 2 \\end{cases} \\] <p>where \\(\\bf{\\Lambda}^{(s, t)}\\) is the covariance matrix of the L-moments from <code>l_moment_cov_from_cdf</code>, and \\(\\tau^{(s,t)}_r = \\lambda^{(s,t)}_r / \\lambda^{(s,t)}_2\\) the population L-ratio.</p> <p>Examples:</p> <p>Evaluate the LL-stats covariance matrix of the standard exponential distribution, for 0, 1, and 2 degrees of trimming.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.expon()  # standard exponential distribution\n&gt;&gt;&gt; X.l_stats_cov().round(6)\narray([[1.      , 0.5     , 0.      , 0.      ],\n    [0.5     , 0.333333, 0.111111, 0.055556],\n    [0.      , 0.111111, 0.237037, 0.185185],\n    [0.      , 0.055556, 0.185185, 0.21164 ]])\n&gt;&gt;&gt; X.l_stats_cov(trim=(0, 1)).round(6)\narray([[ 0.333333,  0.125   , -0.111111, -0.041667],\n    [ 0.125   ,  0.075   ,  0.      , -0.025   ],\n    [-0.111111,  0.      ,  0.21164 ,  0.079365],\n    [-0.041667, -0.025   ,  0.079365,  0.10754 ]])\n&gt;&gt;&gt; X.l_stats_cov(trim=(0, 2)).round(6)\narray([[ 0.2     ,  0.066667, -0.114286, -0.02    ],\n    [ 0.066667,  0.038095, -0.014286, -0.023333],\n    [-0.114286, -0.014286,  0.228571,  0.04    ],\n    [-0.02    , -0.023333,  0.04    ,  0.086545]])\n</code></pre> <p>Note that with 0 trim the L-location is independent of the L-skewness and L-kurtosis. With 1 trim, the L-scale and L-skewness are independent. And with 2 trim, all L-stats depend on each other.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>moments</code> <code>int</code> <p>The amount of L-statistics to consider. Defaults to 4.</p> <code>4</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <code>0</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of     trimmed L-moments</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_moment_influence","title":"<code>l_moment_influence(r, /, *args, trim=0, quad_opts=None, tol=1e-08, **kwds)</code>","text":"<p>Returns the influence function (IF) of an L-moment.</p> \\[ \\psi_{\\lambda^{(s, t)}_r | F}(x)     = c^{(s,t)}_r     \\, F(x)^s     \\, \\big( 1-{F}(x) \\big)^t     \\, \\tilde{P}^{(s,t)}_{r-1} \\big( F(x) \\big)     \\, x     - \\lambda^{(s,t)}_r     \\;, \\] <p>with \\(F\\) the CDF, \\(\\tilde{P}^{(s,t)}_{r-1}\\) the shifted Jacobi polynomial, and</p> \\[ c^{(s,t)}_r     = \\frac{r+s+t}{r} \\frac{B(r, \\, r+s+t)}{B(r+s, \\, r+t)}     \\;, \\] <p>where \\(B\\) is the (complete) Beta function.</p> <p>The proof is trivial, because population L-moments are linear functionals.</p> Notes <p>The order parameter <code>r</code> is not vectorized.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder</code> <p>The L-moment order \\(r \\in \\mathbb{N}^+\\)..</p> required <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <code>0</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>tol</code> <code>float</code> <p>Values that are absolutely smaller than this will be rounded to zero.</p> <code>1e-08</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>influence_function</code> <code>_Fn1</code> <p>The (vectorized) influence function, \\(\\psi_{\\lambda^{(s, t)}_r | F}(x)\\).</p> See Also <ul> <li><code>l_rv_generic.l_moment</code> </li> <li><code>lmo.l_moment</code></li> </ul> References <ul> <li>Frank R. Hampel (1974) - The Influence Curve and its Role in     Robust Estimation</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_ratio_influence","title":"<code>l_ratio_influence(r, k, /, *args, trim=0, quad_opts=None, tol=1e-08, **kwds)</code>","text":"<p>Returns the influence function (IF) of an L-moment ratio.</p> \\[ \\psi_{\\tau^{(s, t)}_{r,k}|F}(x) = \\frac{     \\psi_{\\lambda^{(s, t)}_r|F}(x)     - \\tau^{(s, t)}_{r,k} \\, \\psi_{\\lambda^{(s, t)}_k|F}(x) }{     \\lambda^{(s,t)}_k } \\;, \\] <p>where the L-moment ratio is defined as</p> \\[ \\tau^{(s, t)}_{r,k} = \\frac{     \\lambda^{(s, t)}_r }{     \\lambda^{(s, t)}_k } \\;. \\] <p>Because IF\u2019s are a special case of the general G\u00e2teuax derivative, the L-ratio IF is derived by applying the chain rule to the L-moment IF.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder</code> <p>L-moment ratio order, i.e. the order of the numerator L-moment.</p> required <code>k</code> <code>AnyOrder</code> <p>Denominator L-moment order, defaults to 2.</p> required <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <code>0</code> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>None</code> <code>tol</code> <code>float</code> <p>Values that are absolutely smaller than this will be rounded to zero.</p> <code>1e-08</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>influence_function</code> <code>Callable[[_T_x], _T_x]</code> <p>The influence function, with vectorized signature <code>() -&gt; ()</code>.</p> See Also <ul> <li><code>l_rv_generic.l_ratio</code> </li> <li><code>lmo.l_ratio</code></li> </ul> References <ul> <li>Frank R. Hampel (1974) - The Influence Curve and its Role in     Robust Estimation</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_fit","title":"<code>l_fit(data, *args, n_extra=0, trim=0, full_output=False, fit_kwargs=None, random_state=None, **kwds)</code>","text":"<pre><code>l_fit(\n    data: lnpt.AnyVectorFloat,\n    *args: float,\n    n_extra: int = ...,\n    trim: lmt.AnyTrimInt = ...,\n    full_output: Literal[True],\n    fit_kwargs: Mapping[str, Any] | None = ...,\n    **kwds: Any\n) -&gt; tuple[float, ...]\n</code></pre><pre><code>l_fit(\n    data: lnpt.AnyVectorFloat,\n    *args: float,\n    n_extra: int = ...,\n    trim: lmt.AnyTrimInt = ...,\n    full_output: bool = ...,\n    fit_kwargs: Mapping[str, Any] | None = ...,\n    **kwds: Any\n) -&gt; tuple[float, ...]\n</code></pre> <p>Return estimates of shape (if applicable), location, and scale parameters from data. The default estimation method is Method of L-moments (L-MM), but the Generalized Method of L-Moments (L-GMM) is also available (see the <code>n_extra</code> parameter).</p> <p>See \u2018lmo.inference.fit\u2019 for details.</p> <p>Examples:</p> <p>Fitting standard normal samples Using scipy\u2019s default MLE (Maximum Likelihood Estimation) method:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from scipy.stats import norm\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_normal(200)\n&gt;&gt;&gt; norm.fit(x)\n(0.0033254, 0.95554)\n</code></pre> <p>Better results can be obtained different by using Lmo\u2019s L-MM (Method of L-moment):</p> <pre><code>&gt;&gt;&gt; norm.l_fit(x, random_state=rng)\n(0.0033145, 0.96179)\n&gt;&gt;&gt; norm.l_fit(x, trim=1, random_state=rng)\n(0.0196385, 0.96861)\n</code></pre> <p>To use more L-moments than the number of parameters, two in this case, <code>n_extra</code> can be used. This will use the L-GMM (Generalized Method of L-Moments), which results in slightly better estimates:</p> <pre><code>&gt;&gt;&gt; norm.l_fit(x, n_extra=1, random_state=rng)\n(0.0039747, .96233)\n&gt;&gt;&gt; norm.l_fit(x, trim=1, n_extra=1, random_state=rng)\n(-0.00127874, 0.968547)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>AnyVectorFloat</code> <p>1-D array-like data to use in estimating the distribution parameters.</p> required <code>*args</code> <code>float</code> <p>Starting value(s) for any shape-characterizing arguments ( those not provided will be determined by a call to <code>fit(data)</code>).</p> <code>()</code> <code>trim</code> <code>AnyTrimInt</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>0</code> <code>n_extra</code> <code>int</code> <p>The amount of extra L-moment conditions to use than the amount of parameters. If 0 (default), L-MM will be used. If &gt;0, \\(k\\)-step L-GMM will be used.</p> <code>0</code> <code>full_output</code> <code>bool</code> <p>If set to True, a <code>LGMMResult</code> instance will be returned, instead of only a tuple with parameters.</p> <code>False</code> <code>fit_kwargs</code> <code>Mapping[str, Any] | None</code> <p>Additional keyword arguments to be passed to \u2018lmo.inference.fit\u2019 or \u2018scipy.optimize.minimize\u2019.</p> <code>None</code> <code>random_state</code> <code>int | Generator | None</code> <p>Integer or <code>numpy.random.Generator</code> instance, used for Monte-Carlo simulation when <code>n_extra &gt; 0</code>. If <code>None</code> (default), the <code>random_state</code> of this distribution will be used.</p> <code>None</code> <code>**kwds</code> <code>Any</code> <p>Special keyword arguments are recognized as holding certain parameters fixed:</p> <pre><code>- `f0...fn`: hold respective shape parameters fixed.\nAlternatively, shape parameters to fix can be specified by\nname. For example, if `self.shapes == \"a, b\"`, `fa` and\n`fix_a` are equivalent to `f0`, and `fb` and `fix_b` are\nequivalent to `f1`.\n- `floc`: hold location parameter fixed to specified value.\n- `fscale`: hold scale parameter fixed to specified value.\n</code></pre> <code>{}</code> <p>Returns:</p> Name Type Description <code>result</code> <code>tuple[float, ...] | GMMResult</code> <p>Named tuple with estimates for any shape parameters (if applicable), followed by those for location and scale. For most random variables, shape statistics will be returned, but there are exceptions (e.g. <code>norm</code>). If <code>full_output=True</code>, an instance of <code>LGMMResult</code> will be returned instead.</p> See Also <ul> <li>\u2018lmo.inference.fit\u2019</li> </ul> References <ul> <li>Alvarez et al. (2023) - Inference in parametric models with many L-moments</li> </ul> Todo <ul> <li>Support integral parameters.</li> </ul>"},{"location":"api/distributions/#lmo.contrib.scipy_stats.l_rv_generic.l_fit_loc_scale","title":"<code>l_fit_loc_scale(data, *args, trim=0, **kwds)</code>","text":"<p>Estimate loc and scale parameters from data using the first two L-moments.</p> Notes <p>The implementation mimics that of <code>fit_loc_scale()</code></p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>AnyArrayFloat</code> <p>Data to fit.</p> required <code>*args</code> <code>Any</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information).</p> <code>()</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>0</code> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to pass to the distribution.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>loc_hat</code> <code>float</code> <p>Estimated location parameter for the data.</p> <code>scale_hat</code> <code>float</code> <p>Estimated scale parameter for the data.</p>"},{"location":"api/distributions/#parametric","title":"Parametric","text":""},{"location":"api/distributions/#lmo.distributions.kumaraswamy","title":"<code>lmo.distributions.kumaraswamy = kumaraswamy_gen(name='kumaraswamy', a=0.0, b=1.0)</code>","text":"<p>A Kumaraswamy random variable, similar to <code>scipy.stats.beta</code>.</p> <p>The probability density function for <code>kumaraswamy</code> is:</p> \\[     f(x, a, b) = a x^{a - 1} b \\left(1 - x^a\\right)^{b - 1} \\] <p>for \\( 0 &lt; x &lt; 1,\\ a &gt; 0,\\ b &gt; 0 \\).</p> <p><code>kumaraswamy</code> takes \\( a \\) and \\( b \\) as shape parameters.</p> See Also <ul> <li>Theoretical L-moments: Kumaraswamy</li> </ul>"},{"location":"api/distributions/#lmo.distributions.wakeby","title":"<code>lmo.distributions.wakeby = wakeby_gen(name='wakeby', a=0.0)</code>","text":"<p>A Wakeby random variable, a generalization of <code>scipy.stats.genpareto</code>.</p> <p><code>wakeby</code> takes \\( b \\), \\( d \\) and \\( f \\) as shape parameters.</p> <p>For a detailed description of the Wakeby distribution, refer to Distributions - Wakeby.</p>"},{"location":"api/distributions/#lmo.distributions.genlambda","title":"<code>lmo.distributions.genlambda = genlambda_gen(name='genlambda')</code>","text":"<p>A generalized Tukey-Lambda random variable.</p> <p><code>genlambda</code> takes <code>b</code>, <code>d</code> and <code>f</code> as shape parameters. <code>b</code> and <code>d</code> can be any float, and <code>f</code> requires <code>-1 &lt;= f &lt;= 1</code>.</p> <p>If <code>f == 0</code> and <code>b == d</code>, <code>genlambda</code> is equivalent to <code>scipy.stats.tukeylambda</code>, with <code>b</code> (or <code>d</code>) as shape parameter.</p> <p>For a detailed description of the GLD, refer to Distributions - GLD.</p>"},{"location":"api/distributions/#nonparametric","title":"Nonparametric","text":""},{"location":"api/distributions/#lmo.distributions.l_poly","title":"<code>lmo.distributions.l_poly(lmbda, /, trim=0, *, seed=None)</code>","text":"<p>Polynomial quantile distribution with (only) the given L-moments.</p> <p>Parameters:</p> Name Type Description Default <code>lmbda</code> <code>AnyVectorFloat</code> <p>1-d array-like of L-moments \\( \\tlmoment{s,t}{r} \\) for \\( r = 1, 2, \\ldots, R \\). At least 2 L-moments are required. All remaining L-moments with \\( r &gt; R \\) are considered zero.</p> required <code>trim</code> <code>AnyTrim</code> <p>The trim-length(s) of L-moments <code>lmbda</code>.</p> <code>0</code> <code>seed</code> <code>Seed | None</code> <p>Random number generator.</p> <code>None</code>"},{"location":"api/distributions/#lmo.distributions.l_poly.fit","title":"<code>lmo.distributions.l_poly.fit(data, /, moments=None, trim=0)</code>","text":"<p>Fit distribution using the (trimmed) L-moment estimates of the given data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>_AnyRealND</code> <p>1-d array-like with sample observations.</p> required <code>moments</code> <code>int | None</code> <p>How many sample L-moments to use, <code>2 &lt;= moments &lt; len(data)</code>. Defaults to \\(\\sqrt[3]{n}\\), where \\(n\\) is <code>len(data)</code>.</p> <code>None</code> <code>trim</code> <code>AnyTrim</code> <p>The left and right trim-lengths \\((s, t)\\) to use. Defaults to \\((0, 0)\\).</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>A fitted <code>l_poly</code> instance.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Invalid <code>data</code> shape.</p> <code>ValueError</code> <p>Not enough <code>moments</code>.</p> <code>ValueError</code> <p>If the L-moments of the data do not result in strictly monotinically increasing quantile function (PPF).</p> <p>This generally means that either the left, the right, or both <code>trim</code>-orders are too small.</p>"},{"location":"api/distributions/#lmo.distributions.l_poly.rvs","title":"<code>lmo.distributions.l_poly.rvs(size=None, random_state=None)</code>","text":"<pre><code>rvs(\n    size: Literal[1] | None = None, random_state: lnpt.Seed | None = None\n) -&gt; np.float64\n</code></pre><pre><code>rvs(\n    size: int | tuple[int, ...], random_state: lnpt.Seed | None = None\n) -&gt; npt.NDArray[np.float64]\n</code></pre> <p>Draw random variates from the relevant distribution.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int | tuple[int, ...] | None</code> <p>Defining number of random variates, defaults to 1.</p> <code>None</code> <code>random_state</code> <code>Seed | None</code> <p>Seed or <code>numpy.random.Generator</code> instance. Defaults to <code>l_poly.random_state</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>float64 | NDArray[float64]</code> <p>A scalar or array with shape like <code>size</code>.</p>"},{"location":"api/distributions/#lmo.distributions.l_poly.ppf","title":"<code>lmo.distributions.l_poly.ppf(p)</code>","text":"<p>Percent point function \\( Q(p) \\) (inverse of CDF, a.k.a. the quantile function) at \\( p \\) of the given distribution.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>_T_x</code> <p>Scalar or array-like of lower tail probability values in \\( [0, 1] \\).</p> required See Also <ul> <li><code>ppf_from_l_moments</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.isf","title":"<code>lmo.distributions.l_poly.isf(q)</code>","text":"<p>Inverse survival function \\( \\bar{Q}(q) = Q(1 - q) \\) (inverse of <code>sf</code>) at \\( q \\).</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>_T_x</code> <p>Scalar or array-like of upper tail probability values in \\( [0, 1] \\).</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.qdf","title":"<code>lmo.distributions.l_poly.qdf(p)</code>","text":"<p>Quantile density function \\( q \\equiv \\frac{\\dd{Q}}{\\dd{p}} \\) ( derivative of the PPF) at \\( p \\) of the given distribution.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>_T_x</code> <p>Scalar or array-like of lower tail probability values in \\( [0, 1] \\).</p> required See Also <ul> <li><code>qdf_from_l_moments</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.cdf","title":"<code>lmo.distributions.l_poly.cdf(x)</code>","text":"<p>Cumulative distribution function \\( F(x) = \\mathrm{P}(X \\le x) \\) at \\( x \\) of the given distribution.</p> Note <p>Because the CDF of <code>l_poly</code> is not analytically expressible, it is evaluated numerically using a root-finding algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_T_x</code> <p>Scalar or array-like of quantiles.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.logcdf","title":"<code>lmo.distributions.l_poly.logcdf(x)</code>","text":"<p>Logarithm of the cumulative distribution function (CDF) at \\( x \\), i.e. \\( \\ln F(x) \\).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_T_x</code> <p>Scalar or array-like of quantiles.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.sf","title":"<code>lmo.distributions.l_poly.sf(x)</code>","text":"<p>Survival function \\(S(x) = \\mathrm{P}(X &gt; x) = 1 - \\mathrm{P}(X \\le x) = 1 - F(x) \\) (the complement of the CDF).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_T_x</code> <p>Scalar or array-like of quantiles.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.logsf","title":"<code>lmo.distributions.l_poly.logsf(x)</code>","text":"<p>Logarithm of the survical function (SF) at \\( x \\), i.e. \\( \\ln \\left( S(x) \\right) \\).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_T_x</code> <p>Scalar or array-like of quantiles.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.pdf","title":"<code>lmo.distributions.l_poly.pdf(x)</code>","text":"<p>Probability density function \\( f \\equiv \\frac{\\dd{F}}{\\dd{x}} \\) (derivative of the CDF) at \\( x \\).</p> <p>By applying the inverse function rule, the PDF can also defined using the QDF as \\(  f(x) = 1 / q\\big(F(x)\\big) \\).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_T_x</code> <p>Scalar or array-like of quantiles.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.logpdf","title":"<code>lmo.distributions.l_poly.logpdf(x)</code>","text":"<p>Logarithm of the PDF.</p>"},{"location":"api/distributions/#lmo.distributions.l_poly.hf","title":"<code>lmo.distributions.l_poly.hf(x)</code>","text":"<p>Hazard function  \\( h(x) = f(x) / S(x) \\) at \\( x \\), with \\( f \\) and \\( S \\) the PDF and SF, respectively.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_T_x</code> <p>Scalar or array-like of quantiles.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.median","title":"<code>lmo.distributions.l_poly.median()</code>","text":"<p>Median (50th percentile) of the distribution. Alias for <code>ppf(1 / 2)</code>.</p> See Also <ul> <li><code>l_poly.ppf</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.mean","title":"<code>lmo.distributions.l_poly.mean()</code>","text":"<p>The mean \\( \\mu = \\E[X] \\) of random varianble \\( X \\) of the relevant distribution.</p> See Also <ul> <li><code>l_poly.l_loc</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.var","title":"<code>lmo.distributions.l_poly.var()</code>","text":"<p>The variance \\( \\Var[X] = \\E\\bigl[(X - \\E[X])^2\\bigr] = \\E\\bigl[X^2\\bigr] - \\E[X]^2 = \\sigma^2 \\) (2nd central product moment) of random varianble \\( X \\) of the relevant distribution.</p> See Also <ul> <li><code>l_poly.moment</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.std","title":"<code>lmo.distributions.l_poly.std()</code>","text":"<p>The standard deviation \\( \\Std[X] = \\sqrt{\\Var[X]} = \\sigma \\) of random varianble \\( X \\) of the relevant distribution.</p> See Also <ul> <li><code>l_poly.l_scale</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.entropy","title":"<code>lmo.distributions.l_poly.entropy()</code>","text":"<p>Differential entropy \\( \\mathrm{H}[X] \\) of random varianble \\( X \\) of the relevant distribution.</p> <p>It is defined as</p> \\[ \\mathrm{H}[X]     = \\E \\bigl[ -\\ln f(X) \\bigr]     = -\\int_{Q(0)}^{Q(1)} \\ln f(x) \\dd x     = \\int_0^1 \\ln q(p) \\dd p , \\] <p>with \\( f(x) \\) the PDF, \\( Q(p) \\) the PPF, and \\( q(p) = Q'(p) \\) the QDF.</p> See Also <ul> <li><code>entropy_from_qdf</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.support","title":"<code>lmo.distributions.l_poly.support()</code>","text":"<p>The support \\( (Q(0), Q(1)) \\) of the distribution, where \\( Q(p) \\) is the PPF.</p>"},{"location":"api/distributions/#lmo.distributions.l_poly.interval","title":"<code>lmo.distributions.l_poly.interval(confidence)</code>","text":"<pre><code>interval(confidence: _AnyReal0D) -&gt; tuple[np.float64, np.float64]\n</code></pre><pre><code>interval(\n    confidence: _AnyRealND,\n) -&gt; tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]\n</code></pre> <p>Confidence interval with equal areas around the median.</p> <p>For <code>confidence</code> level \\( \\alpha \\in [0, 1] \\), this function evaluates</p> \\[     \\left[         Q\\left( \\frac{1 - \\alpha}{2} \\right) ,         Q\\left( \\frac{1 + \\alpha}{2} \\right)     \\right], \\] <p>where \\( Q(p) \\) is the PPF.</p> <p>Parameters:</p> Name Type Description Default <code>confidence</code> <code>_AnyReal0D | _AnyRealND</code> <p>Scalar or array-like. The Probability that a random varianble will be drawn from the returned range.</p> <p>Each confidence value should be between 0 and 1.</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.moment","title":"<code>lmo.distributions.l_poly.moment(n)</code>","text":"<p>Non-central product moment \\( \\E[X^n] \\) of \\( X \\) of specified order \\( n \\).</p> Note <p>The product moment is evaluated using numerical integration (<code>scipy.integrate.quad</code>), which cannot check whether the product-moment actually exists for the distribution, in which case an invalid result will be returned.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | integer[Any]</code> <p>Order \\( n \\ge 0 \\) of the moment.</p> required See Also <ul> <li><code>l_poly.l_moment</code></li> </ul> Todo <ul> <li>For n&gt;=2, attempt tot infer from <code>_l_moments</code> if the 2nd moment     condition holds, using <code>diagnostics.l_moment_bounds</code>.</li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.stats","title":"<code>lmo.distributions.l_poly.stats(moments='mv')</code>","text":"<pre><code>stats() -&gt; _Tuple2[float]\n</code></pre><pre><code>stats(moments: _Stats0) -&gt; tuple[]\n</code></pre><pre><code>stats(moments: _Stats1) -&gt; _Tuple1[float]\n</code></pre><pre><code>stats(moments: _Stats2) -&gt; _Tuple2[float]\n</code></pre><pre><code>stats(moments: _Stats3) -&gt; _Tuple3[float]\n</code></pre><pre><code>stats(moments: _Stats4) -&gt; _Tuple4[float]\n</code></pre> <p>Some product-moment statistics of the given distribution.</p> <p>Parameters:</p> Name Type Description Default <code>moments</code> <code>_Stats</code> <p>Composed of letters <code>mvsk</code> defining which product-moment statistic to compute:</p> <code>'m'</code>: Mean \\( \\mu = \\E[X] \\) <code>'v'</code>: Variance \\( \\sigma^2 = \\E[(X - \\mu)^2] \\) <code>'s'</code>: Skewness \\( \\E[(X - \\mu)^3] / \\sigma^3 \\) <code>'k'</code>: Ex. Kurtosis \\( \\E[(X - \\mu)^4] / \\sigma^4 - 3 \\) <code>'mv'</code>"},{"location":"api/distributions/#lmo.distributions.l_poly.expect","title":"<code>lmo.distributions.l_poly.expect(g)</code>","text":"<p>Calculate expected value of a function with respect to the distribution by numerical integration.</p> <p>The expected value of a function \\( g(x) \\) with respect to a random variable \\( X \\) is defined as</p> \\[     \\E\\left[ g(X) \\right]         = \\int_{Q(0)}^{Q(1)} g(x) f(x) \\dd x         = \\int_0^1 g\\big(Q(u)\\big) \\dd u , \\] <p>with \\( f(x) \\) the PDF, and \\( Q \\) the PPF.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code> (float) -&gt; float </code> <p>Continuous and deterministic function \\( g: \\reals \\mapsto \\reals \\).</p> required"},{"location":"api/distributions/#lmo.distributions.l_poly.l_moment","title":"<code>lmo.distributions.l_poly.l_moment(r, /, trim=None)</code>","text":"<pre><code>l_moment(r: lmt.AnyOrder, /, trim: lmt.AnyTrim | None = None) -&gt; np.float64\n</code></pre><pre><code>l_moment(\n    r: lmt.AnyOrderND, /, trim: lmt.AnyTrim | None = None\n) -&gt; npt.NDArray[np.float64]\n</code></pre> <p>Evaluate the population L-moment(s) \\(\\lambda^{(s,t)}_r\\).</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> required <code>trim</code> <code>AnyTrim | None</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>None</code>"},{"location":"api/distributions/#lmo.distributions.l_poly.l_ratio","title":"<code>lmo.distributions.l_poly.l_ratio(r, k, /, trim=None)</code>","text":"<pre><code>l_ratio(\n    r: lmt.AnyOrder, k: lmt.AnyOrder, /, trim: lmt.AnyTrim | None = None\n) -&gt; np.float64\n</code></pre><pre><code>l_ratio(\n    r: lmt.AnyOrderND,\n    k: lmt.AnyOrder | lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim | None = None,\n) -&gt; npt.NDArray[np.float64]\n</code></pre><pre><code>l_ratio(\n    r: lmt.AnyOrder | lmt.AnyOrderND,\n    k: lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim | None = None,\n) -&gt; npt.NDArray[np.float64]\n</code></pre> <p>Evaluate the population L-moment ratio(\u2019s) \\(\\tau^{(s,t)}_{r,k}\\).</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> required <code>k</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order of the denominator, e.g. 2.</p> required <code>trim</code> <code>AnyTrim | None</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>None</code>"},{"location":"api/distributions/#lmo.distributions.l_poly.l_stats","title":"<code>lmo.distributions.l_poly.l_stats(trim=None, moments=4)</code>","text":"<p>Evaluate the L-moments (for \\(r \\le 2\\)) and L-ratio\u2019s (for \\(r &gt; 2\\)).</p> <p>Parameters:</p> Name Type Description Default <code>trim</code> <code>AnyTrim | None</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <code>None</code> <code>moments</code> <code>int</code> <p>The amount of L-moments to return. Defaults to 4.</p> <code>4</code>"},{"location":"api/distributions/#lmo.distributions.l_poly.l_loc","title":"<code>lmo.distributions.l_poly.l_loc(trim=None)</code>","text":"<p>L-location of the distribution, i.e. the 1st L-moment.</p> <p>Alias for <code>l_poly.l_moment(1, ...)</code>.</p> See Also <ul> <li><code>l_poly.l_moment</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.l_scale","title":"<code>lmo.distributions.l_poly.l_scale(trim=None)</code>","text":"<p>L-scale of the distribution, i.e. the 2nd L-moment.</p> <p>Alias for <code>l_poly.l_moment(2, ...)</code>.</p> See Also <ul> <li><code>l_poly.l_moment</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.l_skew","title":"<code>lmo.distributions.l_poly.l_skew(trim=None)</code>","text":"<p>L-skewness coefficient of the distribution; the 3rd L-moment ratio.</p> <p>Alias for <code>l_poly.l_ratio(3, 2, ...)</code>.</p> See Also <ul> <li><code>l_poly.l_ratio</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.l_kurtosis","title":"<code>lmo.distributions.l_poly.l_kurtosis(trim=None)</code>","text":"<p>L-kurtosis coefficient of the distribution; the 4th L-moment ratio.</p> <p>Alias for <code>l_poly.l_ratio(4, 2, ...)</code>.</p> See Also <ul> <li><code>l_poly.l_ratio</code></li> </ul>"},{"location":"api/distributions/#lmo.distributions.l_poly.nnlf","title":"<code>lmo.distributions.l_poly.nnlf(theta, x)</code>","text":"<p>Negative loglikelihood function.</p> <p>This is calculated as <code>-sum(log pdf(x, *theta), axis=0)</code>, where <code>theta</code> are the vector of L-moments, and optionally the trim.</p> Notes <p>This is mostly for compatibility <code>rv_generic</code>, and is impractically slow (due to the numerical inversion of the ppf).</p> <p>Parameters:</p> Name Type Description Default <code>theta</code> <code>_LPolyParams</code> <p>Tuple of size 1 or 2, with the L-moments vector, and optionally the trim (defaults to 0).</p> required <code>x</code> <code>NDArray[float64]</code> <p>Array-like with observations of shape <code>(n)</code> or <code>(n, *ks)</code>.</p> required <p>Returns:</p> Type Description <code>float | NDArray[float64]</code> <p>Scalar or array of shape <code>(*ks)</code> with negative loglikelihoods.</p>"},{"location":"api/low_level/","title":"Low-level API","text":""},{"location":"api/low_level/#lmo.constants","title":"<code>lmo.constants</code>","text":"<p>Mathematical constants.</p>"},{"location":"api/low_level/#lmo.constants.theta_m","title":"<code>lmo.constants.theta_m: Final[float] = 0.9553166181245093</code>  <code>module-attribute</code>","text":"<p>Magic angle \\( \\theta_m = \\arctan \\sqrt 2 \\).</p> See also <ul> <li>Magic angle - Wikipedia</li> </ul>"},{"location":"api/low_level/#lmo.constants.theta_m_bar","title":"<code>lmo.constants.theta_m_bar: Final[float] = 0.1520433619923482</code>  <code>module-attribute</code>","text":"<p>Magic number of turns \\( \\bar{\\theta}_m = \\theta_m / (2 \\pi) \\).</p> See also <ul> <li><code>lmo.constants.theta_m</code></li> <li>Magic angle - Wikipedia</li> <li>Turn (angle) - Wikipedia</li> </ul>"},{"location":"api/low_level/#lmo.linalg","title":"<code>lmo.linalg</code>","text":"<p>Linear algebra and linearized orthogonal polynomials.</p>"},{"location":"api/low_level/#lmo.linalg.sandwich","title":"<code>lmo.linalg.sandwich(A, X, /, dtype=np.float64)</code>","text":"<p>Calculates the \u201csandwich\u201d matrix product (<code>A @ X @ A.T</code>) along the specified <code>X</code> axis.</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>Array[tuple[_K, _R], floating[Any]]</code> <p>2-D array of shape <code>(k, r)</code>, the \u201cbread\u201d.</p> required <code>X</code> <code>Array[tuple[_R, *tuple[_R, ...]], floating[Any]]</code> <p>Array of shape <code>(r, r, ...)</code>.</p> required <code>dtype</code> <code>_DType[_TF]</code> <p>The data type of the result.</p> <code>float64</code> <p>Returns:</p> Name Type Description <code>C</code> <code>Array[tuple[_K, *tuple[_K, ...]], _TF]</code> <p>Array of shape <code>(k, k, ...)</code>.</p> See Also <ul> <li>https://wikipedia.org/wiki/Covariance_matrix</li> </ul>"},{"location":"api/low_level/#lmo.linalg.pascal","title":"<code>lmo.linalg.pascal(k, /, dtype=np.int64, *, inv=False)</code>","text":"<p>Construct the lower-diagonal Pascal matrix \\(L_{k \\times k\\)}$, or its matrix inverse \\(L^{-1}\\).</p> \\[ \\begin{align} L_{ij} &amp;= \\binom{i}{j} \\\\ L^{-1}_{ij} &amp;= (-1)^{i - j} L_{ij} \\end{align} \\] <p>Implemented using recursion, unlike the slow naive implementation from the equivalent <code>scipy.linalg.pascal</code> and <code>scipy.linalg.invpascal</code> functions using <code>kind='lower'</code>. By using the binomial recurrence relation, assuming \\(0 &lt; j &lt; i\\), \\(\\binom{i}{j} = \\frac{i}{j} \\binom{i-1}{j-1}\\), the following recursive definition is obtained:</p> \\[ L_{ij} = \\begin{cases}     0 &amp; \\text{if } i &lt; j \\text{,} \\\\     1 &amp; \\text{if } i = j \\vee j = 0 \\text{, and} \\\\     (i \\, L_{i-1,\\, j-1}) / j &amp; \\text{otherwise.} \\end{cases} \\] <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; pascal(4, dtype=np.int_)\narray([[1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 2, 1, 0],\n       [1, 3, 3, 1]])\n&gt;&gt;&gt; pascal(4, dtype=np.int_, inv=True)\narray([[ 1,  0,  0,  0],\n       [-1,  1,  0,  0],\n       [ 1, -2,  1,  0],\n       [-1,  3, -3,  1]])\n&gt;&gt;&gt; np.rint(np.linalg.inv(pascal(4))).astype(np.int_)\narray([[ 1,  0,  0,  0],\n       [-1,  1,  0,  0],\n       [ 1, -2,  1,  0],\n       [-1,  3, -3,  1]])\n</code></pre> <p>Now, let\u2019s compare with scipy:</p> <pre><code>&gt;&gt;&gt; import scipy.linalg\n&gt;&gt;&gt; scipy.linalg.invpascal(4, kind='lower').astype(np.int_)\narray([[ 1,  0,  0,  0],\n       [-1,  1,  0,  0],\n       [ 1, -2,  1,  0],\n       [-1,  3, -3,  1]])\n</code></pre>"},{"location":"api/low_level/#lmo.linalg.ir_pascal","title":"<code>lmo.linalg.ir_pascal(k, /, dtype)</code>","text":"<p>Inverse regulatized lower-diagonal Pascal matrix, \\(\\bar{L}_{ij} = L^{-1}_ij / i\\).</p> <p>Used to linearly combine order statistics order statistics into L-moments.</p>"},{"location":"api/low_level/#lmo.linalg.sh_legendre","title":"<code>lmo.linalg.sh_legendre(k, /, dtype=np.int64)</code>","text":"<p>Shifted Legendre polynomial coefficient matrix \\(\\widetilde{P}\\) of shape <code>(k, k)</code>.</p> <p>The \\(j\\)-th coefficient of the shifted Legendre polynomial of degree \\(k\\) is at \\((k, j)\\):</p> \\[ \\widetilde{p}_{k, j} = (-1)^{k - j} \\binom{k}{j} \\binom{k + j}{j} \\] <p>Useful for transforming probability-weighted moments into L-moments.</p> Danger <p>For \\(k \\ge 29\\), all 64-bits dtypes (default is int64) will overflow, which results in either an <code>OverflowError</code> (if you\u2019re lucky), or will give incorrect results. Similarly, all 32-bits dtypes (e.g. <code>np.int_</code> on Windows) already overflow when \\(k \\ge 16\\).</p> <p>This is not explicitly checked \u2013 so be sure to select the right <code>dtype</code> depending on <code>k</code>.</p> <p>One option is to use <code>dtype=np.object_</code>, which will use Python-native <code>int</code>. However, this is a lot slower, and is likely to fail. For instance, when multiplied together with some <code>float64</code> array, a <code>TypeError</code> is raised.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>_K</code> <p>The size of the matrix, and the max degree of the shifted Legendre polynomial.</p> required <code>dtype</code> <code>_DType[_TI]</code> <p>Desired output data type, e.g, <code>numpy.float64</code>. Must be signed. The default is <code>numpy.int64</code>.</p> <code>int64</code> <p>Returns:</p> Name Type Description <code>P</code> <code>_Square[_K, _TI]</code> <p>2-D array of the lower-triangular square matrix of size \\(k^2\\)`.</p> <p>Examples:</p> <p>Calculate \\(\\widetilde{P}_{4 \\times 4}\\):</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import sh_legendre\n&gt;&gt;&gt; sh_legendre(4, dtype=int)\narray([[  1,   0,   0,   0],\n       [ -1,   2,   0,   0],\n       [  1,  -6,   6,   0],\n       [ -1,  12, -30,  20]])\n</code></pre> See Also <ul> <li>https://wikipedia.org/wiki/Legendre_polynomials</li> <li>https://wikipedia.org/wiki/Pascal_matrix</li> </ul>"},{"location":"api/low_level/#lmo.linalg.sh_jacobi","title":"<code>lmo.linalg.sh_jacobi(k, a, b, /, dtype=np.float64)</code>","text":"<p>Shifted Jacobi polynomial coefficient matrix \\(\\widetilde{P}^{(a,b)}\\) of shape <code>(k, k)</code>.</p> <p>The \\(j\\)-th coefficient of the shifted Jacobi polynomial of degree \\(k\\) is at \\((k, j)\\):</p> <p>The \u201cshift\u201d refers to the change of variables \\(x \\mapsto 2x - 1\\) in the (unshifted) Jacobi (or hypergeometric) polynomials.</p> <p>The (shifted) Jacobi polynomials \\(\\widetilde{P}^{(a,b)}\\) generalize  the (shifted) Legendre polynomials \\(\\widetilde{P}\\): \\(\\widetilde{P}^{(0, 0)} = \\widetilde{P}\\)</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>_K</code> <p>The size of the matrix, and the max degree of the polynomial.</p> required <code>a</code> <code>float</code> <p>The \\(\\alpha\\) parameter, must be \\(\\ge 0\\).</p> required <code>b</code> <code>float</code> <p>The \\(\\beta\\) parameter, must be \\(\\ge 0\\).</p> required <code>dtype</code> <code>_DType[_TF]</code> <p>Desired output data type, e.g, <code>numpy.float64</code>. Default is <code>numpy.int64</code> if <code>a</code> and <code>b</code> are integers, otherwise <code>np.float64</code>.</p> <code>float64</code> <p>Returns:</p> Name Type Description <code>P</code> <code>_Square[_K, _TF]</code> <p>2-D array of the lower-triangular square matrix of size \\(k^2\\)`.</p> <p>Examples:</p> <p>Calculate \\(\\widetilde{P}^{(1, 1)}_{4 \\times 4}\\):</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import sh_jacobi\n&gt;&gt;&gt; sh_jacobi(4, 1, 1, dtype=int)\narray([[  1,   0,   0,   0],\n       [ -2,   4,   0,   0],\n       [  3, -15,  15,   0],\n       [ -4,  36, -84,  56]])\n</code></pre> <p>Let\u2019s compare \\(\\widetilde{P}^(1, \\pi)_3\\) with the scipy Jacobi poly1d. This requires manual shifting \\(x \\mapsto f(x)\\), with \\(f(x) = 2x - 1\\):</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scipy.special as sc\n&gt;&gt;&gt; f_x = np.poly1d([2, -1])  # f(x) = 2*x + 1\n&gt;&gt;&gt; sc.jacobi(3, 1, np.pi)(f_x)\npoly1d([ 125.80159497, -228.55053774,  128.54584648,  -21.79690371])\n&gt;&gt;&gt; sh_jacobi(4, 1, np.pi)[3]\narray([ -21.79690371,  128.54584648, -228.55053774,  125.80159497])\n</code></pre> <p>Apart from the reversed coefficients of <code>numpy.poly1d</code> (an awkward design choice, but it\u2019s fixed in the new <code>numpy.polynomial</code> module.)</p> See Also <ul> <li>https://mathworld.wolfram.com/JacobiPolynomial.html</li> <li><code>scipy.special.jacobi</code></li> </ul>"},{"location":"api/low_level/#lmo.linalg.succession_matrix","title":"<code>lmo.linalg.succession_matrix(c)</code>","text":"<p>A toeplitz-like transformation matrix construction, that prepends \\(i\\) zeroes to \\(i\\)-th row, so that the input shape is mapped from <code>(n, k)</code> to <code>(n, k + n)</code>.</p> <p>So all values \\(i &gt; j \\vee i + j \\ge k\\) are zero in the succession matrix.</p> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>Array[tuple[_K, int], _T] | Array[tuple[_K], _T]</code> <p>Dense matrix of shape <code>(n, k)</code>.</p> required <p>Returns:</p> Name Type Description <code>S</code> <code>Array[tuple[_K, int], _T]</code> <p>Matrix of shape <code>(n, k + n)</code></p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import succession_matrix\n&gt;&gt;&gt; c = np.arange(1, 9).reshape(4, 2)\n&gt;&gt;&gt; c\narray([[1, 2],\n       [3, 4],\n       [5, 6],\n       [7, 8]])\n&gt;&gt;&gt; succession_matrix(c)\narray([[1, 2, 0, 0, 0],\n       [0, 3, 4, 0, 0],\n       [0, 0, 5, 6, 0],\n       [0, 0, 0, 7, 8]])\n</code></pre>"},{"location":"api/low_level/#lmo.linalg.trim_matrix","title":"<code>lmo.linalg.trim_matrix(r, /, trim, dtype=np.float64)</code>","text":"<p>Linearization of the trimmed L-moment recurrence relations, following the (corrected) derivation by Hosking (2007) from the (shifted) Jacobi Polynomials.</p> <p>This constructs a \\(r \\times r + t_1 + t_2\\) matrix \\(T^{(t_1, t_2)}\\) that \u201ctrims\u201d conventional L-moments. E.g. the first 3 \\((1, 1)\\) trimmed L-moments can be obtained from the first \\(3+1+1=5\\) (untrimmed) L-moments (assuming they exist) with <code>trim_matrix(3, (1, 1)) @ l_moment(x, np.ogrid[:5] + 1)</code>.</p> <p>The big \u201cL\u201d in \u201cL-moment\u201d, referring to it being a Linear combination of order statistics, has been prominently put in the name by Hosking (1990) for a good reason. It means that transforming order statistics to a bunch of L-moments, can be done using a single matrix multiplication (see <code>lmo.linalg.sh_legendre</code>). By exploiting liniarity, it can easily be chained with this trim matrix, to obtain a reusable order-statistics -&gt; trimmed L-moments transformation (matrix).</p> <p>Note that these linear transformations can be used in exactly the same way to e.g. calculate several population TL-moments of some random varianble, using nothing but its theoretical probablity-weighted moments (PWMs).</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>_R</code> <p>The max (trimmed) L-moment order.</p> required <code>trim</code> <code>tuple[int, int]</code> <p>Left- and right-trim orders \\((t_1, t_2)\\), integers \\(\\ge 0\\). If set to (0, 0), the identity matrix is returned.</p> required <code>dtype</code> <code>_DType[_TF]</code> <p>Desired output data type, e.g, <code>numpy.float64</code> (default).</p> <code>float64</code> <p>Returns:</p> Type Description <code>Array[tuple[_R, int], _TF]</code> <p>Toeplitz-like matrix of shape \\((r, r + t_1 + t_2)\\).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import trim_matrix\n&gt;&gt;&gt; trim_matrix(3, (0, 1))\narray([[ 1.        , -1.        ,  0.        ,  0.        ],\n       [ 0.        ,  0.75      , -0.75      ,  0.        ],\n       [ 0.        ,  0.        ,  0.66666667, -0.66666667]])\n&gt;&gt;&gt; trim_matrix(3, (1, 0))\narray([[1.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.75      , 0.75      , 0.        ],\n       [0.        , 0.        , 0.66666667, 0.66666667]])\n</code></pre> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/low_level/#lmo.special","title":"<code>lmo.special</code>","text":"<p>Mathematical \u201cspecial\u201d functions, extending <code>scipy.special</code>.</p>"},{"location":"api/low_level/#lmo.special.fpow","title":"<code>lmo.special.fpow(x, n, /, out=None)</code>","text":"<pre><code>fpow(x: _Real_in, n: _Real_in, /, out: None = None) -&gt; _F8\n</code></pre><pre><code>fpow(x: _RealND_in, n: _Real_in | _RealND_in, /, out: None = None) -&gt; _F8ND\n</code></pre><pre><code>fpow(x: _Real_in, n: _RealND_in, /, out: None = None) -&gt; _F8ND\n</code></pre><pre><code>fpow(x: _RealND_in, n: _Real_in | _RealND_in, /, out: _ArrayT) -&gt; _ArrayT\n</code></pre><pre><code>fpow(x: _Real_in, n: _RealND_in, /, out: _ArrayT) -&gt; _ArrayT\n</code></pre> <p>Factorial power, or falling factorial.</p> <p>It is defined as</p> \\[     \\ffact{x}{n} = \\frac{\\Gamma(x + 1)}{\\Gamma(x - n + 1)} \\] <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_Real_in | _RealND_in</code> <p>Real-valued array-like or scalar.</p> required <code>n</code> <code>_Real_in | _RealND_in</code> <p>Real valued array-like or scalar.</p> required <code>out</code> <code>_ArrayT | None</code> <p>Optional output array for the function results</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>_ArrayT | _F8 | _F8ND</code> <p>Array or scalar with the value(s) of the function.</p> See Also <ul> <li><code>scipy.special.poch</code> \u2013 the rising factorial</li> </ul>"},{"location":"api/low_level/#lmo.special.gamma2","title":"<code>lmo.special.gamma2(a, x, /, out=None)</code>","text":"<pre><code>gamma2(a: _Real_in, x: _Real_in, /, out: None = None) -&gt; _F8\n</code></pre><pre><code>gamma2(a: _Real_in, x: _RealND_in, /, out: None = None) -&gt; _F8ND\n</code></pre><pre><code>gamma2(a: _Real_in, x: _RealND_in, /, out: _ArrayT) -&gt; _ArrayT\n</code></pre> <p>Incomplete (upper) gamma function.</p> <p>It is defined as</p> \\[     \\Gamma(a,\\ x) = \\int_x^\\infty t^{a-1} e^{-t} \\mathrm{d}t \\] <p>for \\( a \\ge 0 \\) and \\( x \\ge 0 \\).</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>_Real_in</code> <p>Real-valued non-negative scalar.</p> required <code>x</code> <code>_Real_in | _RealND_in</code> <p>Real-valued non-negative array-like.</p> required <code>out</code> <code>_ArrayT | None</code> <p>Optional output array for the results.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>_ArrayT | _F8 | _F8ND</code> <p>Scalar of array with the values of the incomplete gamma function.</p> See Also <ul> <li><code>scipy.special.gammaincc</code> for the   regularized gamma function \\( Q(a,\\ x) \\).</li> </ul>"},{"location":"api/low_level/#lmo.special.harmonic","title":"<code>lmo.special.harmonic(n, /, out=None)</code>","text":"<pre><code>harmonic(n: _Real_in, /, out: None = None) -&gt; float\n</code></pre><pre><code>harmonic(n: _RealND_in, /, out: None = None) -&gt; _F8ND\n</code></pre><pre><code>harmonic(n: _RealND_in, /, out: _ArrayT) -&gt; _ArrayT\n</code></pre> <p>Harmonic number \\( H_n = \\sum_{k=1}^{n} 1 / k \\), extended for real and complex argument via analytic contunuation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; harmonic(0)\n0.0\n&gt;&gt;&gt; harmonic(1)\n1.0\n&gt;&gt;&gt; harmonic(2)\n1.5\n&gt;&gt;&gt; harmonic(42)\n4.32674\n&gt;&gt;&gt; harmonic(np.pi)\n1.87274\n&gt;&gt;&gt; harmonic(-1 / 12)\n-0.146106\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>_Real_in | _RealND_in</code> <p>Real- or complex- valued parameter, as array-like or scalar.</p> required <code>out</code> <code>_ArrayT | None</code> <p>Optional real or complex output array for the results.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>out</code> <code>_ArrayT | float | _F8ND</code> <p>Array or scalar with the value(s) of the function.</p> See Also <ul> <li>Harmonic number - Wikipedia</li> </ul>"},{"location":"api/low_level/#lmo.special.norm_sh_jacobi","title":"<code>lmo.special.norm_sh_jacobi(n, alpha, beta)</code>","text":"<pre><code>norm_sh_jacobi(n: AnyOrder, alpha: float, beta: float) -&gt; _F8\n</code></pre><pre><code>norm_sh_jacobi(n: AnyOrderND, alpha: float, beta: float) -&gt; _F8ND\n</code></pre> <p>Evaluate the (weighted) \\( L^2 \\)-norm of a shifted Jacobi polynomial.</p> <p>Specifically,</p> \\[     \\| p_n \\|^2     = \\braket{p_n | p_n}     = \\int_0^1 |p_n|^2 \\mathrm{d}x     = \\frac{1}{2 n + \\alpha + \\beta + 1} \\frac         {\\Gamma(n + \\alpha + 1) \\Gamma(n + \\beta + 1)}         {n! \\ \\Gamma(n + \\alpha + \\beta + 1)} \\] <p>with</p> \\[     p_n(x) \\equiv         x^{\\beta / 2} \\         (1 - x)^{\\alpha / 2} \\         \\shjacobi{n}{\\alpha}{\\beta}{x} \\] <p>the normalized Jacobi polynomial on \\( [0, 1] \\).</p>"},{"location":"api/low_level/#lmo.special.fourier_jacobi","title":"<code>lmo.special.fourier_jacobi(x, c, a, b)</code>","text":"<pre><code>fourier_jacobi(x: _Real_in, c: _RealND_in, a: float, b: float) -&gt; _F8\n</code></pre><pre><code>fourier_jacobi(x: _RealND_in, c: _RealND_in, a: float, b: float) -&gt; _F8ND\n</code></pre> <p>Evaluate the Fourier-Jacobi series, using the Clenshaw summation algorithm.</p> <p>If \\( c \\) is of length \\( n + 1 \\), this function returns the value:</p> \\[     c_0 \\cdot \\jacobi{0}{a}{b}{x} +     c_1 \\cdot \\jacobi{1}{a}{b}{x} +     \\ldots +     c_n \\cdot \\jacobi{n}{a}{b}{x} \\] <p>Here, \\( \\jacobi{n}{a}{b}{x} \\) is a Jacobi polynomial of degree \\( n = |\\vec{c}| \\), which is orthogonal iff \\( (a, b) \\in (-1,\\ \\infty)^2 \\) and \\( x \\in [0,\\ 1] \\).</p> Tip <p>Trailing zeros in the coefficients will be used in the evaluation, so they should be avoided if efficiency is a concern.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>_Real_in | _RealND_in</code> <p>Scalar or array-like with input data.</p> required <code>c</code> <code>_RealND_in</code> <p>Array-like of coefficients, ordered from low to high. All coefficients to the right are considered zero.</p> <p>For instance, <code>[4, 3, 2]</code> gives \\( 4 \\jacobi{0}{a}{b}{x} + 3 \\jacobi{1}{a}{b}{x} + 2 \\jacobi{2}{a}{b}{x} \\).</p> required <code>a</code> <code>float</code> <p>Jacobi parameter \\( a &gt; -1 \\).</p> required <code>b</code> <code>float</code> <p>Jacobi parameter \\( a &gt; -1 \\).</p> required <p>Returns:</p> Name Type Description <code>out</code> <code>_F8 | _F8ND</code> <p>Scalar or array of same shape as <code>x</code>.</p> See Also <ul> <li>Generalized Fourier series - Wikipedia</li> <li>Clenshaw Recurrence Formula - Wolfram MathWorld</li> <li>Jacobi Polynomial - Worlfram Mathworld</li> </ul>"},{"location":"api/low_level/#lmo.theoretical","title":"<code>lmo.theoretical</code>","text":"<p>Theoretical (population) L-moments of known univariate probability distributions.</p>"},{"location":"api/low_level/#lmo.theoretical.cdf_from_ppf","title":"<code>lmo.theoretical.cdf_from_ppf(ppf)</code>","text":"<p>Numerical inversion of the PPF.</p> Note <p>This function isn\u2019t vectorized.</p>"},{"location":"api/low_level/#lmo.theoretical.entropy_from_qdf","title":"<code>lmo.theoretical.entropy_from_qdf(qdf, /, *args, **kwds)</code>","text":"<pre><code>entropy_from_qdf(qdf: _QDF[[]]) -&gt; float\n</code></pre><pre><code>entropy_from_qdf(qdf: _QDF[_Tss], /, *args: _Tss.args, **kwds: _Tss.kwargs) -&gt; float\n</code></pre> <p>Evaluate the (differential / continuous) entropy \\( H(X) \\) of a univariate random variable \\( X \\), from its quantile density function (QDF), \\( q(u) = \\frac{\\mathrm{d} F^{-1}(u)}{\\mathrm{d} u} \\), with \\( F^{-1} \\) the inverse of the CDF, i.e. the PPF / quantile function.</p> <p>The derivation follows from the identity \\( f(x) = 1 / q(F(x)) \\) of PDF \\( f \\), specifically:</p> \\[     h(X)         = \\E[-\\ln f(X)]         = \\int_\\mathbb{R} \\ln \\frac{1}{f(x)} \\mathrm{d} x         = \\int_0^1 \\ln q(u) \\mathrm{d} u \\] <p>Parameters:</p> Name Type Description Default <code>qdf</code> <code> (float, *Tss.args, **Tss.kwargs) -&gt; float</code> <p>The quantile distribution function (QDF).</p> required <code>*args</code> <code>args</code> <p>Optional additional positional arguments to pass to <code>qdf</code>.</p> <code>()</code> <code>**kwds</code> <code>kwargs</code> <p>Optional keyword arguments to pass to <code>qdf</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>float</code> <p>The differential entropy \\( H(X) \\).</p> See Also <ul> <li>Differential entropy - Wikipedia </li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_comoment_from_pdf","title":"<code>lmo.theoretical.l_comoment_from_pdf(pdf, cdfs, r, /, trim=0, *, supports=None, quad_opts=None)</code>","text":"<p>Evaluate the theoretical L-comoment matrix of a multivariate probability distribution, using the joint PDF \\(f(\\vec x) \\equiv f(x_1, x_2, \\ldots, x_n)\\) of random vector \\(\\vec{X}\\), and the marginal CDFs \\(F_k\\) of its \\(k\\)-th random variable.</p> <p>The L-comoment matrix is defined as</p> \\[ \\Lambda_{r}^{(s, t)} =     \\left[         \\lambda_{r [ij]}^{(s, t)}     \\right]_{n \\times n} \\;, \\] <p>with elements</p> \\[ \\begin{align*} \\lambda_{r [ij]}^{(s, t)}     &amp;= c^{(s,t)}_r \\int_{\\mathbb{R^n}}         x_i \\         u_j^s \\         (1 - u_j)^t \\         \\widetilde{P}^{(t, s)}_{r - 1} (u_j) \\         f(\\vec{x}) \\         \\mathrm{d} \\vec{x} \\\\     &amp;= c^{(s,t)}_r \\, \\mathbb{E}_{\\vec{X}} \\left[         X_i \\         U_j^s \\         (1 - U_j)^t \\         \\widetilde{P}^{(t, s)}_{r - 1}(U_j)     \\right]     \\, , \\end{align*} \\] <p>where \\(U_j = F_j(X_j)\\) and \\(u_j = F_j(x_j)\\) denote the (marginal) probability integral transform  of \\(X_j\\) and \\(x_j \\sim X_j\\). Furthermore, \\(\\widetilde{P}^{(\\alpha, \\beta)}_k\\) is a shifted Jacobi polynomial, and</p> \\[ c^{(s,t)}_r =     \\frac{r + s + t}{r}     \\frac{\\B(r,\\ r + s + t)}{\\B(r + s,\\ r + t)} \\; , \\] <p>a positive constant.</p> <p>For \\(r \\ge 2\\), it can also be expressed as</p> \\[ \\lambda_{r [ij]}^{(s, t)}     = c^{(s,t)}_r \\mathrm{Cov} \\left[         X_i, \\;         U_j^s \\         (1 - U_j)^t \\         \\widetilde{P}^{(t, s)}_{r - 1}(U_j)     \\right] \\;     , \\] <p>and without trim (\\(s = t = 0\\)), this simplifies to</p> \\[ \\lambda_{r [ij]}     = \\mathrm{Cov} \\left[         X_i ,\\;         \\widetilde{P}_{r - 1} (U_j)     \\right] \\;     , \\] <p>with \\(\\tilde{P}_n = \\tilde{P}^{(0, 0)}_n\\) the shifted Legendre polynomial. This last form is precisely the definition introduced by Serfling &amp; Xiao (2007).</p> <p>Note that the L-comoments along the diagonal, are equivalent to the (univariate) L-moments, i.e.</p> \\[ \\lambda_{r [ii]}^{(s, t)}\\big( \\vec{X} \\big)     = \\lambda_{r}^{(s, t)}\\big( X_i \\big) \\;. \\] Notes <p>At the time of writing, trimmed L-comoments have not been explicitly defined in the literature. Instead, the author (@jorenham) derived it by generizing the (untrimmed) L-comoment definition by Serfling &amp; Xiao (2007), analogous to the generalization of L-moments into TL-moments by Elamir &amp; Seheult (2003).</p> <p>Examples:</p> <p>Find the L-coscale and TL-coscale matrices of the multivariate Student\u2019s t distribution with 4 degrees of freedom:</p> <pre><code>&gt;&gt;&gt; from scipy.stats import multivariate_t\n&gt;&gt;&gt; df = 4\n&gt;&gt;&gt; loc = np.array([0.5, -0.2])\n&gt;&gt;&gt; cov = np.array([[2.0, 0.3], [0.3, 0.5]])\n&gt;&gt;&gt; X = multivariate_t(loc=loc, shape=cov, df=df)\n</code></pre> <pre><code>&gt;&gt;&gt; from scipy.special import stdtr\n&gt;&gt;&gt; std = np.sqrt(np.diag(cov))\n&gt;&gt;&gt; cdf0 = lambda x: stdtr(df, (x - loc[0]) / std[0])\n&gt;&gt;&gt; cdf1 = lambda x: stdtr(df, (x - loc[1]) / std[1])\n</code></pre> <pre><code>&gt;&gt;&gt; l_cov = l_comoment_from_pdf(X.pdf, (cdf0, cdf1), 2)\n&gt;&gt;&gt; l_cov.round(4)\narray([[1.0413, 0.3124],\n       [0.1562, 0.5207]])\n&gt;&gt;&gt; tl_cov = l_comoment_from_pdf(X.pdf, (cdf0, cdf1), 2, trim=1)\n&gt;&gt;&gt; tl_cov.round(4)\narray([[0.4893, 0.1468],\n       [0.0734, 0.2447]])\n</code></pre> <p>The (Pearson) correlation coefficient can be recovered in several ways:</p> <pre><code>&gt;&gt;&gt; cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])  # \"true\" correlation\n0.3\n&gt;&gt;&gt; l_cov[0, 1] / l_cov[0, 0]\n0.3\n&gt;&gt;&gt; l_cov[1, 0] / l_cov[1, 1]\n0.3\n&gt;&gt;&gt; tl_cov[0, 1] / tl_cov[0, 0]\n0.3\n&gt;&gt;&gt; tl_cov[1, 0] / tl_cov[1, 1]\n0.3\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>pdf</code> <code>Callable[[_ArrF8], float] | Callable[[_ArrF8], float64]</code> <p>Joint Probability Distribution Function (PDF), that accepts a float vector of size \\(n\\), and returns a scalar in \\([0, 1]\\).</p> required <code>cdfs</code> <code>Sequence[_Fn1]</code> <p>Sequence with \\(n\\) marginal CDF\u2019s.</p> required <code>r</code> <code>AnyOrder</code> <p>Non-negative integer \\(r\\) with the L-moment order.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim, either as a \\((s, t)\\) tuple with \\(s, t &gt; -1/2\\), or \\(t\\) as alias for \\((t, t)\\).</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>supports</code> <code>Sequence[_Pair[float]] | None</code> <p>A sequence with \\(n\\) 2-tuples, corresponding to the marginal integration limits. Defaults to \\([(-\\infty, \\infty), \\dots]\\).</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p>Returns:</p> Name Type Description <code>lmbda</code> <code>_ArrF8</code> <p>The population L-comoment matrix with shape \\(n \\times n\\).</p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>R. Serfling &amp; P. Xiao (2007) - A Contribution to Multivariate   L-Moments: L-Comoment   Matrices</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_coratio_from_pdf","title":"<code>lmo.theoretical.l_coratio_from_pdf(pdf, cdfs, r, r0=2, /, trim=0, *, supports=None, quad_opts=None)</code>","text":"<p>Evaluate the theoretical L-comoment ratio matrix of a multivariate probability distribution, using the joint PDF \\(f_{\\vec{X}}(\\vec{x})\\) and \\(n\\) marginal CDFs \\(F_X(x)\\) of random vector \\(\\vec{X}\\).</p> \\[ \\tilde \\Lambda_{r,r_0}^{(s, t)} =     \\left[         \\left. \\lambda_{r [ij]}^{(s, t)} \\right/         \\lambda_{r_0 [ii]}^{(s, t)}     \\right]_{n \\times n} \\] See Also <ul> <li><code>l_comoment_from_pdf</code></li> <li><code>lmo.l_coratio</code></li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_moment_from_cdf","title":"<code>lmo.theoretical.l_moment_from_cdf(cdf, r, /, trim=0, *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<pre><code>l_moment_from_cdf(\n    cdf: _Fn1 | Callable[[float], float],\n    r: lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] | None = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n    ppf: _Fn1 | None = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_moment_from_cdf(\n    cdf: _Fn1 | Callable[[float], float],\n    r: lmt.AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] | None = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n    ppf: _Fn1 | None = ...,\n) -&gt; np.float64\n</code></pre> <p>Evaluate the population L-moment of a continuous probability distribution, using its Cumulative Distribution Function (CDF) \\(F_X(x) = P(X \\le x)\\).</p> \\[ \\lambda^{(s, t)}_r = \\begin{cases}     1 &amp; r = 0 \\\\     \\displaystyle     \\int_{\\mathbb{R}}         \\left(H(x) - I_u(s + 1,\\ t + 1)\\right) \\         \\mathrm{d} x     &amp; r = 1 \\\\     \\displaystyle     \\frac{c^{(s,t)}_r}{r}     \\int_{\\mathbb{R}}         u^{s + 1}         \\left(1 - u\\right)^{t + 1} \\         \\widetilde{P}^{(t + 1, s + 1)}_{r - 2}(u) \\         \\mathrm{d} x     &amp; r &gt; 1 \\; , \\end{cases} \\] <p>where,</p> \\[ c^{(s,t)}_r =     \\frac{r + s + t}{r}     \\frac{\\B(r,\\ r + s + t)}{\\B(r + s,\\ r + t)} \\; , \\] <p>\\(\\widetilde{P}^{(\\alpha, \\beta)}_k(x)\\) the shifted (\\(x \\mapsto 2x-1\\)) Jacobi polynomial, \\(H(x)\\) the Heaviside step function, and \\(I_x(\\alpha, \\beta)\\) the regularized incomplete gamma function, and \\(u = F_X(x)\\) the probability integral transform of \\(x \\sim X\\).</p> Notes <p>Numerical integration is performed with <code>scipy.integrate.quad</code>, which cannot verify whether the integral exists and is finite. If it returns an error message, an <code>IntegrationWarning</code> is issues, and <code>nan</code> is returned (even if <code>quad</code> returned a finite result).</p> <p>Examples:</p> <p>Evaluate the first 4 L- and TL-moments of the standard normal distribution:</p> <pre><code>&gt;&gt;&gt; from scipy.special import ndtr  # standard normal CDF\n&gt;&gt;&gt; l_moment_from_cdf(ndtr, [1, 2, 3, 4])\narray([0.        , 0.56418958, 0.        , 0.06917061])\n&gt;&gt;&gt; l_moment_from_cdf(ndtr, [1, 2, 3, 4], trim=1)\narray([0.        , 0.29701138, 0.        , 0.01855727])\n</code></pre> <p>Evaluate the first 4 TL-moments of the standard Cauchy distribution:</p> <pre><code>&gt;&gt;&gt; def cdf_cauchy(x: float) -&gt; float:\n...     return np.arctan(x) / np.pi + 1 / 2\n&gt;&gt;&gt; l_moment_from_cdf(cdf_cauchy, [1, 2, 3, 4], trim=1)\narray([0.        , 0.69782723, 0.        , 0.23922105])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cdf</code> <code>_Fn1 | Callable[[float], float]</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> required <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim, either as a \\((s, t)\\) tuple with \\(s, t &gt; -1/2\\), or \\(t\\) as alias for \\((t, t)\\).</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>support</code> <code>_Pair[float] | None</code> <p>The subinterval of the nonzero domain of <code>cdf</code>. Generally it\u2019s not needed to provide this, as it will be guessed automatically.</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>alpha</code> <code>float</code> <p>Split the integral into integrals with limits \\([a, F^{-1}(\\alpha)]\\), \\([F(\\alpha), F^{-1}(1 - \\alpha)]\\) and \\([F^{-1}(1 - \\alpha), b]\\) to improve numerical stability. So \\(\\alpha\\) can be consideresd the size of the tail. Numerical experiments have found 0.05 to give good results for different distributions.</p> <code>ppf</code> <code>_Fn1 | None</code> <p>The inverse of the cdf, used with <code>alpha</code> to calculate the integral split points (if provided).</p> <p>Raises:</p> Type Description <code>TypeError</code> <p><code>r</code> is not integer-valued or negative</p> <code>ValueError</code> <p><code>r</code> is negative</p> <p>Returns:</p> Name Type Description <code>lmbda</code> <code>float64 | _ArrF8</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>. If <code>nan</code>, consult the related <code>IntegrationWarning</code> message.</p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul> See Also <ul> <li><code>theoretical.l_moment_from_ppf</code>:   population L-moment, using the inverse CDF</li> <li><code>l_moment</code>: sample L-moment</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_moment_from_ppf","title":"<code>lmo.theoretical.l_moment_from_ppf(ppf, r, /, trim=0, *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<pre><code>l_moment_from_ppf(\n    ppf: _Fn1 | Callable[[float], float],\n    r: lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_moment_from_ppf(\n    ppf: _Fn1 | Callable[[float], float],\n    r: lmt.AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; np.float64\n</code></pre> <p>Evaluate the population L-moment of a univariate probability distribution, using its Percentile Function (PPF), \\(x(F)\\), also commonly known as the quantile function, which is the inverse of the Cumulative Distribution Function (CDF).</p> \\[ \\lambda^{(s, t)}_r =     c^{(s, t)}_r     \\int_0^1         F^s (1 - F)^t \\         \\widetilde{P}^{(t, s)}_{r - 1}(F) \\         x(F) \\         \\mathrm{d} F \\; , \\] <p>where</p> \\[ c^{(s,t)}_r = \\frac{r+s+t}{r} \\frac{B(r,\\,r+s+t)}{B(r+s,\\,r+t)} \\;, \\] <p>and \\(\\widetilde{P}^{(\\alpha, \\beta)}_k(x)\\) the shifted (\\(x \\mapsto 2x-1\\)) Jacobi polynomial.</p> Notes <p>Numerical integration is performed with <code>scipy.integrate.quad</code>, which cannot verify whether the integral exists and is finite. If it returns an error message, an <code>IntegrationWarning</code> is issues, and <code>nan</code> is returned (even if <code>quad</code> returned a finite result).</p> <p>Examples:</p> <p>Evaluate the L- and TL-location and -scale of the standard normal distribution:</p> <pre><code>&gt;&gt;&gt; from scipy.special import ndtri  # standard normal inverse CDF\n&gt;&gt;&gt; l_moment_from_ppf(ndtri, [1, 2])\narray([0.        , 0.56418958])\n&gt;&gt;&gt; l_moment_from_ppf(ndtri, [1, 2], trim=1)\narray([0.        , 0.29701138])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ppf</code> <code>_Fn1 | Callable[[float], float]</code> <p>The quantile function \\(x(F)\\), a monotonically continuous increasing function with signature <code>(float) -&gt; float</code>, that maps a probability in \\([0, 1]\\), to the domain of the distribution.</p> required <code>r</code> <code>AnyOrder | AnyOrderND</code> <p>L-moment order(s), non-negative integer or array-like of integers. E.g. 0 gives 1, 1 the L-location, 2 the L-scale, etc.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim, either as a \\((s, t)\\) tuple with \\(s, t &gt; -1/2\\), or \\(t\\) as alias for \\((t, t)\\).</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>support</code> <code>_Pair[float]</code> <p>Integration limits. Defaults to (0, 1), as it should. There is no need to change this to anything else, and only exists to make the function signature consistent with the <code>*_from_cdf</code> analogue.</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>alpha</code> <code>float</code> <p>Split the integral into integrals with limits \\([0, \\alpha]\\), \\([\\alpha, 1-\\alpha]\\) and \\([1-\\alpha, 0]\\) to improve numerical stability. So \\(\\alpha\\) can be consideresd the size of the tail. Numerical experiments have found 0.1 to give good results for different distributions.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Invalid <code>r</code> or <code>trim</code> types.</p> <code>ValueError</code> <p>Invalid <code>r</code> or <code>trim</code> values.</p> <p>Returns:</p> Name Type Description <code>lmbda</code> <code>float64 | _ArrF8</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>. If <code>nan</code>, consult the related <code>IntegrationWarning</code> message.</p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul> See Also <ul> <li><code>theoretical.l_moment_from_cdf</code>:   population L-moment, using the CDF (i.e. the inverse PPF)</li> <li><code>l_moment</code>: sample L-moment</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_moment_from_qdf","title":"<code>lmo.theoretical.l_moment_from_qdf(qdf, r, /, trim=0, *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<pre><code>l_moment_from_qdf(\n    qdf: _Fn1 | Callable[[float], float],\n    r: lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_moment_from_qdf(\n    qdf: _Fn1 | Callable[[float], float],\n    r: lmt.AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; np.float64\n</code></pre> <p>Evaluate the population L-moments \\( \\tlmoment{s, t}{r} \\) for \\( r &gt; 1 \\) from the quantile distribution function (QDF), which is the derivative of the PPF (quantile function).</p>"},{"location":"api/low_level/#lmo.theoretical.l_ratio_from_cdf","title":"<code>lmo.theoretical.l_ratio_from_cdf(cdf, r, s, /, trim=0, *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<pre><code>l_ratio_from_cdf(\n    cdf: _Fn1,\n    r: lmt.AnyOrderND,\n    s: lmt.AnyOrder | lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] | None = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n    ppf: _Fn1 | None = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_ratio_from_cdf(\n    cdf: _Fn1,\n    r: lmt.AnyOrder | lmt.AnyOrderND,\n    s: lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] | None = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n    ppf: _Fn1 | None = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_ratio_from_cdf(\n    cdf: _Fn1,\n    r: lmt.AnyOrder,\n    s: lmt.AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] | None = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; np.float64\n</code></pre> <p>Population L-ratio\u2019s from a CDF.</p> See Also <ul> <li><code>l_ratio_from_ppf</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_ratio_from_ppf","title":"<code>lmo.theoretical.l_ratio_from_ppf(ppf, r, s, /, trim=0, *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<pre><code>l_ratio_from_ppf(\n    ppf: _Fn1,\n    r: lmt.AnyOrderND,\n    s: lmt.AnyOrder | lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_ratio_from_ppf(\n    ppf: _Fn1,\n    r: lmt.AnyOrder | lmt.AnyOrderND,\n    s: lmt.AnyOrderND,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; _ArrF8\n</code></pre><pre><code>l_ratio_from_ppf(\n    ppf: _Fn1,\n    r: lmt.AnyOrder,\n    s: lmt.AnyOrder,\n    /,\n    trim: lmt.AnyTrim = ...,\n    *,\n    support: _Pair[float] = ...,\n    quad_opts: lspt.QuadOptions | None = ...,\n    alpha: float = ...,\n) -&gt; np.float64\n</code></pre> <p>Population L-ratio\u2019s from a PPF.</p> See Also <ul> <li><code>l_ratio_from_cdf</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_stats_from_cdf","title":"<code>lmo.theoretical.l_stats_from_cdf(cdf, num=4, /, trim=0, *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<p>Calculates the theoretical- / population- L-moments (for \\(r \\le 2\\)) and L-ratio\u2019s (for \\(r &gt; 2\\)) of a distribution, from its CDF.</p> <p>By default, the first <code>num = 4</code> population L-stats are calculated:</p> <ul> <li>\\(\\lambda^{(s,t)}_1\\) - L-location</li> <li>\\(\\lambda^{(s,t)}_2\\) - L-scale</li> <li>\\(\\tau^{(s,t)}_3\\) - L-skewness coefficient</li> <li>\\(\\tau^{(s,t)}_4\\) - L-kurtosis coefficient</li> </ul> <p>This function is equivalent to <code>l_ratio_from_cdf(cdf, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code>.</p> Note <p>This should not be confused with the term L-statistic, which is sometimes used to describe any linear combination of order statistics.</p> See Also <ul> <li><code>l_stats_from_ppf</code> - Population     L-stats from the quantile function.</li> <li><code>l_ratio_from_cdf</code> - Generalized     population L-ratio\u2019s from the CDF.</li> <li><code>lmo.l_stats</code> - Unbiased sample estimation of L-stats.</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_stats_from_ppf","title":"<code>lmo.theoretical.l_stats_from_ppf(ppf, num=4, /, trim=0, *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<p>Calculates the theoretical- / population- L-moments (for \\(r \\le 2\\)) and L-ratio\u2019s (for \\(r &gt; 2\\)) of a distribution, from its quantile function.</p> <p>By default, the first <code>num = 4</code> population L-stats are calculated:</p> <ul> <li>\\(\\lambda^{(s,t)}_1\\) - L-location</li> <li>\\(\\lambda^{(s,t)}_2\\) - L-scale</li> <li>\\(\\tau^{(s,t)}_3\\) - L-skewness coefficient</li> <li>\\(\\tau^{(s,t)}_4\\) - L-kurtosis coefficient</li> </ul> <p>This function is equivalent to <code>l_ratio_from_cdf(cdf, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code>.</p> Note <p>This should not be confused with the term L-statistic, which is sometimes used to describe any linear combination of order statistics.</p> See Also <ul> <li><code>l_stats_from_cdf</code> - Population     L-stats from the CDF.</li> <li><code>l_ratio_from_ppf</code> - Generalized     population L-ratio\u2019s from the quantile function.</li> <li><code>lmo.l_stats</code> - Unbiased sample estimation of L-stats.</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_moment_cov_from_cdf","title":"<code>lmo.theoretical.l_moment_cov_from_cdf(cdf, r_max, /, trim=0, *, support=None, quad_opts=None)</code>","text":"<p>L-moments that are estimated from \\(n\\) samples of a distribution with CDF \\(F\\), converge to the multivariate normal distribution as the sample size \\(n \\rightarrow \\infty\\).</p> \\[ \\sqrt{n} \\left(     \\vec{l}^{(s, t)} - \\vec{\\lambda}^{(s, t)} \\right) \\sim \\mathcal{N}(     \\vec{0},     \\mathbf{\\Lambda}^{(s, t)} ) \\] <p>Here, \\(\\vec{l}^{(s, t)} = \\left[l^{(s, t)}_r, \\dots, l^{(s, t)}_{r_{max}} \\right]^T\\) is a vector of estimated sample L-moments, and \\(\\vec{\\lambda}^{(s, t)}\\) its theoretical (\u201ctrue\u201d) counterpart.</p> <p>This function calculates the covariance matrix</p> \\[ \\begin{align*} \\bf{\\Lambda}^{(s,t)}_{k, r}     &amp;= \\mathrm{Cov}[l^{(s, t)}_k, l^{(s, t)}_r] \\\\     &amp;= c_k c_r     \\iint\\limits_{x &lt; y} \\left(         p^{(s, t)}_k(u) \\ p^{(s, t)}_r(v) +         p^{(s, t)}_r(u) \\ p^{(s, t)}_k(v)     \\right) \\     w^{(s + 1,\\ t)}(u) \\     w^{(s,\\ t + 1)}(v) \\     \\mathrm{d} x \\     \\mathrm{d} y \\; , \\end{align*} \\] <p>where \\(u = F_X(x)\\) and \\(v = F_Y(y)\\) (marginal) probability integral transforms, and</p> \\[ c_n = \\frac{\\Gamma(n) \\Gamma(n+s+t+1)}{n \\Gamma(n+s) \\Gamma(n+t)}\\;, \\] <p>the shifted Jacobi polynomial \\(p^{(s, t)}_n(u) = P^{(t, s)}_{n-1}(2u - 1)\\), \\(P^{(t, s)}_m\\), and \\(w^{(s, t)}(u) = u^s (1 - u)^t\\) its weight function.</p> Notes <p>This function uses <code>scipy.integrate.nquad</code> for numerical integration. Unexpected results may be returned if the integral does not exist, or does not converge. The results are rounded to match the order of magnitude of the absolute error of <code>scipy.integrate.nquad</code>.</p> <p>This function is not vectorized or parallelized.</p> <p>For small sample sizes (\\(n &lt; 100\\)), the covariances of the higher-order L-moments (\\(r &gt; 2\\)) can be biased. But this bias quickly disappears at roughly \\(n &gt; 200\\) (depending on the trim- and L-moment orders).</p> <p>Parameters:</p> Name Type Description Default <code>cdf</code> <code>_Fn1</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> required <code>r_max</code> <code>AnyOrder</code> <p>The amount of L-moment orders to consider. If for example <code>r_max = 4</code>, the covariance matrix will be of shape <code>(4, 4)</code>, and the columns and rows correspond to the L-moments of order \\(r = 1, \\dots, r_{max}\\).</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Must be a tuple of two non-negative ints or floats.</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>support</code> <code>_Pair[float] | None</code> <p>The subinterval of the nonzero domain of <code>cdf</code>. Generally it\u2019s not needed to provide this, as it will be guessed automatically.</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p>Returns:</p> Name Type Description <code>cov</code> <code>_ArrF8</code> <p>Covariance matrix, with shape <code>(r_max, r_max)</code>.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the covariance matrix is invalid.</p> See Also <ul> <li><code>l_moment_from_cdf</code> -     Population L-moments from the cumulative distribution function</li> <li><code>l_moment_from_ppf</code> -     Population L-moments from the quantile function</li> <li><code>lmo.l_moment</code> - Unbiased L-moment estimation from     samples</li> <li><code>lmo.l_moment_cov</code> - Distribution-free exact     L-moment exact covariance estimate.</li> </ul> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_stats_cov_from_cdf","title":"<code>lmo.theoretical.l_stats_cov_from_cdf(cdf, /, num=4, trim=0, *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<p>Similar to <code>l_moment_from_cdf</code>, but for the <code>lmo.l_stats</code>.</p> <p>As the sample size \\(n \\rightarrow \\infty\\), the L-moment ratio\u2019s are also distributed (multivariate) normally. The L-stats are defined to be L-moments for \\(r\\le 2\\), and L-ratio coefficients otherwise.</p> <p>The corresponding covariance matrix has been found to be</p> \\[ \\bf{T}^{(s, t)}_{k, r} = \\begin{cases}     \\bf{\\Lambda}^{(s, t)}_{k, r}         &amp; k \\le 2 \\wedge r \\le 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}     }{         \\lambda^{(s,t)}_{2}     }         &amp; k \\le 2 \\wedge r &gt; 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_k \\bf{\\Lambda}^{(s, t)}_{2, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}         + \\tau_k \\tau_r \\bf{\\Lambda}^{(s, t)}_{2, 2}     }{         \\Big( \\lambda^{(s,t)}_{2} \\Big)^2     }         &amp; k &gt; 2 \\wedge r &gt; 2 \\end{cases} \\] <p>where \\(\\bf{\\Lambda}^{(s, t)}\\) is the covariance matrix of the L-moments from <code>l_moment_cov_from_cdf</code>, and \\(\\tau^{(s,t)}_r = \\lambda^{(s,t)}_r / \\lambda^{(s,t)}_2\\) the population L-ratio.</p> <p>Parameters:</p> Name Type Description Default <code>cdf</code> <code>_Fn1</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> required <code>num</code> <code>AnyOrder</code> <p>The amount of L-statistics to return. Defaults to 4.</p> <code>4</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim. Must be a tuple of two non-negative ints or floats.</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>support</code> <code>_Pair[float] | None</code> <p>The subinterval of the nonzero domain of <code>cdf</code>. Generally it\u2019s not needed to provide this, as it will be guessed automatically.</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>alpha</code> <code>float</code> <p>Two-sided quantile to split the integral at.</p> <code>ppf</code> <code>_Fn1 | None</code> <p>Quantile function, for calculating the split integral limits.</p> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_moment_influence_from_cdf","title":"<code>lmo.theoretical.l_moment_influence_from_cdf(cdf, r, /, trim=0, *, support=None, l_moment=None, quad_opts=None, alpha=ALPHA, tol=1e-08)</code>","text":"<p>Influence Function (IF) of a theoretical L-moment.</p> \\[ \\psi_{\\lambda^{(s, t)}_r | F}(x)     = c^{(s,t)}_r     \\, F(x)^s     \\, \\big( 1-{F}(x) \\big)^t     \\, \\tilde{P}^{(s,t)}_{r-1} \\big( F(x) \\big)     \\, x     - \\lambda^{(s,t)}_r     \\;, \\] <p>with \\(F\\) the CDF, \\(\\tilde{P}^{(s,t)}_{r-1}\\) the shifted Jacobi polynomial, and</p> \\[ c^{(s,t)}_r     = \\frac{r+s+t}{r} \\frac{B(r, \\, r+s+t)}{B(r+s, \\, r+t)}     \\;, \\] <p>where \\(B\\) is the (complete) Beta function.</p> <p>The proof is trivial, because population L-moments are linear functionals.</p> Notes <p>The order parameter <code>r</code> is not vectorized.</p> <p>Parameters:</p> Name Type Description Default <code>cdf</code> <code>_Fn1</code> <p>Vectorized cumulative distribution function (CDF).</p> required <code>r</code> <code>AnyOrder</code> <p>The L-moment order. Must be a non-negative integer.</p> required <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim lengths. Defaults to (0, 0).</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>support</code> <code>_Pair[float] | None</code> <p>The subinterval of the nonzero domain of <code>cdf</code>.</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>l_moment</code> <code>float | float64 | None</code> <p>The relevant L-moment to use. If not provided, it is calculated from the CDF.</p> <code>alpha</code> <code>float</code> <p>Two-sided quantile to split the integral at.</p> <code>tol</code> <code>float</code> <p>Zero-roundoff absolute threshold.</p> <p>Returns:</p> Name Type Description <code>influence_function</code> <code>Callable[[_T_x], _T_x]</code> <p>The influence function, with vectorized signature <code>() -&gt; ()</code>.</p> See Also <ul> <li><code>l_moment_from_cdf</code></li> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"api/low_level/#lmo.theoretical.l_ratio_influence_from_cdf","title":"<code>lmo.theoretical.l_ratio_influence_from_cdf(cdf, r, k=2, /, trim=0, *, support=None, l_moments=None, quad_opts=None, alpha=ALPHA, tol=1e-08)</code>","text":"<p>Construct the influence function of a theoretical L-moment ratio.</p> \\[ \\psi_{\\tau^{(s, t)}_{r,k}|F}(x) = \\frac{     \\psi_{\\lambda^{(s, t)}_r|F}(x)     - \\tau^{(s, t)}_{r,k} \\, \\psi_{\\lambda^{(s, t)}_k|F}(x) }{     \\lambda^{(s,t)}_k } \\;, \\] <p>where the generalized L-moment ratio is defined as</p> \\[ \\tau^{(s, t)}_{r,k} = \\frac{     \\lambda^{(s, t)}_r }{     \\lambda^{(s, t)}_k } \\;. \\] <p>Because IF\u2019s are a special case of the general G\u00e2teuax derivative, the L-ratio IF is derived by applying the chain rule to the L-moment IF.</p> <p>Parameters:</p> Name Type Description Default <code>cdf</code> <code>_Fn1</code> <p>Vectorized cumulative distribution function (CDF).</p> required <code>r</code> <code>AnyOrder</code> <p>L-moment ratio order, i.e. the order of the numerator L-moment.</p> required <code>k</code> <code>AnyOrder</code> <p>Denominator L-moment order, defaults to 2.</p> <code>2</code> <code>trim</code> <code>AnyTrim</code> <p>Left- and right- trim lengths. Defaults to (0, 0).</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>support</code> <code>_Pair[float] | None</code> <p>The subinterval of the nonzero domain of <code>cdf</code>.</p> <code>l_moments</code> <code>_Pair[float] | None</code> <p>The L-moments corresponding to \\(r\\) and \\(k\\). If not provided, they are calculated from the CDF.</p> <code>quad_opts</code> <code>QuadOptions | None</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <code>alpha</code> <code>float</code> <p>Two-sided quantile to split the integral at.</p> <code>tol</code> <code>float</code> <p>Zero-roundoff absolute threshold.</p> <p>Returns:</p> Name Type Description <code>influence_function</code> <code>Callable[[_T_x], _T_x]</code> <p>The influence function, with vectorized signature <code>() -&gt; ()</code>.</p> See Also <ul> <li><code>l_ratio_from_cdf</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/low_level/#lmo.theoretical.ppf_from_l_moments","title":"<code>lmo.theoretical.ppf_from_l_moments(lmbda, /, trim=0, *, support=(-np.inf, np.inf), validate=True, extrapolate=False)</code>","text":"<p>Return a PPF (quantile function, or inverse CDF), with the specified. L-moments \\( \\tlmoment{s, t}{1}, \\tlmoment{s, t}{2}, \\ldots, \\tlmoment{s, t}{R} \\). Other L-moments are considered zero.</p> <p>For \\( R \\) L-moments, this function returns</p> \\[     \\hat{Q}_R(u) = \\sum_{r=1}^{R}         r \\frac{2r + s + t - 1}{r + s + t}         \\tlmoment{s, t}{r}         \\shjacobi{r - 1}{t}{s}{u}, \\] <p>where \\( \\shjacobi{n}{a}{b}{x} \\) is an \\( n \\)-th degree shifted Jacobi polynomial, which is orthogonal for \\( (a, b) \\in (-1, \\infty)^2 \\) on \\( u \\in [0, 1] \\).</p> <p>This nonparametric quantile function estimation method was first described by J.R.M. Hosking in 2007. However, his derivation contains a small, but obvious error, resulting in zero-division for \\( r = 1 \\). So Lmo derived this correct version  himself, by using the fact that L-moments are the disguised coefficients of the PPF\u2019s generalized Fourier-Jacobi series expansion.</p> <p>With Parseval\u2019s theorem it can be shown that, if the probability-weighted moment \\( M_{2,s,t} \\) (which is the variance if \\( s = t = 0 \\)) is finite, then \\( \\hat{Q}_R(u) = Q(u) \\) as \\( R \\to \\infty \\).</p> <p>Parameters:</p> Name Type Description Default <code>lmbda</code> <code>AnyVectorFloat</code> <p>1-d array-like of L-moments \\( \\tlmoment{s,t}{r} \\) for \\( r = 1, 2, \\ldots, R \\). At least 2 L-moments are required. All remaining L-moments with \\( r &gt; R \\) are considered zero.</p> required <code>trim</code> <code>AnyTrim</code> <p>The trim-length(s) of L-moments <code>lmbda</code>.</p> <code>0</code> <code>support</code> <code>_Pair[float]</code> <p>A tuple like <code>(x_min, x_max)</code>. If provided, the PPF results will be clipped to within this interval.</p> <code>(-inf, inf)</code> <code>validate</code> <code>bool</code> <p>If <code>True</code> (default), a <code>ValueError</code> will be raised if the resulting PPF is invalid (non-monotonic), which can be solved by increasing  the <code>trim</code>.</p> <code>True</code> <code>extrapolate</code> <code>bool</code> <p>If set to <code>True</code>, a simple moving average of \\( R \\) and \\( R - 1 \\) will be returned. This generally results in a smoother and more accurate PPF, but its L-moments will not be equal to <code>lmda</code>. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>ppf</code> <code>_Fn1</code> <p>A vectorized PPF (quantile function). Its extra optional keyword argument <code>r_max: int</code> can be used to \u201ccensor\u201d trailing L-moments, i.e. truncating the degree of the polynomial.</p>"},{"location":"api/low_level/#lmo.theoretical.qdf_from_l_moments","title":"<code>lmo.theoretical.qdf_from_l_moments(lmbda, /, trim=0, *, validate=True, extrapolate=False)</code>","text":"<p>Return the QDF (quantile density function, the derivative of the PPF), with the specified L-moments \\( \\tlmoment{s, t}{1}, \\tlmoment{s, t}{2}, \\ldots, \\tlmoment{s, t}{R} \\). Other L-moments are considered zero.</p> <p>This function returns</p> \\[ \\begin{align*}     \\hat{q}_R(u)         &amp;= \\frac{\\dd{\\hat{Q}_R(u)}}{\\dd{u}}  \\\\         &amp;= \\sum_{r=2}^{R}             r (2r + s + t - 1)             \\tlmoment{s, t}{r}             \\shjacobi{r - 2}{t + 1}{s + 1}{u}, \\end{align*} \\] <p>where \\( \\shjacobi{n}{a}{b}{x} \\) is an \\( n \\)-th degree shifted Jacobi polynomial, which is orthogonal for \\( (a, b) \\in (-1, \\infty)^2 \\) on \\( u \\in [0, 1] \\).</p> <p>See <code>ppf_from_l_moments</code> for options.</p>"},{"location":"api/low_level/#lmo.inference","title":"<code>lmo.inference</code>","text":"<p>Statistical inference for parametric probability distributions.</p>"},{"location":"api/low_level/#lmo.inference.fit","title":"<code>lmo.inference.fit(ppf, args0, n_obs, l_moments, r=None, trim=0, *, k=None, k_max=50, l_tol=0.0001, l_moment_fn=None, n_mc_samples=9999, random_state=None, **kwds)</code>","text":"<p>Fit the distribution parameters using the (Generalized) Method of L-Moments (L-(G)MM).</p> <p>The goal is to find the \u201ctrue\u201d parameters \\(\\bm{\\theta^*}\\) of the distribution. In practise, this is done using a reasonably close estimate, \\(\\bm{\\hat\\theta}\\).</p> <p>In the (non-Generalized) Method of L-moments (L-MM), this is done by solving the system of equations \\(\\ell^{(s, t)}_r = \\lambda^{(s, t)}_r\\), for \\(r = 1, \\dots, n\\), with \\(n\\) the number of free parameters. Because the amount of parameters matches the amount of L-moment conditions, the solution is point-defined, and can be found using simple least squares.</p> <p>L-GMM extends L-MM by allowing more L-moment conditions than there are free parameters, \\(m &gt; n\\). This requires solving an over-identified system of \\(m\\) equations:</p> \\[ \\bm{\\hat\\theta} =     \\mathop{\\arg \\min} \\limits_{\\theta \\in \\Theta} \\Bigl\\{         \\left[             \\bm{\\lambda}^{(s, t)}(X_\\theta) - \\bm{\\ell}^{(s, t)}         \\right]^T         W_m         \\left[             \\bm{\\lambda}^{(s, t)}(X_\\theta) - \\bm{\\ell}^{(s, t)}         \\right]     \\Bigr\\}     \\, , \\] <p>where \\(W_m\\) is a \\(m \\times m\\) weight matrix.</p> <p>The weight matrix is initially chosen as the matrix inverse of the non-parametric L-moment covariance matrix, see <code>lmo.l_moment_cov</code>. These weights are then plugged into the the equation above, and fed into <code>scipy.optimize.minimize</code>, to obtain the initial parameter estimates.</p> <p>In the next step(s), Monte-Carlo sampling is used to draw samples from the distribution (using the current parameter estimates), with sample sizes matching that of the data. The L-moments of these samples are consequently used to to calculate the new weight matrix.</p> Todo <ul> <li>Raise on minimization error, warn on failed k-step convergence</li> <li>Optional <code>integrality</code> kwarg with boolean mask for integral params.</li> <li>Implement CUE: Continuously Updating GMM (i.e. implement and     use  <code>_loss_cue()</code>, then run with <code>k=1</code>), see     #299.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>ppf</code> <code>_Fn1</code> <p>The (vectorized) quantile function of the probability distribution, with signature <code>(q: T, *theta: float) -&gt; T</code>.</p> required <code>args0</code> <code>AnyVectorFloat</code> <p>Initial estimate of the distribution\u2019s parameter values.</p> required <code>n_obs</code> <code>int</code> <p>Amount of observations.</p> required <code>l_moments</code> <code>AnyVectorFloat</code> <p>Estimated sample L-moments. Must be a 1-d array-like s.t. <code>len(l_moments) &gt;= len(args0)</code>.</p> required <code>r</code> <code>AnyOrderND | None</code> <p>The orders of <code>l_moments</code>. Defaults to <code>[1, ..., len(l_moments)]</code>.</p> <code>None</code> <code>trim</code> <code>int | tuple[int, int]</code> <p>The L-moment trim-length(s) to use. Currently, only integral trimming is supported.</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>k</code> <code>int | None</code> <p>If set to a positive integer, exactly \\(k\\) steps will be run. Will be ignored if <code>n_extra=0</code>.</p> <code>k_max</code> <code>int</code> <p>Maximum amount of steps to run while not reaching convergence. Will be ignored if \\(k\\) is specified or if <code>n_extra=0</code>.</p> <code>l_tol</code> <code>float</code> <p>Error tolerance in the parametric L-moments (unit-standardized). Will be ignored if \\(k\\) is specified or if <code>n_extra=0</code>.</p> <code>l_moment_fn</code> <code>Callable[..., _ArrF8] | None</code> <p>Function for parametric L-moment calculation, with signature: <code>(r: intp[:], *theta: float, trim: tuple[int, int]) -&gt; float64[:]</code>.</p> <code>n_mc_samples</code> <code>int</code> <p>The number of Monte-Carlo (MC) samples drawn from the distribution to to form the weight matrix in step \\(k &gt; 1\\). Will be ignored if <code>n_extra=0</code>.</p> <code>random_state</code> <code>Seed | None</code> <p>A seed value or <code>numpy.random.Generator</code> instance, used for weight matrix estimation in step \\(k &gt; 1\\). Will be ignored if <code>n_extra=0</code>.</p> <code>**kwds</code> <code>Any</code> <p>Additional keyword arguments to be passed to <code>scipy.optimize.minimize</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Invalid arguments.</p> <p>Returns:</p> Name Type Description <code>result</code> <code>GMMResult</code> <p>An instance of [<code>GMMResult</code>][<code>lmo.inference.GMMResult</code>].</p> References <ul> <li>Alvarez et al. (2023) - Inference in parametric models with many L-moments</li> </ul>"},{"location":"api/low_level/#lmo.inference.GMMResult","title":"<code>lmo.inference.GMMResult</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Represents the Generalized Method of L-Moments (L-GMM) results. See <code>lmo.inference.fit</code> for details.</p>"},{"location":"api/low_level/#lmo.inference.GMMResult.n_arg","title":"<code>n_arg: int</code>  <code>property</code>","text":"<p>The number of model parameters.</p>"},{"location":"api/low_level/#lmo.inference.GMMResult.n_con","title":"<code>n_con: int</code>  <code>property</code>","text":"<p>The amount of L-moment conditions of the model.</p>"},{"location":"api/low_level/#lmo.inference.GMMResult.n_extra","title":"<code>n_extra: int</code>  <code>property</code>","text":"<p>The number of over-identifying L-moment conditions. For L-MM this is zero, otherwise, for L-GMM, it is strictly positive.</p>"},{"location":"api/low_level/#lmo.inference.GMMResult.j_test","title":"<code>j_test: HypothesisTestResult</code>  <code>property</code>","text":"<p>Sargan-Hansen J-test for over-identifying restrictions; a hypothesis test for the invalidity of the model.</p> <p>The test is defined through two hypotheses:</p> <ul> <li>\\(H_0\\): The data satisfies the L-moment conditions, i.e. the model is     \u201cvalid\u201d.</li> <li>\\(H_1\\): The data does not satisfy the L-moment conditions, i.e. the     model is \u201cinvalid\u201d.</li> </ul> References <ul> <li>J. D. Sargan (1958) - The Estimation of Economic Relationships Using Instrumental Variables</li> <li>J. P. Hansen (1982) - Large Sample Properties of Generalized Method of Moments Estimators</li> </ul>"},{"location":"api/low_level/#lmo.inference.GMMResult.AIC","title":"<code>AIC: float</code>  <code>property</code>","text":"<p>Akaike Information Criterion, based on the p-value of the J-test. Requires over-identified L-moment conditions, i.e. <code>n_extra &gt; 0</code>.</p> <p>The AIC is useful for model selection, e.g. for finding the most appropriate probability distribution from the data (smaller is better).</p> References <ul> <li>H. Akaike (1974) - A new look at the statistical model identification</li> </ul>"},{"location":"api/low_level/#lmo.inference.GMMResult.AICc","title":"<code>AICc: float</code>  <code>property</code>","text":"<p>A modification of the AIC that includes a bias-correction small sample sizes.</p> References <ul> <li>N. Sugiura (1978) - Further analysis of the data by Akaike\u2019s information criterion and the finite corrections</li> </ul>"},{"location":"api/pandas/","title":"Optional <code>pandas</code> integration","text":"<p>Extension methods for <code>pandas.Series</code> and <code>pandas.DataFrame</code>.</p> <p>Pandas is an optional dependency, and can be installed using <code>pip install lmo[pandas]</code>.</p> <p>Examples:</p> <p>Univariate summary statistics:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({\"a\": [1, 2, 2, 3, 4], \"b\": [3, 4, 4, 4, 4]})\n&gt;&gt;&gt; df.l_stats()\n          a    b\nr\n1  2.400000  3.8\n2  0.700000  0.2\n3  0.142857 -1.0\n4  0.285714  1.0\n&gt;&gt;&gt; df.aggregate([\"mean\", \"std\", \"skew\", \"kurt\"])\n             a         b\nmean  2.400000  3.800000\nstd   1.140175  0.447214\nskew  0.404796 -2.236068\nkurt -0.177515  5.000000\n</code></pre> <p>Comparison of L-correlation, and Pearson correlation matrices:</p> <pre><code>&gt;&gt;&gt; df = pd.DataFrame({\"dogs\": [0.2, 0.0, 0.5, 0.4], \"cats\": [0.3, 0.2, 0.0, 0.1]})\n&gt;&gt;&gt; df.l_corr()\n      dogs      cats\ndogs   1.0 -0.764706\ncats  -0.8  1.000000\n&gt;&gt;&gt; df.corr()\n          dogs      cats\ndogs  1.000000 -0.756889\ncats -0.756889  1.000000\n</code></pre>"},{"location":"api/pandas/#lmo.contrib.pandas.Series","title":"<code>lmo.contrib.pandas.Series</code>","text":"<p>Extension methods for <code>pandas.Series</code>.</p> <p>This class is not meant to be used directly. These methods are curried and registered as series accessors.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_moment","title":"<code>l_moment(r, /, trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_moment</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float | Series[float]</code> <p>A scalar, or a <code>pd.Series[float]</code>, indexed by <code>r</code>.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_ratio","title":"<code>l_ratio(r, k, /, trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_ratio</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float | Series[float]</code> <p>A scalar, or <code>pd.Series[float]</code>, with a <code>MultiIndex</code> of <code>r</code> and <code>k</code>.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_stats","title":"<code>l_stats(trim=0, num=4, **kwargs)</code>","text":"<p>See <code>lmo.l_stats</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>Series[float]</code> <p>A <code>pd.Series[float]</code> with index <code>r = 1, ..., num</code>.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_loc","title":"<code>l_loc(trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_loc</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>A scalar.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_scale","title":"<code>l_scale(trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_scale</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>A scalar.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_variation","title":"<code>l_variation(trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_variation</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>A scalar.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_skew","title":"<code>l_skew(trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_skew</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>A scalar.</p>"},{"location":"api/pandas/#lmo.contrib.pandas.Series.l_kurtosis","title":"<code>l_kurtosis(trim=0, **kwargs)</code>","text":"<p>See <code>lmo.l_kurtosis</code>.</p> <p>Returns:</p> Name Type Description <code>out</code> <code>float</code> <p>A scalar.</p>"},{"location":"examples/lmm/","title":"Fitting the GEV","text":"In\u00a0[1]: Copied! <pre>import lmo\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import lmo import numpy as np import matplotlib.pyplot as plt <p>Peak streamflow values in $m^3 s^{-1}$</p> In\u00a0[3]: Copied! <pre>data = [\n    123, 2250, 543, 178, 67, 5100, 248, 1500, 342, 329,\n    543, 980, 1020, 4502, 3406, 856, 297,\n]  # fmt: skip\n</pre> data = [     123, 2250, 543, 178, 67, 5100, 248, 1500, 342, 329,     543, 980, 1020, 4502, 3406, 856, 297, ]  # fmt: skip <p>Summarize the probability distribution of the data using L-moments:</p> <ul> <li>L-location $l_1$: the 1st L-moment, equivalent to the mean.</li> <li>L-scale $l_2$: the 2nd L-moment, equivalent to half the gini mean difference.</li> <li>L-skewness coefficient $t_3$: the 3rd L-moment ratio $l_3 / l_2$</li> <li>L-kurtosis coefficient $t_4$: the 4th L-moment ratio $l_4 / l_2$</li> </ul> In\u00a0[4]: Copied! <pre>l_stats_data = lmo.l_stats(data)\nprint(\"L-moment statistics [L-loc, L-scale, L-skew, L-kurt]:\\n\")\nprint(\"Data:\", l_stats_data)\n</pre> l_stats_data = lmo.l_stats(data) print(\"L-moment statistics [L-loc, L-scale, L-skew, L-kurt]:\\n\") print(\"Data:\", l_stats_data) <pre>L-moment statistics [L-loc, L-scale, L-skew, L-kurt]:\n\nData: [1310.82353  799.77206    0.48093    0.19718]\n</pre> <p>For reference, the normal distribution has L-skewness $\\tau_3 = 0$ (unskewed) and L-kurtosis $\\tau_4 \\approx 0.1226$. So this distribution is not normally distributed.</p> <p>This is confirmed by the L-moment-based hypothesis test for non-normality.</p> In\u00a0[5]: Copied! <pre>lmo.diagnostic.normaltest(data).is_significant(0.01)\n</pre> lmo.diagnostic.normaltest(data).is_significant(0.01) Out[5]: <pre>np.True_</pre> <p>Now fit the Generalized Extreme Value (GEV) distribution to the data, using scipy'y default MLE method, and the Method of L-moments (L-MM)</p> In\u00a0[6]: Copied! <pre>from scipy.stats.distributions import genextreme as GEV\n\n# MM (method of moments) fails, as the variance is non-finite\n# params_mm = GEV.fit(data, method='MM')\nparams_mle = GEV.fit(data, method=\"MLE\")\nparams_lmm = GEV.l_fit(data)\n\nprint(\"Fitted GEV parameters [shape (c), loc, scale]:\\n\")\nprint(\"MLE:\", np.round(params_mle, 5))\nprint(\"L-MM:\", np.round(params_lmm, 5))\n</pre> from scipy.stats.distributions import genextreme as GEV  # MM (method of moments) fails, as the variance is non-finite # params_mm = GEV.fit(data, method='MM') params_mle = GEV.fit(data, method=\"MLE\") params_lmm = GEV.l_fit(data)  print(\"Fitted GEV parameters [shape (c), loc, scale]:\\n\") print(\"MLE:\", np.round(params_mle, 5)) print(\"L-MM:\", np.round(params_lmm, 5)) <pre>Fitted GEV parameters [shape (c), loc, scale]:\n\nMLE: [ -0.93795 391.81895 424.55898]\nL-MM: [ -0.43365 481.11193 629.29211]\n</pre> In\u00a0[7]: Copied! <pre>X_mle = GEV(*params_mle)\nX_lmm = GEV(*params_lmm)\n\nprint(\"Fitted GEV L-moment statistics (loc, scale, skew, kurtosis):\\n\")\nprint(\"Data:\", l_stats_data)\nprint(\"MLE: \", X_mle.l_stats())\nprint(\"L-MM:\", X_lmm.l_stats())\n</pre> X_mle = GEV(*params_mle) X_lmm = GEV(*params_lmm)  print(\"Fitted GEV L-moment statistics (loc, scale, skew, kurtosis):\\n\") print(\"Data:\", l_stats_data) print(\"MLE: \", X_mle.l_stats()) print(\"L-MM:\", X_lmm.l_stats()) <pre>Fitted GEV L-moment statistics (loc, scale, skew, kurtosis):\n\nData: [1310.82353  799.77206    0.48093    0.19718]\nMLE:  [6999.41443 6465.82686    0.93602    0.89896]\nL-MM: [1310.82353  799.77207    0.48093    0.34856]\n</pre> <p>Clearly, the MLE is completely wrong, as the mean is almost 5x larger than the sample mean.</p> <p>Let's confirm this visually:</p> In\u00a0[8]: Copied! <pre>from scipy.stats import probplot\n\nfig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 4.5))\nprobplot(data, dist=X_mle, plot=axs[0], rvalue=True)\nprobplot(data, dist=X_lmm, plot=axs[1], rvalue=True)\naxs[0].set_title(\"MLE\")\naxs[1].set_title(\"L-MM\")\nplt.tight_layout()\n</pre> from scipy.stats import probplot  fig, axs = plt.subplots(1, 2, sharey=True, figsize=(10, 4.5)) probplot(data, dist=X_mle, plot=axs[0], rvalue=True) probplot(data, dist=X_lmm, plot=axs[1], rvalue=True) axs[0].set_title(\"MLE\") axs[1].set_title(\"L-MM\") plt.tight_layout()"},{"location":"examples/visual_intro/","title":"L-moments: Explained visually","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n</pre> import matplotlib.pyplot as plt import numpy as np <p>Let's start with some data</p> In\u00a0[3]: Copied! <pre>data = np.array([\n    0.87, 0.87, 1.29, 1.50, 1.70, 0.66, 1.50, 0.5, 1.00, 1.25, 2.30,\n    1.03, 2.85, 0.68, 1.74, 1.94, 0.63, 2.04, 1.2, 0.64, 2.05, 0.97,\n    2.81, 1.02, 2.76, 0.86, 1.36, 1.29, 1.68, 0.72, 1.67, 1.15, 3.26,\n    0.93, 0.83, 0.91, 0.92, 2.32, 1.12, 3.21, 1.23, 1.22, 1.29, 2.08,\n    0.64, 2.83, 2.68, 1.77, 0.69, 1.69, 0.70, 1.83, 2.25, 1.23, 1.17,\n    0.94, 1.22, 0.76, 0.69, 0.48, 1.04, 2.49, 1.38, 1.57, 1.79, 1.59,\n    1.30, 1.54, 1.07, 1.03, 0.76, 2.35, 2.05, 2.02, 2.36, 1.59, 0.97,\n    1.63, 1.66, 0.94, 1.45, 1.26, 1.25, 0.68, 2.96, 0.80, 1.16, 0.82,\n    0.64, 0.87, 1.33, 1.28, 1.26, 1.19, 1.24, 1.12, 1.45, 1.03, 1.37,\n    1.40, 1.35, 1.28, 1.04, 1.31, 0.87, 0.96, 2.55, 1.72, 1.05, 1.15,\n    1.73, 1.03, 1.53, 2.41, 1.36, 2.08, 0.92, 0.73, 1.56, 1.94, 0.78,\n])  # fmt: skip\n</pre> data = np.array([     0.87, 0.87, 1.29, 1.50, 1.70, 0.66, 1.50, 0.5, 1.00, 1.25, 2.30,     1.03, 2.85, 0.68, 1.74, 1.94, 0.63, 2.04, 1.2, 0.64, 2.05, 0.97,     2.81, 1.02, 2.76, 0.86, 1.36, 1.29, 1.68, 0.72, 1.67, 1.15, 3.26,     0.93, 0.83, 0.91, 0.92, 2.32, 1.12, 3.21, 1.23, 1.22, 1.29, 2.08,     0.64, 2.83, 2.68, 1.77, 0.69, 1.69, 0.70, 1.83, 2.25, 1.23, 1.17,     0.94, 1.22, 0.76, 0.69, 0.48, 1.04, 2.49, 1.38, 1.57, 1.79, 1.59,     1.30, 1.54, 1.07, 1.03, 0.76, 2.35, 2.05, 2.02, 2.36, 1.59, 0.97,     1.63, 1.66, 0.94, 1.45, 1.26, 1.25, 0.68, 2.96, 0.80, 1.16, 0.82,     0.64, 0.87, 1.33, 1.28, 1.26, 1.19, 1.24, 1.12, 1.45, 1.03, 1.37,     1.40, 1.35, 1.28, 1.04, 1.31, 0.87, 0.96, 2.55, 1.72, 1.05, 1.15,     1.73, 1.03, 1.53, 2.41, 1.36, 2.08, 0.92, 0.73, 1.56, 1.94, 0.78, ])  # fmt: skip <p>Let's see what the data looks like:</p> In\u00a0[4]: Copied! <pre>n_samp = len(data)\n# instead of at 0th quantile, start at the \"center\" of the first sample\nq0 = 1 / (2 * n_samp)\n# quantiles, a.k.a. \"plotting positions\"\nqs = np.linspace(q0, 1 - q0, len(data))\n# plot the data against the quantiles\n_ = plt.scatter(data, qs, s=16)\n</pre> n_samp = len(data) # instead of at 0th quantile, start at the \"center\" of the first sample q0 = 1 / (2 * n_samp) # quantiles, a.k.a. \"plotting positions\" qs = np.linspace(q0, 1 - q0, len(data)) # plot the data against the quantiles _ = plt.scatter(data, qs, s=16) <p>Oh, That's not very useful \ud83d\ude05</p> <p>Let's do this again, but now we sort the data first:</p> In\u00a0[5]: Copied! <pre>data_sorted = np.sort(data)\nplt.scatter(data_sorted, qs, s=16)\nplt.gca().update({\"xlabel\": r\"$x_{k:n}$\", \"ylabel\": r\"$\\hat{F}(\\cdot)$\"})\n</pre> data_sorted = np.sort(data) plt.scatter(data_sorted, qs, s=16) plt.gca().update({\"xlabel\": r\"$x_{k:n}$\", \"ylabel\": r\"$\\hat{F}(\\cdot)$\"}) Out[5]: <pre>[Text(0.5, 0, '$x_{k:n}$'), Text(0, 0.5, '$\\\\hat{F}(\\\\cdot)$')]</pre> <p>That's a lot better!</p> <p>It's almost as if we're looking at a cumulative distribution function \ud83e\udd14</p> In\u00a0[6]: Copied! <pre>import lmo\n\nprint(lmo.l_loc(data))\nprint(np.mean(data))\n</pre> import lmo  print(lmo.l_loc(data)) print(np.mean(data)) <pre>1.4087603305785124\n1.4087603305785124\n</pre> <p>... no, that's not a coincidence: The L-location is, in fact, equivalent to the mean \ud83e\udd37.</p> <p>However! This is only the case for the first L-moment. And later we'll see that this also isn't the case anymore if we trim it.</p> <p>Anyway, it's time to move on to the cool stuff.</p> In\u00a0[7]: Copied! <pre>print(lmo.l_scale(data))\nprint(np.std(data))\n</pre> print(lmo.l_scale(data)) print(np.std(data)) <pre>0.34159366391184576\n0.6217152629447046\n</pre> <p>Well, they clearly aren't the same thing this time... But it doesn't tell us much, really.</p> <p>And what even is the L-scale, anyway? Ok, I'll try to pain a picture of it:</p> In\u00a0[8]: Copied! <pre>ks = np.arange(n_samp)\nwhat_the_L_is_this = lmo.l_weights(2, n_samp)[-1] * n_samp\n# plt.plot(ks, what_the_L_is_this)\nplt.fill_between(ks, what_the_L_is_this, step=\"mid\")\nplt.gca().update({\"xlabel\": \"$k$\", \"ylabel\": r\"$w_{k:n}$\"})\n</pre> ks = np.arange(n_samp) what_the_L_is_this = lmo.l_weights(2, n_samp)[-1] * n_samp # plt.plot(ks, what_the_L_is_this) plt.fill_between(ks, what_the_L_is_this, step=\"mid\") plt.gca().update({\"xlabel\": \"$k$\", \"ylabel\": r\"$w_{k:n}$\"}) Out[8]: <pre>[Text(0.5, 0, '$k$'), Text(0, 0.5, '$w_{k:n}$')]</pre> <p>Yes, this beautiful painting is, in fact, an area plot of a perfectly straight line.</p> <p>... wait wait, come back! It wasn't a joke! I'm actually going somewhere with this!</p> <p>~ahem~</p> <p>What we're looking at here, are the linear weights (on the y-axis) for each of the ordered samples (the x-axis).</p> <p>If we multiply each of these weights with <code>data_sorted</code>, and then calculate the L-location 1st raw moment mean, we end up with the L-scale!</p> <p>This is what the \"L\" in the L-scale (and L-moment) stands for: Linear.</p> <p>Yes, yes, I hear you, please stop shouting! Of course, sorting isn't a linear operation, I agree with you.. So how about we label it as \"sorta\" linear, and call it a day? ... No wait! put that down! I was only joking! It was just a puu...</p> <p>So... Where was I?</p> <p>Ah yes!! L-scale weights; let's try them out:</p> In\u00a0[9]: Copied! <pre># L-scale for reference\nprint(\"Lmo L-scale:\", lmo.l_scale(data))\n# DIY L-scale; no duct-tape needed!\nprint(\"DIY L-scale:\", np.mean(what_the_L_is_this * data_sorted))\n</pre> # L-scale for reference print(\"Lmo L-scale:\", lmo.l_scale(data)) # DIY L-scale; no duct-tape needed! print(\"DIY L-scale:\", np.mean(what_the_L_is_this * data_sorted)) <pre>Lmo L-scale: 0.34159366391184576\nDIY L-scale: 0.34159366391184576\n</pre> <p>See? I actually was going somewhere!</p> <p>For bonus points, let's add some \"algebra\" to that \"linear\", so that we can calculate both the L-location (yes, still the mean) and the L-scale simultaneously:</p> In\u00a0[10]: Copied! <pre># Lmo (that's right: multi-tasking is no problem for Lmo!):\nprint(\"Lmo:\", lmo.l_moment(data, [1, 2]))\n\n# DIY:\nah_so_these_are_actually_sample_weights = lmo.l_weights(2, n_samp)\ndiy_l_scale = ah_so_these_are_actually_sample_weights @ data_sorted\nprint(\"DIY:\", diy_l_scale)\n</pre> # Lmo (that's right: multi-tasking is no problem for Lmo!): print(\"Lmo:\", lmo.l_moment(data, [1, 2]))  # DIY: ah_so_these_are_actually_sample_weights = lmo.l_weights(2, n_samp) diy_l_scale = ah_so_these_are_actually_sample_weights @ data_sorted print(\"DIY:\", diy_l_scale) <pre>Lmo: [1.40876 0.34159]\nDIY: [1.40876 0.34159]\n</pre> <p>~drops mic~</p> <p> </p> <p><sub>... on toe</sub></p> In\u00a0[11]: Copied! <pre>def plot_l_weights(rth: int, size: int, *, ax=plt):\n    assert rth &gt; 0\n    w_r_k = lmo.l_weights(rth, size)\n    ax.fill_between(np.arange(size), w_r_k[-1] * size, step=\"mid\")\n    try:\n        ax.xlabel(\"$k$\")\n        ax.ylabel(f\"$w_{rth}[k:n]$\")\n    except AttributeError:\n        ax.set_xlabel(\"$k$\")\n        ax.set_ylabel(f\"$w_{rth}[k:n]$\")\n    return w_r_k\n\n\nl_weights_3 = plot_l_weights(3, n_samp)\n</pre> def plot_l_weights(rth: int, size: int, *, ax=plt):     assert rth &gt; 0     w_r_k = lmo.l_weights(rth, size)     ax.fill_between(np.arange(size), w_r_k[-1] * size, step=\"mid\")     try:         ax.xlabel(\"$k$\")         ax.ylabel(f\"$w_{rth}[k:n]$\")     except AttributeError:         ax.set_xlabel(\"$k$\")         ax.set_ylabel(f\"$w_{rth}[k:n]$\")     return w_r_k   l_weights_3 = plot_l_weights(3, n_samp) <p>Now that's more like it!</p> <p>And now for let's actually calculate the L-skewness:</p> In\u00a0[12]: Copied! <pre>print(\"Lmo:\", lmo.l_skew(data))\n# the `l_weights` index is 1-based, so -1 is first applied here\nprint(\"DIY:\", (l_weights_3[2] @ data_sorted) / (l_weights_3[1] @ data_sorted))\n</pre> print(\"Lmo:\", lmo.l_skew(data)) # the `l_weights` index is 1-based, so -1 is first applied here print(\"DIY:\", (l_weights_3[2] @ data_sorted) / (l_weights_3[1] @ data_sorted)) <pre>Lmo: 0.2189964482831403\nDIY: 0.2189964482831402\n</pre> <p>Apart from the tiny (safe-to-ignore) numerical error, it's a match \ud83c\udf89!</p> In\u00a0[13]: Copied! <pre>l_weights_4 = plot_l_weights(4, n_samp)\n</pre> l_weights_4 = plot_l_weights(4, n_samp) In\u00a0[14]: Copied! <pre># c'est \u00e7a\nprint(\"Lmo:\", lmo.l_stats(data))\n\ndiy_lmo_all4 = l_weights_4 @ data_sorted\ndiy_lmo_all4[2:] /= diy_lmo_all4[1]  # L-moment's =&gt; L-ratio's for r &gt; 2\nprint(\"DIY:\", diy_lmo_all4)\n</pre> # c'est \u00e7a print(\"Lmo:\", lmo.l_stats(data))  diy_lmo_all4 = l_weights_4 @ data_sorted diy_lmo_all4[2:] /= diy_lmo_all4[1]  # L-moment's =&gt; L-ratio's for r &gt; 2 print(\"DIY:\", diy_lmo_all4) <pre>Lmo: [1.40876 0.34159 0.219   0.13282]\nDIY: [1.40876 0.34159 0.219   0.13282]\n</pre> <p>While we're at it, let's also make an L-collage \ud83c\udf7e.</p> <p>But this time, let's go for that full 16-bit experience \ud83d\udd79</p> In\u00a0[15]: Copied! <pre>fig, axs = plt.subplots(2, 2, figsize=(10, 8), sharey=True, sharex=True)\n\nn_hindsight = 16\n\nplot_l_weights(1, n_hindsight, ax=axs[0, 0])\naxs[0, 0].set_title(\"L-location\")\naxs[0, 0].set_xlabel(None)\n\nplot_l_weights(2, n_hindsight, ax=axs[0, 1])\naxs[0, 1].set_title(\"L-scale\")\naxs[0, 1].set_xlabel(None)\naxs[0, 1].set_ylabel(None)\n\nplot_l_weights(3, n_hindsight, ax=axs[1, 0])\naxs[1, 0].set_title(\"L-skewness\")\n\nplot_l_weights(4, n_hindsight, ax=axs[1, 1])\naxs[1, 1].set_title(\"L-kurtosis\")\naxs[1, 1].set_ylabel(None)\n\naxs[0, 0].set_xlim(-0.5, n_hindsight - 1)\naxs[0, 1].set_xlim(-0.5, n_hindsight - 1)\naxs[1, 0].set_xlim(-0.5, n_hindsight - 1)\naxs[1, 1].set_xlim(-0.5, n_hindsight - 1)\n\nplt.tight_layout()\n</pre> fig, axs = plt.subplots(2, 2, figsize=(10, 8), sharey=True, sharex=True)  n_hindsight = 16  plot_l_weights(1, n_hindsight, ax=axs[0, 0]) axs[0, 0].set_title(\"L-location\") axs[0, 0].set_xlabel(None)  plot_l_weights(2, n_hindsight, ax=axs[0, 1]) axs[0, 1].set_title(\"L-scale\") axs[0, 1].set_xlabel(None) axs[0, 1].set_ylabel(None)  plot_l_weights(3, n_hindsight, ax=axs[1, 0]) axs[1, 0].set_title(\"L-skewness\")  plot_l_weights(4, n_hindsight, ax=axs[1, 1]) axs[1, 1].set_title(\"L-kurtosis\") axs[1, 1].set_ylabel(None)  axs[0, 0].set_xlim(-0.5, n_hindsight - 1) axs[0, 1].set_xlim(-0.5, n_hindsight - 1) axs[1, 0].set_xlim(-0.5, n_hindsight - 1) axs[1, 1].set_xlim(-0.5, n_hindsight - 1)  plt.tight_layout()"},{"location":"examples/visual_intro/#required-dependencies","title":"Required dependencies\u00b6","text":"<p>This notebook requires that you have <code>matplotlib</code> installed, and, of course, Lmo (preferrably the latest stable release).</p>"},{"location":"examples/visual_intro/#dealing-with-data","title":"Dealing with data\u00b6","text":""},{"location":"examples/visual_intro/#l-moments-from-scratch","title":"L-moments from scratch\u00b6","text":"<p>Now it's (finally) time to look at some L-moments.</p>"},{"location":"examples/visual_intro/#the-l-location-lambda_1","title":"The L-location $\\lambda_1$\u00b6","text":"<p>This is the first L-moment. As the name suggests, it describes the location of a distribution.</p> <p>The analogue with product-moments is the first raw moment, although it usually is called \"the mean\".</p> <p>Let's compare the two:</p>"},{"location":"examples/visual_intro/#the-l-scale-lambda_2","title":"The L-scale $\\lambda_2$\u00b6","text":"<p>The L-scale is a measure of dispersion, just like the standard deviation. It's simply the 2nd L-moment, so there's no need to worry about square roots.</p> <p>There's also no need to worry about that $ / (n - 1)$ stuff (Bessel's correction) that you need to get an unbiased a less biased estimate of the standard deviation...</p> <p>... and that's because, yes you guessed right, the L-scale is always unbiased!</p> <p>Ok, now let's take a look at the L-scale and the standard deviation, so we can see which one is better:</p>"},{"location":"examples/visual_intro/#the-l-skewness-tau_3","title":"The L-skewness $\\tau_3$\u00b6","text":"<p>Now this one is a bit of a twist:</p> <p>It's not an L-moment!</p> <p>...</p> <p>...</p> <p>~ now it's your yurn to ask \"... but what is it then???\" ... ~</p> <p>...</p> <p>...</p> <p>c'mon, I practiced all night for this, please play along...</p> <p>...</p> <p>...</p> <p>~sigh~</p> <p>...</p> <p>...</p> <p>ehrm, I'm glad you asked! It's an L-moment ratio!</p> <p>...</p> <p>~ silence ~</p> <p>...</p> <p>~ why am I doing this again? ~</p> <p>...</p> <p>Ok let's just finish this; It's an L-moment that's divided by the L-scale. So these L-moment ratio's (or L-ratio's for short) are the analogue of *standardized moments.</p> <p>Without going into detail, just quickly glance over these following equations, for the two, and see which one you like better:</p> Fisher Skewness (from raw moments) L-Skewness (from L-moments) $ \\displaystyle \\tilde{\\mu}_3 = \\frac{\\mu_3 - 3\\mu_1 \\mu_2 + 2\\mu_1^3}{(\\mu_2 - \\mu_1^2)^{3/2}}$ $\\displaystyle \\tau_3 = \\frac{\\lambda_3}{\\lambda_2}$ <p>So apart from complexity, the L-skewness is still linear, whereas the Fisher Skewness requires a 3rd power. In case your data contains some outliers, or its distribution is heavy-tailed, then the Fisher skewness will quickly break down. But the L-skewness is just as robust as the mean is, and will treat outliers just like any other sample.</p> <p>Anyway, enough talk, let's visualize it (i.e. its sample weights):</p>"},{"location":"examples/visual_intro/#the-l-kurtosis-tau_4","title":"The L-kurtosis $\\tau_4$\u00b6","text":"<p>Well, I'm sure you know the drill by know. So here's the short version</p> <ul> <li>L-moments: good</li> <li>Product moments: bad</li> <li>Now, pics please!</li> </ul>"},{"location":"examples/visual_intro/#l-all-of-the-above-aka-the-l-stats","title":"L-\"all of the above\", a.k.a. the L-stats\u00b6","text":"<p>Now for our final trick; let's calculate everything at once!</p>"}]}