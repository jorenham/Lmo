{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#lmo-trimmed-l-moments-and-l-comoments","title":"Lmo - Trimmed L-moments and L-comoments","text":"<pre><code>Is your tail too heavy? \nCan't find a moment? \nAre the swans black? \nThe distribution pathological?\n\n... then look no further: Lmo's got you covered!\n\nUniform or multi-dimensional, Lmo can summarize it all with one quick glance!\n</code></pre> <p>Unlike the legacy moments, L-moments uniquely describe a  probability distribution, and are more robust and efficient. The \"L\" stands for Linear; it is a linear combination of order statistics. So Lmo is as fast as sorting your samples (in terms of time-complexity).</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Calculates trimmed L-moments and L-comoments, from samples or any   <code>scipy.stats</code> distribution.</li> <li>Full support for trimmed L-moment (TL-moments), e.g.   <code>lmo.l_moment(..., trim=(1/137, 3.1416))</code>.</li> <li>Method of L-moments for robust distribution fitting.</li> <li>Fast estimation of L-comoment matrices from your multidimensional data   or multivariate distribution.</li> <li>Goodness-of-fit test, using L-moment or L-moment ratio's.</li> <li>Non-parametric estimation of continuous distributions    with <code>lmo.l_rv_nonparametric</code></li> <li>Exact (co)variance structure of the sample- and population L-moments.</li> <li>Theoretical &amp; empirical influence functions of L-moments &amp; L-ratio's.</li> <li>Complete docs, including detailed API  reference with usage examples and with mathematical \\(\\TeX\\) definitions.</li> <li>Clean Pythonic syntax for ease of use.</li> <li>Vectorized functions for very fast fitting.</li> <li>Fully typed, tested, and tickled.</li> </ul>"},{"location":"#quick-example","title":"Quick example","text":"<p>Even if your data is pathological like  Cauchy, and the L-moments  are not defined, the trimmed L-moments (TL-moments) can be used instead. Let's calculate the TL-location and TL-scale of a small amount of samples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; rng = np.random.default_rng(1980)\n&gt;&gt;&gt; x = rng.standard_cauchy(96)  # pickle me, Lmo\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1, 1)).\narray([-0.17937038,  0.68287665])\n</code></pre> <p>Now compare with the theoretical standard Cauchy TL-moments:</p> <pre><code>&gt;&gt;&gt; from scipy.stats import cauchy\n&gt;&gt;&gt; cauchy.l_moment([1, 2], trim=(1, 1))\narray([0.        , 0.69782723])\n</code></pre> <p>See the documentation for more examples and the API reference.</p>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>Automatic trim-length selection.</li> <li>Plotting utilities (deps optional), e.g. for L-moment ratio diagrams.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Lmo is on PyPI, so you can do something like:</p> <pre><code>pip install lmo\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<ul> <li><code>python &gt;= 3.10</code></li> <li><code>numpy &gt;= 1.22</code></li> <li><code>scipy &gt;= 1.9</code></li> </ul>"},{"location":"#foundational-literature","title":"Foundational Literature","text":"<ul> <li>J.R.M. Hosking (1990) \u2013 L-moments: Analysis and Estimation of    Distributions using Linear Combinations of Order Statistics   </li> <li>E.A.H. Elamir &amp; A.H. Seheult (2003) \u2013 Trimmed L-moments   </li> <li>E.A.H. Elamir &amp; A.H. Seheult (2004) \u2013 Exact variance structure of    sample L-moments</li> <li>J.R.M. Hosking (2007) \u2013 Some theory and practical uses of trimmed    L-moments</li> <li>R. Ser\ufb02ing &amp; P. Xiao (2007) \u2013 A contribution to multivariate    L-moments: L-comoment matrices</li> <li>W.H. Asquith (2011) \u2013 Univariate Distributional Analysis with    L-moment Statistics</li> </ul>"},{"location":"api/","title":"Lmo reference","text":""},{"location":"api/#high-level-api","title":"High-level API","text":""},{"location":"api/#sample-l-moments","title":"Sample L-moments","text":""},{"location":"api/#lmo.l_moment","title":"<code>lmo.l_moment(a, r, /, trim=(0, 0), *, axis=None, dtype=np.float_, fweights=None, aweights=None, sort='stable', cache=False)</code>","text":"<p>Estimates the generalized trimmed L-moment \\(\\lambda^{(s, t)}_r\\) from the samples along the specified axis. By default, this will be the regular L-moment, \\(\\lambda_r = \\lambda^{(0, 0)}_r\\).</p> PARAMETER  DESCRIPTION <code>a</code> <p>Array containing numbers whose L-moments is desired. If <code>a</code> is not an array, a conversion is attempted.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>The L-moment order(s), non-negative integer or array.</p> <p> TYPE: <code>IntVector | AnyInt</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((s, t)\\), non-negative ints or floats that are bound by \\(s + t &lt; n - r\\). A single scalar \\(t\\) can be proivided as well, as alias for \\((t, t)\\).</p> <p>Some special cases include:</p> <ul> <li>\\((0, 0)\\): The original L-moment, introduced by Hosking     in 1990.</li> <li>\\((0, t)\\): LL-moment (Linear combination of Lowest     order statistics), introduced by Bayazit &amp; Onoz in 2002.     Assigns more weight to smaller observations.</li> <li>\\((s, 0)\\): LH-moment (Linear combination of Higher     order statistics), as described by Wang in 1997.     Assigns more weight to larger observations.</li> <li>\\((t, t)\\): TL-moment (Trimmed L-moment) \\(\\\\lambda_r^t\\),     with symmetric trimming. First introduced by Elamir &amp; Seheult     in 2003, and refined by Hosking in 2007. Generally more robust     than L-moments. Useful for fitting pathological distributions,     such as the Cauchy distribution.</li> </ul> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>axis</code> <p>Axis along which to calculate the moments. If <code>None</code> (default), all samples in the array will be used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Floating type to use in computing the L-moments. Default is <code>numpy.float64</code>.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>fweights</code> <p>1-D array of integer frequency weights; the number of times each observation vector should be repeated.</p> <p> TYPE: <code>IntVector | None</code> DEFAULT: <code>None</code> </p> <code>aweights</code> <p>An array of weights associated with the values in <code>a</code>. Each value in <code>a</code> contributes to the average according to its associated weight. The weights array can either be 1-D (in which case its length must be the size of a along the given axis) or of the same shape as <code>a</code>. If <code>aweights=None</code> (default), then all data in <code>a</code> are assumed to have a weight equal to one.</p> <p>All <code>aweights</code> must be <code>&gt;=0</code>, and the sum must be nonzero.</p> <p>The algorithm is similar to that for weighted quantiles.</p> <p> TYPE: <code>npt.ArrayLike | None</code> DEFAULT: <code>None</code> </p> <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | stable | heap</code> DEFAULT: <code>'stable'</code> </p> <code>cache</code> <p>Set to <code>True</code> to speed up future L-moment calculations that have the same number of observations in <code>a</code>, equal <code>trim</code>, and equal or smaller <code>r</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>l</code> <p>The L-moment(s) of the input This is a scalar iff a is 1-d and r is a scalar. Otherwise, this is an array with <code>np.ndim(r) + np.ndim(a) - 1</code> dimensions and shape like <code>(*np.shape(r), *(d for d in np.shape(a) if d != axis))</code>.</p> <p> TYPE: <code>npt.NDArray[T] | T</code> </p> <p>Examples:</p> <p>Calculate the L-location and L-scale from student-T(2) samples, for different (symmetric) trim-lengths.</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_t(2, 99)\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(0, 0))\narray([-0.01412282,  0.94063132])\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1/2, 1/2))\narray([-0.02158858,  0.5796519 ])\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1, 1))\narray([-0.0124483 ,  0.40120115])\n</code></pre> <p>The theoretical L-locations are all 0, and the the L-scale are <code>1.1107</code>, <code>0.6002</code> and <code>0.4165</code>, respectively.</p> See Also <ul> <li>L-moment - Wikipedia</li> <li><code>scipy.stats.moment</code></li> </ul> References <ul> <li>J.R.M. Hosking (1990)</li> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/#lmo.l_ratio","title":"<code>lmo.l_ratio(a, r, s, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Estimates the generalized L-moment ratio:</p> \\[ \\tau^{(s, t)}_{rs} = \\frac{     \\lambda^{(s, t)}_r }{     \\lambda^{(s, t)}_s } \\] <p>Equivalent to <code>lmo.l_moment(a, r, *, **) / lmo.l_moment(a, s, *, **)</code>.</p> <p>The L-moment with <code>r=0</code> is <code>1</code>, so the <code>l_ratio(a, r, 0, *, **)</code> is equivalent to <code>l_moment(a, r, *, **)</code>.</p> Notes <p>Often, when referring to the \\(r\\)th L-ratio, the L-moment ratio with \\(k=2\\) is implied, i.e. \\(\\tau^{(s, t)}_r\\) is short-hand notation for \\(\\tau^{(s, t)}_{r,2}\\).</p> <p>The L-variation (L-moment Coefficient of Variation, or L-CB) is another special case of the L-moment ratio, \\(\\tau^{(s, t)}_{2,1}\\). It is sometimes denoted in the literature by dropping the subscript indices: \\(\\tau^{(s, t)}\\). Note that this should only be used with strictly positive distributions.</p> <p>Examples:</p> <p>Estimate the L-location, L-scale, L-skewness and L-kurtosis simultaneously:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).lognormal(size=99)\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2])\narray([1.53196368, 0.77549561, 0.4463163 , 0.29752178])\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(0, 1))\narray([0.75646807, 0.32203446, 0.23887609, 0.07917904])\n</code></pre> See Also <ul> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"api/#lmo.l_stats","title":"<code>lmo.l_stats(a, /, trim=(0, 0), num=4, *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Calculates the L-loc(ation), L-scale, L-skew(ness) and L-kurtosis.</p> <p>Equivalent to <code>lmo.l_ratio(a, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code> by default.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, scipy.stats\n&gt;&gt;&gt; x = scipy.stats.gumbel_r.rvs(size=99, random_state=12345)\n&gt;&gt;&gt; lmo.l_stats(x)\narray([0.79014773, 0.68346357, 0.12207413, 0.12829047])\n</code></pre> <p>The theoretical L-stats of the standard Gumbel distribution are <code>[0.577, 0.693, 0.170, 0.150]</code>.</p> See Also <ul> <li><code>lmo.l_stats_se</code></li> <li><code>lmo.l_ratio</code></li> <li><code>lmo.l_costats</code></li> </ul>"},{"location":"api/#lmo.l_loc","title":"<code>lmo.l_loc(a, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>L-location (or L-loc): unbiased estimator of the first L-moment, \\(\\lambda^{(s, t)}_1\\).</p> <p>Alias for <code>lmo.l_moment(a, 1, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_cauchy(99)\n&gt;&gt;&gt; x.mean()\n-7.5648...\n&gt;&gt;&gt; lmo.l_loc(x)  # no trim; equivalent to the (arithmetic) mean\n-7.5648...\n&gt;&gt;&gt; lmo.l_loc(x, trim=(1, 1))  # TL-location\n-0.15924...\n&gt;&gt;&gt; lmo.l_loc(x, trim=(3/2, 3/2))  # Fractional trimming (only in Lmo)\n-0.085845...\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), the L-location is equivalent to the arithmetic mean.</p> See Also <ul> <li><code>lmo.l_moment</code></li> <li><code>numpy.average</code></li> </ul>"},{"location":"api/#lmo.l_scale","title":"<code>lmo.l_scale(a, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>L-scale: unbiased estimator of the second L-moment, \\(\\lambda^{(s, t)}_2\\).</p> <p>Alias for <code>lmo.l_moment(a, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_cauchy(99)\n&gt;&gt;&gt; x.std()\n72.87715244...\n&gt;&gt;&gt; lmo.l_scale(x)\n9.501123995...\n&gt;&gt;&gt; lmo.l_scale(x, trim=(1, 1))\n0.658993279...\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), the L-scale is equivalent to half the Gini mean difference (GMD).</p> See Also <ul> <li><code>lmo.l_moment</code></li> <li><code>numpy.std</code></li> </ul>"},{"location":"api/#lmo.l_variation","title":"<code>lmo.l_variation(a, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>The coefficient of L-variation (or L-CV) unbiased sample estimator:</p> \\[ \\tau^{(s, t)} = \\frac{     \\lambda^{(s, t)}_2 }{     \\lambda^{(s, t)}_1 } \\] <p>Alias for <code>lmo.l_ratio(a, 2, 1, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).pareto(4.2, 99)\n&gt;&gt;&gt; x.std() / x.mean()\n1.32161112...\n&gt;&gt;&gt; lmo.l_variation(x)\n0.59073639...\n&gt;&gt;&gt; lmo.l_variation(x, trim=(0, 1))\n0.55395044...\n</code></pre> Notes <p>If <code>trim = (0, 0)</code> (default), this is equivalent to the Gini coefficient, and lies within the interval \\((0, 1)\\).</p> See Also <ul> <li>Gini coefficient - Wikipedia</li> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.variation.l_ratio</code></li> </ul>"},{"location":"api/#lmo.l_skew","title":"<code>lmo.l_skew(a, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Unbiased sample estimator of the coefficient of L-skewness, or L-skew for short:</p> \\[ \\tau^{(s, t)}_3     = \\frac{         \\lambda^{(s, t)}_3     }{         \\lambda^{(s, t)}_2     } \\] <p>Alias for <code>lmo.l_ratio(a, 3, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_exponential(99)\n&gt;&gt;&gt; lmo.l_skew(x)\n0.38524343...\n&gt;&gt;&gt; lmo.l_skew(x, trim=(0, 1))\n0.27116139...\n</code></pre> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.skew</code></li> </ul>"},{"location":"api/#lmo.l_kurtosis","title":"<code>lmo.l_kurtosis(a, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>L-kurtosis coefficient; the 4th sample L-moment ratio.</p> \\[ \\tau^{(s, t)}_4     = \\frac{         \\lambda^{(s, t)}_4     }{         \\lambda^{(s, t)}_2     } \\] <p>Alias for <code>lmo.l_ratio(a, 4, 2, *, **)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; x = np.random.default_rng(12345).standard_t(2, 99)\n&gt;&gt;&gt; lmo.l_kurtosis(x)\n0.28912787...\n&gt;&gt;&gt; lmo.l_kurtosis(x, trim=(1, 1))\n0.19928182...\n</code></pre> Notes <p>The L-kurtosis \\(\\tau_4\\) lies within the interval \\([-\\frac{1}{4}, 1)\\), and by the L-skewness \\(\\\\tau_3\\) as \\(5 \\tau_3^2 - 1 \\le 4 \\tau_4\\).</p> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>scipy.stats.kurtosis</code></li> </ul>"},{"location":"api/#lmo.l_moment_cov","title":"<code>lmo.l_moment_cov(a, r_max, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Non-parmateric auto-covariance matrix of the generalized trimmed L-moment point estimates with orders <code>r = 1, ..., r_max</code>.</p> RETURNS DESCRIPTION <code>S_l</code> <p>Variance-covariance matrix/tensor of shape <code>(r_max, r_max, ...)</code></p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <p>Fitting of the cauchy distribution with TL-moments. The location is equal to the TL-location, and scale should be \\(0.698\\) times the TL(1)-scale, see Elamir &amp; Seheult (2003).</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(1337)\n&gt;&gt;&gt; lmo.l_moment(x, [1, 2], trim=(1, 1))\narray([0.08142405, 0.68884917])\n</code></pre> <p>The L-moment estimates seem to make sense. Let's check their standard errors, by taking the square root of the variances (the diagonal of the covariance matrix):</p> <pre><code>&gt;&gt;&gt; lmo.l_moment_cov(x, 2, trim=(1, 1))\narray([[ 4.89407076e-03, -4.26419310e-05],\n       [-4.26419310e-05,  1.30898414e-03]])\n&gt;&gt;&gt; np.sqrt(_.diagonal())\narray([0.06995764, 0.03617989])\n</code></pre> See Also <ul> <li><code>lmo.l_moment</code></li> <li>Covariance matrix - Wikipedia</li> </ul> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>E. Elamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul> Todo <ul> <li>Use the direct (Jacobi) method from Hosking (2015).</li> </ul>"},{"location":"api/#lmo.l_ratio_se","title":"<code>lmo.l_ratio_se(a, r, s, /, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Non-parametric estimates of the Standard Error (SE) in the L-ratio estimates from <code>lmo.l_ratio</code>.</p> <p>Examples:</p> <p>Estimate the values and errors of the TL-loc, scale, skew and kurtosis for Cauchy-distributed samples. The theoretical values are <code>[0.0, 0.698, 0.0, 0.343]</code> (Elamir &amp; Seheult, 2003), respectively.</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.standard_cauchy(42)\n&gt;&gt;&gt; lmo.l_ratio(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(1, 1))\narray([-0.25830513,  0.61738638, -0.03069701,  0.25550176])\n&gt;&gt;&gt; lmo.l_ratio_se(x, [1, 2, 3, 4], [0, 0, 2, 2], trim=(1, 1))\narray([0.32857302, 0.12896501, 0.13835403, 0.07188138])\n</code></pre> See Also <ul> <li><code>lmo.l_ratio</code></li> <li><code>lmo.l_moment_cov</code></li> <li>Propagation of uncertainty</li> </ul> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>E. Elamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul>"},{"location":"api/#lmo.l_stats_se","title":"<code>lmo.l_stats_se(a, /, num=4, trim=(0, 0), *, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Calculates the standard errors (SE's) of the <code>L-stats</code>.</p> <p>Equivalent to <code>lmo.l_ratio_se(a, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code> by default.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, scipy.stats\n&gt;&gt;&gt; x = scipy.stats.gumbel_r.rvs(size=99, random_state=12345)\n&gt;&gt;&gt; lmo.l_stats(x)\narray([0.79014773, 0.68346357, 0.12207413, 0.12829047])\n&gt;&gt;&gt; lmo.l_stats_se(x)\narray([0.12305147, 0.05348839, 0.04472984, 0.03408495])\n</code></pre> <p>The theoretical L-stats of the standard Gumbel distribution are <code>[0.577, 0.693, 0.170, 0.150]</code>. The corresponding relative z-scores are <code>[-1.730, 0.181, 1.070, 0.648]</code>.</p> See Also <ul> <li><code>lmo.l_stats</code></li> <li><code>lmo.l_ratio_se</code></li> </ul>"},{"location":"api/#lmo.l_moment_influence","title":"<code>lmo.l_moment_influence(a, r, /, trim=(0, 0), *, sort='stable', tol=1e-08)</code>","text":"<p>Empirical Influence Function (EIF) of a sample L-moment.</p> Notes <p>This function is not vectorized.</p> PARAMETER  DESCRIPTION <code>a</code> <p>1-D array-like containing observed samples.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>L-moment order. Must be a non-negative integer.</p> <p> TYPE: <code>SupportsIndex</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | stable | heap</code> </p> <code>tol</code> <p>Zero-roundoff absolute threshold.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>influence_function</code> <p>The (vectorized) empirical influence function.</p> <p> TYPE: <code>Callable[[V], V]</code> </p>"},{"location":"api/#lmo.l_ratio_influence","title":"<code>lmo.l_ratio_influence(a, r, k=2, /, trim=(0, 0), *, sort='stable', tol=1e-08)</code>","text":"<p>Empirical Influence Function (EIF) of a sample L-moment ratio.</p> Notes <p>This function is not vectorized.</p> PARAMETER  DESCRIPTION <code>a</code> <p>1-D array-like containing observed samples.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>L-moment ratio order. Must be a non-negative integer.</p> <p> TYPE: <code>SupportsIndex</code> </p> <code>k</code> <p>Denominator L-moment order, defaults to 2.</p> <p> TYPE: <code>SupportsIndex</code> DEFAULT: <code>2</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | stable | heap</code> </p> <code>tol</code> <p>Zero-roundoff absolute threshold.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>influence_function</code> <p>The (vectorized) empirical influence function.</p> <p> TYPE: <code>Callable[[V], V]</code> </p>"},{"location":"api/#sample-l-comoments","title":"Sample L-comoments","text":""},{"location":"api/#lmo.l_comoment","title":"<code>lmo.l_comoment(a, r, /, trim=(0, 0), *, dtype=np.float_, rowvar=True, sort='stable', cache=False)</code>","text":"<p>Multivariate extension of <code>lmo.l_moment</code>.</p> <p>Estimates the L-comoment matrix:</p> \\[ \\Lambda_{r}^{(t_1, t_2)} =     \\left[         \\lambda_{r [ij]}^{(t_1, t_2)}     \\right]_{m \\times m} \\] <p>Whereas the L-moments are calculated using the order statistics of the observations, i.e. by sorting, the L-comoment sorts \\(x_i\\) using the order of \\(x_j\\). This means that in general, \\(\\lambda_{r [ij]}^{(t_1, t_2)} \\neq \\lambda_{r [ji]}^{(t_1, t_2)}\\), i.e. \\(\\Lambda_{r}^{(t_1, t_2)}\\) is not symmetric.</p> <p>The \\(r\\)-th L-comoment \\(\\lambda_{r [ij]}^{(t_1, t_2)}\\) reduces to the L-moment if \\(i=j\\), and can therefore be seen as a generalization of the (univariate) L-moments. Similar to how the diagonal of a covariance matrix contains the variances, the diagonal of the L-comoment matrix contains the L-moments.</p> <p>Based on the proposed definition by Serfling &amp; Xiao (2007) for L-comoments. Extended to allow for generalized trimming.</p> PARAMETER  DESCRIPTION <code>a</code> <p>1-D or 2-D array-like containing <code>m</code> variables and <code>n</code> observations.  Each row of <code>a</code> represents a variable, and each column a single observation of all those variables. Also see <code>rowvar</code> below.  If <code>a</code> is not an array, a conversion is attempted.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>The L-moment order(s), non-negative integer or array.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((t_1, t_2)\\), non-negative ints or floats that are bound by \\(t_1 + t_2 &lt; n - r\\).</p> <p>Some special cases include:</p> <ul> <li>\\((0, 0)\\): The original L-moment, introduced by Hosking     (1990).  Useful for fitting the e.g. log-normal and generalized     extreme value (GEV) distributions.</li> <li>\\((0, m)\\): LL-moment (Linear combination of Lowest     order statistics), introduced by Bayazit &amp; Onoz (2002).     Assigns more weight to smaller observations.</li> <li>\\((s, 0)\\): LH-moment (Linear combination of Higher     order statistics), by Wang (1997).     Assigns more weight to larger observations.</li> <li>\\((t, t)\\): TL-moment (Trimmed L-moment) \\(\\\\lambda_r^t\\),     with symmetric trimming. First introduced by     Elamir &amp; Seheult (2003).     Generally more robust than L-moments.     Useful for fitting heavy-tailed distributions, such as the     Cauchy distribution.</li> </ul> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>rowvar</code> <p>If <code>rowvar</code> is True (default), then each row (axis 0) represents a variable, with observations in the columns (axis 1). Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>dtype</code> <p>Floating type to use in computing the L-moments. Default is <code>numpy.float64</code>.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | stable | heap</code> DEFAULT: <code>'stable'</code> </p> <code>cache</code> <p>Set to <code>True</code> to speed up future L-moment calculations that have the same number of observations in <code>a</code>, equal <code>trim</code>, and equal or smaller <code>r</code>.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>L</code> <p>Array of shape <code>(*r.shape, m, m)</code> with r-th L-comoments.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <p>Estimation of the second L-comoment (the L-coscale) from biviariate normal samples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_comoment(x, 2)\narray([[ 1.2766793 , -0.83299947],\n       [-0.71547941,  1.05990727]])\n</code></pre> <p>The diagonal contains the univariate L-moments:</p> <pre><code>&gt;&gt;&gt; lmo.l_moment(x, 2, axis=-1)\narray([1.2766793 , 1.05990727])\n</code></pre> References <ul> <li>R. Serfling &amp; P. Xiao (2007) - A Contribution to Multivariate   L-Moments: L-Comoment Matrices</li> </ul>"},{"location":"api/#lmo.l_coratio","title":"<code>lmo.l_coratio(a, r, s, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>Estimate the generalized matrix of L-comoment ratio's.</p> \\[ \\tilde \\Lambda_{rs}^{(t_1, t_2)} =     \\left[         \\left. \\lambda_{r [ij]}^{(t_1, t_2)} \\right/         \\lambda_{s [ii]}^{(t_1, t_2)}     \\right]_{m \\times m} \\] See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/#lmo.l_costats","title":"<code>lmo.l_costats(a, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>Calculates the L-coscale, L-corr(elation), L-coskew(ness) and L-cokurtosis.</p> <p>Equivalent to <code>lmo.l_coratio(a, [2, 2, 3, 4], [0, 2, 2, 2], *, **)</code>.</p> See Also <ul> <li><code>lmo.l_stats</code></li> <li><code>lmo.l_coratio</code></li> </ul>"},{"location":"api/#lmo.l_coloc","title":"<code>lmo.l_coloc(a, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>L-colocation matrix of 1st L-comoment estimates, \\(\\Lambda^{(t_1, t_2)}_1\\).</p> <p>Alias for <code>lmo.l_comoment(a, 1, *, **)</code>.</p> Notes <p>If <code>trim = (0, 0)</code> (default), the L-colocation for \\([ij]\\) is the L-location \\(\\lambda_1\\) of \\(x_i\\), independent of \\(x_j\\).</p> <p>Examples:</p> <p>Without trimming, the L-colocation only provides marginal information:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_loc(x, axis=-1)\narray([-0.02678225,  0.03008309])\n&gt;&gt;&gt; lmo.l_coloc(x)\narray([[-0.02678225, -0.02678225],\n       [ 0.03008309,  0.03008309]])\n</code></pre> <p>But the trimmed L-locations are a different story...</p> <pre><code>&gt;&gt;&gt; lmo.l_loc(x, trim=(1, 1), axis=-1)\narray([-0.10488868, -0.00625729])\n&gt;&gt;&gt; lmo.l_coloc(x, trim=(1, 1))\narray([[-0.10488868, -0.03797989],\n       [ 0.03325074, -0.00625729]])\n</code></pre> <p>What this tells us, is somewhat of a mystery: trimmed L-comoments have been only been briefly mentioned once or twice in the literature.</p> See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_loc</code></li> <li><code>numpy.mean</code></li> </ul>"},{"location":"api/#lmo.l_coscale","title":"<code>lmo.l_coscale(a, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>L-coscale matrix of 2nd L-comoment estimates, \\(\\Lambda^{(t_1, t_2)}_2\\).</p> <p>Alias for <code>lmo.l_comoment(a, 2, *, **)</code>.</p> <p>Analogous to the (auto-) variance-covariance matrix, the L-coscale matrix is positive semi-definite, and its main diagonal contains the L-scale's. conversely, the L-coscale matrix is inherently asymmetric, thus yielding more information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_scale(x, trim=(1, 1), axis=-1)\narray([0.66698774, 0.54440895])\n&gt;&gt;&gt; lmo.l_coscale(x, trim=(1, 1))\narray([[ 0.66698774, -0.41025416],\n       [-0.37918065,  0.54440895]])\n</code></pre> See Also <ul> <li><code>lmo.l_comoment</code></li> <li><code>lmo.l_scale</code></li> <li><code>numpy.cov</code></li> </ul>"},{"location":"api/#lmo.l_corr","title":"<code>lmo.l_corr(a, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>Sample L-correlation coefficient matrix \\(\\tilde\\Lambda^{(t_1, t_2)}_2\\); the ratio of the L-coscale matrix over the L-scale column-vectors.</p> <p>Alias for <code>lmo.l_coratio(a, 2, 2, *, **)</code>.</p> <p>The diagonal consists of all 1's.</p> <p>Where the pearson correlation coefficient measures linearity, the (T)L-correlation coefficient measures monotonicity.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo, numpy as np\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; cov = np.array([[6, -3], [-3, 3.5]])\n&gt;&gt;&gt; x = rng.multivariate_normal([0, 0], [[6, -3], [-3, 3.5]], 99).T\n&gt;&gt;&gt; lmo.l_corr(x)\narray([[ 1.        , -0.65247355],\n       [-0.67503962,  1.        ]])\n</code></pre> <p>Let's compare this with the theoretical correlation</p> <pre><code>&gt;&gt;&gt; cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n-0.6546536707079772\n</code></pre> <p>and the (Pearson) correlation coefficient matrix:</p> <pre><code>&gt;&gt;&gt; np.corrcoef(x)\narray([[ 1.        , -0.66383285],\n       [-0.66383285,  1.        ]])\n</code></pre> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>numpy.corrcoef</code></li> </ul>"},{"location":"api/#lmo.l_coskew","title":"<code>lmo.l_coskew(a, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>Sample L-coskewness coefficient matrix \\(\\tilde\\Lambda^{(t_1, t_2)}_3\\).</p> <p>Alias for <code>lmo.l_coratio(a, 3, 2, *, **)</code>.</p> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>lmo.l_skew</code></li> </ul>"},{"location":"api/#lmo.l_cokurtosis","title":"<code>lmo.l_cokurtosis(a, /, trim=(0, 0), *, dtype=np.float_, **kwargs)</code>","text":"<p>Sample L-cokurtosis coefficient matrix \\(\\tilde\\Lambda^{(t_1, t_2)}_4\\).</p> <p>Alias for <code>lmo.l_coratio(a, 4, 2, *, **)</code>.</p> See Also <ul> <li><code>lmo.l_coratio</code></li> <li><code>lmo.l_kurtosis</code></li> </ul>"},{"location":"api/#distributions","title":"Distributions","text":""},{"location":"api/#lmo.l_rv_generic","title":"<code>lmo.l_rv_generic</code>","text":"<p>             Bases: <code>PatchClass</code></p> <p>Additional methods that are patched into <code>scipy.stats.rv_continuous</code> and <code>scipy.stats.rv_discrete</code>.</p>"},{"location":"api/#lmo.l_rv_generic.l_moment","title":"<code>l_moment(r, /, *args, trim=(0, 0), quad_opts=None, **kwds)</code>","text":"<p>Population L-moment(s) \\(\\lambda^{(s,t)}_r\\).</p> \\[ \\lambda^{(s, t)}_r = \\frac{r+s+t}{r} \\frac{B(r,\\,r+s+t)}{B(r+s,\\,r+t)} \\mathbb{E}_X \\left[     U^s     \\left(1 - U\\right)^t     \\,\\tilde{P}^{(t, s)}_{r-1}(U)     \\,X \\right] \\;, \\] <p>with \\(U = F_X(X)\\) the rank of \\(X\\), and \\(\\tilde{P}^{(a,b)}_n(x)\\) the shifted (\\(x \\mapsto 2x-1\\)) Jacobi polynomial.</p> <p>Examples:</p> <p>Evaluate the population L-moments of the normally-distributed IQ test:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import norm\n&gt;&gt;&gt; norm(100, 15).l_moment([1, 2, 3, 4]).round(6)\narray([100.      ,   8.462844,   0.      ,   1.037559])\n&gt;&gt;&gt; _[1] * np.sqrt(np.pi)\n15.000000...\n</code></pre> <p>Discrete distributions are also supported, e.g. the Binomial distribution:</p> <pre><code>&gt;&gt;&gt; from scipy.stats import binom\n&gt;&gt;&gt; binom(10, .6).l_moment([1, 2, 3, 4]).round(6)\narray([ 6.      ,  0.862238, -0.019729,  0.096461])\n</code></pre> PARAMETER  DESCRIPTION <code>r</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p><code>r</code> is not integer-valued</p> <code>ValueError</code> <p><code>r</code> is empty or negative</p> RETURNS DESCRIPTION <code>lmbda</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>.</p> <p> TYPE: <code>np.float_ | npt.NDArray[np.float_]</code> </p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of     trimmed L-moments</li> </ul> See Also <ul> <li><code>lmo.l_moment</code>: sample L-moment</li> </ul>"},{"location":"api/#lmo.l_rv_generic.l_ratio","title":"<code>l_ratio(r, k, /, *args, trim=(0, 0), quad_opts=None, **kwds)</code>","text":"<p>L-moment ratio('s) \\(\\tau^{(s,t)}_{r,k}\\).</p> \\[ \\tau^{(s,t)}_{r,k} = \\frac{\\lambda^{(s,t)}_r}{\\lambda^{(s,t)}_k} \\] <p>Unless explicitly specified, the r-th (\\(r&gt;2\\)) L-ratio, \\(\\tau^{(s,t)}_r\\) refers to \\(\\tau^{(s,t)}_{r, 2}\\). Another special case is the L-variation, or the L-CV, \\(\\tau^{(s,t)} = \\tau^{(s,t)}_{2, 1}\\). This is the L-moment analogue of the coefficient of variation.</p> <p>Examples:</p> <p>Evaluate the population L-CV and LL-CV (CV = coefficient of variation) of the standard Rayleigh distribution.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.rayleigh()\n&gt;&gt;&gt; X.std() / X.mean()  # legacy CV\n0.5227232...\n&gt;&gt;&gt; X.l_ratio(2, 1)\n0.2928932...\n&gt;&gt;&gt; X.l_ratio(2, 1, trim=(0, 1))\n0.2752551...\n</code></pre> <p>And similarly, for the (discrete) Poisson distribution with rate parameter set to 2, the L-CF and LL-CV evaluate to:</p> <pre><code>&gt;&gt;&gt; X = distributions.poisson(2)\n&gt;&gt;&gt; X.std() / X.mean()\n0.7071067...\n&gt;&gt;&gt; X.l_ratio(2, 1)\n0.3857527...\n&gt;&gt;&gt; X.l_ratio(2, 1, trim=(0, 1))\n0.4097538...\n</code></pre> <p>Note that (untrimmed) L-CV requires a higher (subdivision) limit in the integration routine, otherwise it'll complain that it didn't converge (enough) yet. This is because it's effectively integrating a non-smooth function, which is mathematically iffy, but works fine in this numerical application.</p> PARAMETER  DESCRIPTION <code>r</code> <p>L-moment ratio order(s), non-negative integer or array-like of integers.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>k</code> <p>L-moment order of the denominator, e.g. 2.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> See Also <ul> <li><code>lmo.l_rv_generic.l_moment</code></li> <li><code>lmo.l_ratio</code> - Sample L-moment ratio estimator</li> </ul>"},{"location":"api/#lmo.l_rv_generic.l_stats","title":"<code>l_stats(*args, trim=(0, 0), moments=4, quad_opts=None, **kwds)</code>","text":"<p>The L-moments (for \\(r \\le 2\\)) and L-ratio's (for \\(r &gt; 2\\)).</p> <p>By default, the first <code>moments = 4</code> population L-stats are calculated:</p> <ul> <li>\\(\\lambda^{(s,t)}_1\\) - L-location</li> <li>\\(\\lambda^{(s,t)}_2\\) - L-scale</li> <li>\\(\\tau^{(s,t)}_3\\) - L-skewness coefficient</li> <li>\\(\\tau^{(s,t)}_4\\) - L-kurtosis coefficient</li> </ul> <p>This method is equivalent to <code>X.l_ratio([1, 2, 3, 4], [0, 0, 2, 2], *, **)</code>, for with default <code>moments = 4</code>.</p> <p>Examples:</p> <p>Summarize the standard exponential distribution for different trim-orders.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.expon()\n&gt;&gt;&gt; X.l_stats().round(6)\narray([1.      , 0.5     , 0.333333, 0.166667])\n&gt;&gt;&gt; X.l_stats(trim=(0, 1/2)).round(6)\narray([0.666667, 0.333333, 0.266667, 0.114286])\n&gt;&gt;&gt; X.l_stats(trim=(0, 1)).round(6)\narray([0.5     , 0.25    , 0.222222, 0.083333])\n</code></pre> Note <p>This should not be confused with the term L-statistic, which is sometimes used to describe any linear combination of order statistics.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>moments</code> <p>The amount of L-moments to return. Defaults to 4.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> See Also <ul> <li><code>lmo.l_rv_generic.l_ratio</code></li> <li><code>lmo.l_stats</code> - Unbiased sample estimation of   L-stats.</li> </ul>"},{"location":"api/#lmo.l_rv_generic.l_loc","title":"<code>l_loc(*args, trim=(0, 0), **kwds)</code>","text":"<p>L-location of the distribution, i.e. the 1st L-moment.</p> <p>Alias for <code>X.l_moment(1, ...)</code>.</p>"},{"location":"api/#lmo.l_rv_generic.l_scale","title":"<code>l_scale(*args, trim=(0, 0), **kwds)</code>","text":"<p>L-scale of the distribution, i.e. the 2nd L-moment.</p> <p>Alias for <code>X.l_moment(2, ...)</code>.</p>"},{"location":"api/#lmo.l_rv_generic.l_skew","title":"<code>l_skew(*args, trim=(0, 0), **kwds)</code>","text":"<p>L-skewness coefficient of the distribution; the 3rd L-moment ratio.</p> <p>Alias for <code>X.l_ratio(3, 2, ...)</code>.</p>"},{"location":"api/#lmo.l_rv_generic.l_kurtosis","title":"<code>l_kurtosis(*args, trim=(0, 0), **kwds)</code>","text":"<p>L-kurtosis coefficient of the distribution; the 4th L-moment ratio.</p> <p>Alias for <code>X.l_ratio(4, 2, ...)</code>.</p>"},{"location":"api/#lmo.l_rv_generic.l_moments_cov","title":"<code>l_moments_cov(r_max, /, *args, trim=(0, 0), quad_opts=None, **kwds)</code>","text":"<p>Variance/covariance matrix of the L-moment estimators.</p> <p>L-moments that are estimated from \\(n\\) samples of a distribution with CDF \\(F\\), converge to the multivariate normal distribution as the sample size \\(n \\rightarrow \\infty\\).</p> \\[ \\sqrt{n} \\left(     \\vec{l}^{(s, t)} - \\vec{\\lambda}^{(s, t)} \\right) \\sim \\mathcal{N}(     \\vec{0},     \\mathbf{\\Lambda}^{(s, t)} ) \\] <p>Here, \\(\\vec{l}^{(s, t)} = \\left[l^{(s,t)}_r, \\dots, l^{(s,t)}_{r_{max}}\\right]^T\\) is a vector of estimated sample L-moments, and \\(\\vec{\\lambda}^{(s, t)}\\) its theoretical (\"true\") counterpart.</p> <p>This function calculates the covariance matrix</p> \\[ \\begin{align} \\bf{\\Lambda}^{(s,t)}_{k, r}     &amp;= \\mathrm{Cov}[l^{(s, t)}_k, l^{(s, t)}_r] \\\\     &amp;= c_k c_r     \\iint\\limits_{x &lt; y} \\Big[         p_k\\big(F(x)\\big) \\, p_r\\big(F(y)\\big) +         p_r\\big(F(x)\\big) \\, p_k\\big(F(y)\\big)     \\Big]     w^{(s+1,\\, t)}\\big(F(x)\\big) \\,     w^{(s,\\, t+1)}\\big(F(y)\\big) \\,     \\mathrm{d}x \\, \\mathrm{d}y     \\;, \\end{align} \\] <p>where</p> \\[ c_n = \\frac{\\Gamma(n) \\Gamma(n+s+t+1)}{n \\Gamma(n+s) \\Gamma(n+t)}\\;, \\] <p>the shifted Jacobi polynomial \\(p_n(u) = P^{(t, s)}_{n-1}(2u - 1)\\), \\(P^{(t, s)}_m\\), and \\(w^{(s,t)}(u) = u^s (1-u)^t\\) its weight function.</p> Notes <p>This function is not vectorized or parallelized.</p> <p>For small sample sizes (\\(n &lt; 100\\)), the covariances of the higher-order L-moments (\\(r &gt; 2\\)) can be biased. But this bias quickly disappears at roughly \\(n &gt; 200\\) (depending on the trim- and L-moment orders).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.expon()  # standard exponential distribution\n&gt;&gt;&gt; X.l_moments_cov(4).round(6)\narray([[1.      , 0.5     , 0.166667, 0.083333],\n    [0.5     , 0.333333, 0.166667, 0.083333],\n    [0.166667, 0.166667, 0.133333, 0.083333],\n    [0.083333, 0.083333, 0.083333, 0.071429]])\n</code></pre> <pre><code>&gt;&gt;&gt; X.l_moments_cov(4, trim=(0, 1)).round(6)\narray([[0.333333, 0.125   , 0.      , 0.      ],\n    [0.125   , 0.075   , 0.016667, 0.      ],\n    [0.      , 0.016667, 0.016931, 0.00496 ],\n    [0.      , 0.      , 0.00496 , 0.0062  ]])\n</code></pre> PARAMETER  DESCRIPTION <code>r_max</code> <p>The amount of L-moment orders to consider. If for example <code>r_max = 4</code>, the covariance matrix will be of shape <code>(4, 4)</code>, and the columns and rows correspond to the L-moments of order \\(r = 1, \\dots, r_{max}\\).</p> <p> TYPE: <code>int</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>cov</code> <p>Covariance matrix, with shape <code>(r_max, r_max)</code>.</p> <p> TYPE: <code>npt.NDArray[np.float_]</code> </p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If the covariance matrix is invalid.</p> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of     trimmed L-moments</li> </ul>"},{"location":"api/#lmo.l_rv_generic.l_stats_cov","title":"<code>l_stats_cov(*args, moments=4, trim=(0, 0), quad_opts=None, **kwds)</code>","text":"<p>Similar to <code>l_moments_cov</code>, but for the <code>l_stats</code>.</p> <p>As the sample size \\(n \\rightarrow \\infty\\), the L-moment ratio's are also distributed (multivariate) normally. The L-stats are defined to be L-moments for \\(r\\le 2\\), and L-ratio coefficients otherwise.</p> <p>The corresponding covariance matrix has been found to be</p> \\[ \\bf{T}^{(s, t)}_{k, r} = \\begin{cases}     \\bf{\\Lambda}^{(s, t)}_{k, r}         &amp; k \\le 2 \\wedge r \\le 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}     }{         \\lambda^{(s,t)}_{2}     }         &amp; k \\le 2 \\wedge r &gt; 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_k \\bf{\\Lambda}^{(s, t)}_{2, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}         + \\tau_k \\tau_r \\bf{\\Lambda}^{(s, t)}_{2, 2}     }{         \\Big( \\lambda^{(s,t)}_{2} \\Big)^2     }         &amp; k &gt; 2 \\wedge r &gt; 2 \\end{cases} \\] <p>where \\(\\bf{\\Lambda}^{(s, t)}\\) is the covariance matrix of the L-moments from <code>l_moment_cov_from_cdf</code>, and \\(\\tau^{(s,t)}_r = \\lambda^{(s,t)}_r / \\lambda^{(s,t)}_2\\) the population L-ratio.</p> <p>Examples:</p> <p>Evaluate the LL-stats covariance matrix of the standard exponential distribution, for 0, 1, and 2 degrees of trimming.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; from scipy.stats import distributions\n&gt;&gt;&gt; X = distributions.expon()  # standard exponential distribution\n&gt;&gt;&gt; X.l_stats_cov().round(6)\narray([[1.      , 0.5     , 0.      , 0.      ],\n    [0.5     , 0.333333, 0.111111, 0.055556],\n    [0.      , 0.111111, 0.237037, 0.185185],\n    [0.      , 0.055556, 0.185185, 0.21164 ]])\n&gt;&gt;&gt; X.l_stats_cov(trim=(0, 1)).round(6)\narray([[ 0.333333,  0.125   , -0.111111, -0.041667],\n    [ 0.125   ,  0.075   ,  0.      , -0.025   ],\n    [-0.111111,  0.      ,  0.21164 ,  0.079365],\n    [-0.041667, -0.025   ,  0.079365,  0.10754 ]])\n&gt;&gt;&gt; X.l_stats_cov(trim=(0, 2)).round(6)\narray([[ 0.2     ,  0.066667, -0.114286, -0.02    ],\n    [ 0.066667,  0.038095, -0.014286, -0.023333],\n    [-0.114286, -0.014286,  0.228571,  0.04    ],\n    [-0.02    , -0.023333,  0.04    ,  0.086545]])\n</code></pre> <p>Note that with 0 trim the L-location is independent of the L-skewness and L-kurtosis. With 1 trim, the L-scale and L-skewness are independent. And with 2 trim, all L-stats depend on each other.</p> PARAMETER  DESCRIPTION <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>moments</code> <p>The amount of L-statistics to consider. Defaults to 4.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of     trimmed L-moments</li> </ul>"},{"location":"api/#lmo.l_rv_generic.l_moment_influence","title":"<code>l_moment_influence(r, /, *args, trim=(0, 0), quad_opts=None, tol=1e-08, **kwds)</code>","text":"<p>Returns the influence function (IF) of an L-moment.</p> \\[ \\psi_{\\lambda^{(s, t)}_r | F}(x)     = c^{(s,t)}_r     \\, F(x)^s     \\, \\big( 1-{F}(x) \\big)^t     \\, \\tilde{P}^{(s,t)}_{r-1} \\big( F(x) \\big)     \\, x     - \\lambda^{(s,t)}_r     \\;, \\] <p>with \\(F\\) the CDF, \\(\\tilde{P}^{(s,t)}_{r-1}\\) the shifted Jacobi polynomial, and</p> \\[ c^{(s,t)}_r     = \\frac{r+s+t}{r} \\frac{B(r, \\, r+s+t)}{B(r+s, \\, r+t)}     \\;, \\] <p>where \\(B\\) is the (complete) Beta function.</p> <p>The proof is trivial, because population L-moments are linear functionals.</p> Notes <p>The order parameter <code>r</code> is not vectorized.</p> PARAMETER  DESCRIPTION <code>r</code> <p>The L-moment order \\(r \\in \\mathbb{N}^+\\)..</p> <p> TYPE: <code>AnyInt</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>tol</code> <p>Values that are absolutely smaller than this will be rounded to zero.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>influence_function</code> <p>The (vectorized) influence function, \\(\\psi_{\\lambda^{(s, t)}_r | F}(x)\\).</p> <p> TYPE: <code>Callable[[V], V]</code> </p> See Also <ul> <li><code>lmo.l_rv_generic.l_moment</code></li> <li><code>lmo.l_moment</code></li> </ul> References <ul> <li>Frank R. Hampel (1974) - The Influence Curve and its Role in     Robust Estimation</li> </ul>"},{"location":"api/#lmo.l_rv_generic.l_ratio_influence","title":"<code>l_ratio_influence(r, k, /, *args, trim=(0, 0), quad_opts=None, tol=1e-08, **kwds)</code>","text":"<p>Returns the influence function (IF) of an L-moment ratio.</p> \\[ \\psi_{\\tau^{(s, t)}_{r,k}|F}(x) = \\frac{     \\psi_{\\lambda^{(s, t)}_r|F}(x)     - \\tau^{(s, t)}_{r,k} \\, \\psi_{\\lambda^{(s, t)}_k|F}(x) }{     \\lambda^{(s,t)}_k } \\;, \\] <p>where the L-moment ratio is defined as</p> \\[ \\tau^{(s, t)}_{r,k} = \\frac{     \\lambda^{(s, t)}_r }{     \\lambda^{(s, t)}_k } \\;. \\] <p>Because IF's are a special case of the general G\u00e2teuax derivative, the L-ratio IF is derived by applying the chain rule to the L-moment IF.</p> PARAMETER  DESCRIPTION <code>r</code> <p>L-moment ratio order, i.e. the order of the numerator L-moment.</p> <p> TYPE: <code>AnyInt</code> </p> <code>k</code> <p>Denominator L-moment order, defaults to 2.</p> <p> TYPE: <code>AnyInt</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float. or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> DEFAULT: <code>None</code> </p> <code>tol</code> <p>Values that are absolutely smaller than this will be rounded to zero.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1e-08</code> </p> <code>**kwds</code> <p>Additional keyword arguments to pass to the distribution.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>influence_function</code> <p>The influence function, with vectorized signature <code>() -&gt; ()</code>.</p> <p> TYPE: <code>Callable[[V], V]</code> </p> See Also <ul> <li><code>lmo.l_rv_generic.l_ratio</code></li> <li><code>lmo.l_ratio</code></li> </ul> References <ul> <li>Frank R. Hampel (1974) - The Influence Curve and its Role in     Robust Estimation</li> </ul>"},{"location":"api/#lmo.l_rv_generic.fit_l","title":"<code>fit_l(data, *args, trim=(0, 0), optimizer='Nelder-Mead')</code>","text":"<p>Return estimates of shape (if applicable), location, and scale parameters from data, using Method of L-Moments (LMM).</p> Notes <p>The implementation mimics that of <code>fit(method='MM')</code></p> <p>Examples:</p> <p>Fitting of the generalized extreme value (GEV) distribution with MLE (maximum likelihood estimation, which is used by default in <code>.fit</code>) vs LMM with different degrees of trimming.</p> <pre><code>&gt;&gt;&gt; from scipy.stats import genextreme\n&gt;&gt;&gt; c, loc, scale = -0.5, 0, 1\n&gt;&gt;&gt; data = genextreme(c, loc, scale).rvs(1000, random_state=12345)\n&gt;&gt;&gt; genextreme.fit(data)\n(-0.4670..., 0.0294..., 1.0241...)\n&gt;&gt;&gt; genextreme.fit_l(data)\n(-0.447..., 0.085..., 1.036...)\n&gt;&gt;&gt; genextreme.fit_l(data, trim=(0, 1))\n(-0.483..., 0.022..., 1.017...)\n&gt;&gt;&gt; genextreme.fit_l(data, trim=(0, 2))\n(-0.486..., 0.016..., 1.016...)\n</code></pre> PARAMETER  DESCRIPTION <code>data</code> <p>Data to fit.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information).</p> <p> TYPE: <code>float</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>optimizer</code> <p>See the <code>method</code> parameter in <code>scipy.optimize.minimize</code>. Defaults to <code>'Nelder-Mead'</code>. Note that other methods (e.g.<code>'BFGS'</code> or <code>'SLSQP'</code>) can be a lot faster, but may not be as accurate.</p> <p> TYPE: <code>str | Callable[..., OptimizeResult]</code> DEFAULT: <code>'Nelder-Mead'</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Tuple of floats with estimates of the shape parameters (if</p> <code>...</code> <p>applicable), followed by those for location and scale.</p>"},{"location":"api/#lmo.l_rv_generic.fit_l_loc_scale","title":"<code>fit_l_loc_scale(data, *args, trim=(0, 0))</code>","text":"<p>Estimate loc and scale parameters from data using 1st and 2nd L-moments.</p> Notes <p>The implementation mimics that of <code>fit_loc_scale()</code></p> PARAMETER  DESCRIPTION <code>data</code> <p>Data to fit.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>*args</code> <p>The shape parameter(s) for the distribution (see docstring of the instance object for more information).</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>trim</code> <p>Left- and right- trim. Can be scalar or 2-tuple of non-negative int or float.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> RETURNS DESCRIPTION <code>loc_hat</code> <p>Estimated location parameter for the data.</p> <p> TYPE: <code>float</code> </p> <code>scale_hat</code> <p>Estimated scale parameter for the data.</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/#lmo.l_rv_nonparametric","title":"<code>lmo.l_rv_nonparametric(l_moments, trim=(0, 0), a=None, b=None, **kwargs)</code>","text":"<p>             Bases: <code>rv_continuous</code></p> <p>Estimate a distribution using the given L-moments. See <code>scipy.stats.rv_continuous</code> for the available method.</p> <p>The PPF (quantile function) is estimated using generalized Fourier series, with the (shifted) Jacobi orthogonal polynomials as basis, and the (scaled) L-moments as coefficients.</p> <p>The corrected version of theorem 3 from Hosking (2007) states that</p> \\[ \\hat{Q}(q) = \\sum_{r=1}^{R}     \\frac{(r + 1) (2r + s + t - 1)}{r + s + t + 1}     \\lambda^{(s, t)}_r     P^{(t, s)}_{r - 1}(2u - 1) \\; , \\] <p>converges almost everywhere as \\(R \\rightarrow \\infty\\), for any sufficiently smooth (quantile) function \\(Q(u)\\) with \\(0 &lt; u &lt; 1\\).</p> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> <li>Wolfram Research - Jacobi polynomial Fourier Expansion</li> </ul> See Also <ul> <li>Generalized Fourier series - Wikipedia</li> </ul> PARAMETER  DESCRIPTION <code>l_moments</code> <p>Vector containing the first \\(R\\) consecutive L-moments \\(\\left[ \\lambda^{(s, t)}_1 \\; \\lambda^{(s, t)}_2 \\; \\dots \\; \\lambda^{(s, t)}_R \\right]\\), where \\(R \\ge 2\\).</p> <p>Sample L-moments can be estimated using e.g. <code>lmo.l_moment(x, np.mgrid[:R] + 1, trim=(s, t))</code>.</p> <p>The trim-lengths \\((s, t)\\) should be the same for all L-moments.</p> <p> TYPE: <code>FloatVector</code> </p> <code>trim</code> <p>The left and right trim-lengths \\((s, t)\\), that correspond to the provided <code>l_moments</code>.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>a</code> <p>Lower bound of the support of the distribution. By default it is estimated from the L-moments.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>b</code> <p>Upper bound of the support of the distribution. By default it is estimated from the L-moments.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>**kwargs</code> <p>Optional params for <code>scipy.stats.rv_continuous</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If <code>len(l_moments) &lt; 2</code>, <code>l_moments.ndim != 1</code>, or there are invalid L-moments / trim-lengths.</p>"},{"location":"api/#lmo.l_rv_nonparametric.l_moments","title":"<code>l_moments: npt.NDArray[np.float_]</code>  <code>property</code>","text":"<p>Initial L-moments, for orders \\(r = 1, 2, \\dots, R\\).</p>"},{"location":"api/#lmo.l_rv_nonparametric.trim","title":"<code>trim: tuple[int, int] | tuple[float, float]</code>  <code>property</code>","text":"<p>The provided trim-lengths \\((s, t)\\).</p>"},{"location":"api/#lmo.l_rv_nonparametric.ppf_poly","title":"<code>ppf_poly: PolySeries</code>  <code>property</code>","text":"<p>Polynomial estimate of the percent point function (PPF), a.k.a. the quantile function (QF), or the inverse cumulative distribution function (ICDF).</p> Note <p>Converges to the \"true\" PPF in the mean-squared sense, with weight function \\(q^s (1 - q)^t\\) of quantile \\(q \\in \\[0, 1\\]\\), and trim-lengths \\((t_1, t_2) \\in \\mathbb{R^+} \\times \\mathbb{R^+}\\).</p> RETURNS DESCRIPTION <code>PolySeries</code> <p>A <code>numpy.polynomial.Legendre</code> orthogonal polynomial series instance.</p>"},{"location":"api/#lmo.l_rv_nonparametric.cdf_poly","title":"<code>cdf_poly: PolySeries</code>  <code>cached</code> <code>property</code>","text":"<p>Polynomial least-squares interpolation of the CDF.</p> RETURNS DESCRIPTION <code>PolySeries</code> <p>A <code>numpy.polynomial.Legendre</code> orthogonal polynomial series instance.</p>"},{"location":"api/#lmo.l_rv_nonparametric.pdf_poly","title":"<code>pdf_poly: PolySeries</code>  <code>cached</code> <code>property</code>","text":"<p>Derivative of the polynomial interpolation of the CDF, i.e. the polynomial estimate of the PDF.</p> RETURNS DESCRIPTION <code>PolySeries</code> <p>A <code>numpy.polynomial.Legendre</code> orthogonal polynomial series instance.</p>"},{"location":"api/#lmo.l_rv_nonparametric.fit","title":"<code>fit(data, /, rmax=None, trim=(0, 0))</code>  <code>classmethod</code>","text":"<p>Estimate L-moment from the samples, and return a new <code>l_rv_nonparametric</code> instance.</p> PARAMETER  DESCRIPTION <code>data</code> <p>1d array-like with univariate sample observations.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>rmax</code> <p>The (maximum) amount of L-moment orders to use. Defaults to \\(\\lceil 4 \\log_{10} N \\rceil\\). The quantile polynomial will be of degree <code>rmax - 1</code>.</p> <p> TYPE: <code>SupportsIndex | None</code> DEFAULT: <code>None</code> </p> <code>trim</code> <p>The left and right trim-lengths \\((s, t)\\), that correspond to the provided <code>l_moments</code>.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> RETURNS DESCRIPTION <code>l_rv_nonparametric</code> <p>A fitted <code>l_rv_nonparametric</code> instance.</p> Todo <ul> <li>Optimal <code>rmax</code> selection (the error appears to be periodic..?)</li> <li>Optimal <code>trim</code> selection</li> </ul>"},{"location":"api/#statistical-test-and-tools","title":"Statistical test and tools","text":"<p>Hypothesis tests, estimator properties, and performance metrics.</p>"},{"location":"api/#lmo.diagnostic.HypothesisTestResult","title":"<code>lmo.diagnostic.HypothesisTestResult</code>","text":"<p>             Bases: <code>NamedTuple</code></p> <p>Results of a hypothesis test.</p> ATTRIBUTE DESCRIPTION <code>statistic</code> <p>The raw test statistic. Its distribution depends on the specific test implementation.</p> <p> TYPE: <code>float | npt.NDArray[np.float_]</code> </p> <code>pvalue</code> <p>Two-sided probability value corresponding to the the null hypothesis, \\(H_0\\).</p> <p> TYPE: <code>float | npt.NDArray[np.float_]</code> </p>"},{"location":"api/#lmo.diagnostic.HypothesisTestResult.is_valid","title":"<code>is_valid: bool | npt.NDArray[np.bool_]</code>  <code>property</code>","text":"<p>Check if the statistic is finite and not <code>nan</code>.</p>"},{"location":"api/#lmo.diagnostic.HypothesisTestResult.is_significant","title":"<code>is_significant(level=0.05)</code>","text":"<p>Whether or not the null hypothesis can be rejected, with a certain confidence level (5% by default).</p>"},{"location":"api/#lmo.diagnostic.normaltest","title":"<code>lmo.diagnostic.normaltest(a, /, *, axis=None)</code>","text":"<p>Statistical hypothesis test for non-normality, using the L-skewness and L-kurtosis coefficients on the sample data..</p> <p>Adapted from Harri &amp; Coble (2011), and includes Hosking's correction.</p> Definition <ul> <li>H0: The data was drawn from a normal distribution.</li> <li>H1: The data was drawn from a non-normal distribution.</li> </ul> <p>Examples:</p> <p>Compare the testing power with <code>scipy.stats.normaltest</code> given 10.000 samples from a contaminated normal distribution.</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from lmo.diagnostic import normaltest\n&gt;&gt;&gt; from scipy.stats import normaltest as normaltest_scipy\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; n = 10_000\n&gt;&gt;&gt; x = 0.9 * rng.normal(0, 1, n) + 0.1 * rng.normal(0, 9, n)\n&gt;&gt;&gt; normaltest(x)[1]\n0.04806618...\n&gt;&gt;&gt; normaltest_scipy(x)[1]\n0.08435627...\n</code></pre> <p>At a 5% significance level, Lmo's test is significant (i.e. indicating non-normality), whereas scipy's test isn't (i.e. inconclusive).</p> PARAMETER  DESCRIPTION <code>a</code> <p>Array-like of sample data.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>axis</code> <p>Axis along which to compute the test.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>HypothesisTestResult</code> <p>A named tuple with:</p> <ul> <li><code>statistic</code>: The \\(\\tau^2_{3, 4}\\) test statistic.</li> <li><code>pvalue</code>: Two-sided chi squared probability for \\(H_0\\).</li> </ul> References <p>A. Harri &amp; K.H. Coble (2011) - Normality testing: Two new tests using L-moments</p>"},{"location":"api/#lmo.diagnostic.l_moment_gof","title":"<code>lmo.diagnostic.l_moment_gof(rv_or_cdf, l_moments, n_obs, /, trim=(0, 0), **kwargs)</code>","text":"<p>Goodness-of-fit (GOF) hypothesis test for the null hypothesis that the observed L-moments come from a distribution with the given <code>scipy.stats</code> distribution or cumulative distribution function (CDF).</p> <ul> <li><code>H0</code>: The theoretical probability distribution, with the given CDF,     is a good fit for the observed L-moments.</li> <li><code>H1</code>: The distribution is not a good fit for the observed L-moments.</li> </ul> <p>The test statistic is the squared Mahalanobis distance between the \\(n\\) observed L-moments, and the theoretical L-moments. It asymptically (in sample size) follows the \\(\\chi^2\\) distribution, with \\(n\\) degrees of freedom.</p> <p>The sample L-moments are expected to be of consecutive orders \\(r = 1, 2, \\dots, n\\). Generally, the amount of L-moments \\(n\\) should not be less than the amount of parameters of the distribution, including the location and scale parameters. Therefore, it is required to have \\(n \\ge 2\\).</p> Notes <p>The theoretical L-moments and their covariance matrix are calculated from the CDF using numerical integration (<code>scipy.integrate.quad</code> and <code>scipy.integrate.nquad</code>). Undefined or infinite integrals cannot be detected, in which case the results might be incorrect.</p> <p>If an <code>IntegrationWarning</code> is issued, or the function is very slow, then the results are probably incorrect, and larger degrees of trimming should be used.</p> <p>Examples:</p> <p>Test if the samples are drawn from a normal distribution.</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from lmo.diagnostic import l_moment_gof\n&gt;&gt;&gt; from scipy.stats import norm\n&gt;&gt;&gt; rng = np.random.default_rng(12345)\n&gt;&gt;&gt; X = norm(13.12, 1.66)\n&gt;&gt;&gt; n = 1_000\n&gt;&gt;&gt; x = X.rvs(n, random_state=rng)\n&gt;&gt;&gt; x_lm = lmo.l_moment(x, [1, 2, 3, 4])\n&gt;&gt;&gt; l_moment_gof(X, x_lm, n).pvalue\n0.8259...\n</code></pre> <p>Contaminated samples:</p> <pre><code>&gt;&gt;&gt; y = 0.9 * x + 0.1 * rng.normal(X.mean(), X.std() * 10, n)\n&gt;&gt;&gt; y_lm = lmo.l_moment(y, [1,2,3,4])\n&gt;&gt;&gt; y_lm.round(3)\narray([1.3193e+01, 1.2860e+00, 6.0000e-03, 1.6800e-01])\n&gt;&gt;&gt; l_moment_gof(X, y_lm, n).pvalue\n1.2668...e-60\n</code></pre> See Also <ul> <li><code>l_moment_from_cdf</code></li> <li>'l_moment_cov_from_cdf'</li> </ul>"},{"location":"api/#lmo.diagnostic.l_stats_gof","title":"<code>lmo.diagnostic.l_stats_gof(rv_or_cdf, l_stats, n_obs, /, trim=(0, 0), **kwargs)</code>","text":"<p>Analogous to <code>lmo.diagnostic.l_moment_gof</code>, but using the L-stats (see <code>lmo.l_stats</code>).</p>"},{"location":"api/#lmo.diagnostic.l_moment_bounds","title":"<code>lmo.diagnostic.l_moment_bounds(r, /, trim=(0, 0), scale=1.0)</code>","text":"<p>Returns the absolute upper bounds \\(L^{(s,t)}_r\\) on L-moments \\(\\lambda^{(s,t)}_r\\), proportional to the scale \\(\\sigma_X\\) (standard deviation) of the probability distribution of random variable \\(X\\). So \\(\\left| \\lambda^{(s,t)}_r(X) \\right| \\le \\sigma_X \\, L^{(s,t)}_r\\), given that standard deviation \\(\\sigma_X\\) of \\(X\\) exists and is finite.</p> Warning <p>These bounds do not apply to distributions with undefined variance, e.g. the Cauchy distribution, even if trimmed L-moments are used. Distributions with infinite variance (e.g. Student's t with \\(\\nu=2\\)) are a grey area:</p> <p>For the L-scale (\\(r=2\\)), the corresponding bound will not be a valid one. However, it can still be used to find the L-ratio bounds, because the \\(\\sigma_X\\) terms will cancel out. Doing this is not for the faint of heart, as it requires dividing infinity by infinity. So be sure to wear safety glasses.</p> <p>The bounds are derived by applying the Cauchy-Schwarz inequality to the covariance-based definition of generalized trimmed L-moment, for \\(r &gt; 1\\):</p> \\[ \\lambda^{(s,t)}_r(X) =     \\frac{r+s+t}{r}     \\frac{B(r,\\, r+s+t)}{B(r+s,\\, r+t)}     \\mathrm{Cov}\\left[         X,\\;         F(X)^s         \\big(1 - F(X)\\big)^t         P^{(\\alpha, \\beta)}_r(X)     \\right] \\;, \\] <p>where \\(B\\) is the Beta function, \\(P^{(\\alpha, \\beta)}_r\\) the Jacobi polynomial, and \\(F\\) the cumulative distribution function of random variable \\(X\\).</p> <p>After a lot of work, one can (and one did) derive the closed-form inequality:</p> \\[ \\left| \\lambda^{(s,t)}_r(X) \\right| \\le     \\frac{\\sigma_X}{\\sqrt{2 \\pi}}     \\frac{\\Gamma(r+s+t+1)}{r}     \\sqrt{\\frac{         B(r-\\frac{1}{2}, s+\\frac{1}{2}, t+\\frac{1}{2})     }{         \\Gamma(s+t+1) \\Gamma(r+s) \\Gamma(r+t)     }} \\] <p>for \\(r \\in \\mathbb{N}_{\\ge 2}\\) and \\(s, t \\in \\mathbb{R}_{\\ge 0}\\), where \\(\\Gamma\\) is the Gamma function, and \\(B\\) the multivariate Beta function</p> <p>For the untrimmed L-moments, this simplifies to</p> \\[ \\left| \\lambda_r(X) \\right| \\le \\frac{\\sigma_X}{\\sqrt{2 r - 1}} \\,. \\] Notes <p>For \\(r=1\\) there are no bounds, i.e. <code>float('inf')</code> is returned.</p> <p>There are no references; this novel finding is not (yet..?) published by the author, @jorenham.</p> PARAMETER  DESCRIPTION <code>r</code> <p>The L-moment order(s), non-negative integer or array-like of integers.</p> <p> TYPE: <code>IntVector | AnyInt</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((s, t)\\), as a tuple of non-negative ints or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>scale</code> <p>The standard deviation \\(\\sigma_X\\) of the random variable \\(X\\). Defaults to 1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>1.0</code> </p> RETURNS DESCRIPTION <code>out</code> <p>float array or scalar like <code>r</code>.</p> <p> TYPE: <code>float | npt.NDArray[np.float_]</code> </p> See Also <ul> <li><code>l_ratio_bounds</code></li> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"api/#lmo.diagnostic.l_ratio_bounds","title":"<code>lmo.diagnostic.l_ratio_bounds(r, /, trim=(0, 0), *, has_variance=True)</code>","text":"<p>Returns the absolute upper bounds \\(T^{(s,t)}_r\\) on L-moment ratio's \\(\\tau^{(s,t)}_r = \\lambda^{(s,t)}_r / \\lambda^{(s,t)}_r\\), for \\(r \\ge 2\\). So \\(\\left| \\tau^{(s,t)}_r(X) \\right| \\le T^{(s,t)}_r\\), given that \\(\\mathrm{Var}[X] = \\sigma^2_X\\) exists.</p> <p>If the variance of the distribution is not defined, e.g. in case of the Cauchy distribution, this method will not work. In this case, the looser bounds from Hosking (2007) can be used instead, by passing <code>has_variance=False</code>.</p> <p>Examples:</p> <p>Calculate the bounds for different degrees of trimming:</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds([1, 2, 3, 4])\narray([       inf, 1.        , 0.77459667, 0.65465367])\n&gt;&gt;&gt; # the bounds for r=1,2 are the same for all trimmings; skip them\n&gt;&gt;&gt; l_ratio_bounds([3, 4], trim=(1, 1))\narray([0.61475926, 0.4546206 ])\n&gt;&gt;&gt; l_ratio_bounds([3, 4], trim=(.5, 1.5))\narray([0.65060005, 0.49736473])\n</code></pre> <p>In case of undefined variance, the bounds become a lot looser:</p> <pre><code>&gt;&gt;&gt; l_ratio_bounds([3, 4], has_variance=False)\narray([1., 1.])\n&gt;&gt;&gt; l_ratio_bounds([3, 4], trim=(1, 1), has_variance=False)\narray([1.11111111, 1.25      ])\n&gt;&gt;&gt; l_ratio_bounds([3, 4], trim=(.5, 1.5), has_variance=False)\narray([1.33333333, 1.71428571])\n</code></pre> PARAMETER  DESCRIPTION <code>r</code> <p>Order of the L-moment ratio(s), as positive integer scalar or array-like.</p> <p> TYPE: <code>IntVector | AnyInt</code> </p> <code>trim</code> <p>Tuple of left- and right- trim-lengths, matching those of the relevant L-moment ratio's.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> <code>has_variance</code> <p>Set to False if the distribution has undefined variance, in which case the (looser) bounds from J.R.M. Hosking (2007) will be used.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>float | npt.NDArray[np.float_]</code> <p>Array or scalar with shape like \\(r\\).</p> See Also <ul> <li><code>l_ratio</code></li> <li><code>l_ratio_se</code></li> </ul> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed L-moments</li> </ul>"},{"location":"api/#lmo.diagnostic.rejection_point","title":"<code>lmo.diagnostic.rejection_point(influence_fn, /, rho_min=0, rho_max=np.inf)</code>","text":"<p>Evaluate the approximate rejection point of an influence function \\(\\psi_{T|F}(x)\\) given a statistical functional \\(T\\) (e.g. an L-moment) and cumulative distribution function \\(F(x)\\).</p> \\[ \\rho^*_{T|F} = \\inf_{r&gt;0} \\left\\{     r: | \\psi_{T|F}(x) | \\le \\epsilon, \\, |x| &gt; r \\right\\} \\; \\] <p>with a \\(\\epsilon\\) a small positive number, corresponding to the <code>tol</code> param of e.g. <code>lmo.l_rv_generic.l_moment_influence</code>, which defaults to <code>1e-8</code>.</p> <p>Examples:</p> <p>The untrimmed L-location isn't robust, e.g. with the standard normal distribution:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from scipy.stats import distributions as dists\n&gt;&gt;&gt; from lmo.diagnostic import rejection_point\n&gt;&gt;&gt; if_l_loc_norm = dists.norm.l_moment_influence(1, trim=0)\n&gt;&gt;&gt; if_l_loc_norm(np.inf)\ninf\n&gt;&gt;&gt; rejection_point(if_l_loc_norm)\nnan\n</code></pre> <p>For the TL-location of the Gaussian distribution, and even for the Student's t distribution with 4 degrees of freedom (3 also works, but is very slow), they exist.</p> <pre><code>&gt;&gt;&gt; if_tl_loc_norm = dists.norm.l_moment_influence(1, trim=1)\n&gt;&gt;&gt; if_tl_loc_t4 = dists.t(4).l_moment_influence(1, trim=1)\n&gt;&gt;&gt; if_tl_loc_norm(np.inf), if_tl_loc_t4(np.inf)\n(0.0, 0.0)\n&gt;&gt;&gt; rejection_point(if_tl_loc_norm), rejection_point(if_tl_loc_t4)\n(6.0, 206.0)\n</code></pre> Notes <p>Large rejection points (e.g. &gt;1000) are unlikely to be found.</p> <p>For instance, that of the TL-location of the Student's t distribution with 2 degrees of freedom lies between somewhere <code>1e4</code> and <code>1e5</code>, but will not be found. In this case, using <code>trim=2</code> will return <code>166.0</code>.</p> PARAMETER  DESCRIPTION <code>influence_fn</code> <p>Univariate influence function.</p> <p> TYPE: <code>Callable[[float], float]</code> </p> <code>rho_min</code> <p>The minimum \\(\\rho^*_{T|F}\\) of the search space. Must be finite and non-negative. Defaults to \\(0\\).</p> <p> TYPE: <code>float</code> DEFAULT: <code>0</code> </p> <code>rho_max</code> <p>The maximum \\(\\rho^*_{T|F}\\) of the search space. Must be larger than <code>rho_min</code>. Defaults to \\(\\infty\\).</p> <p> TYPE: <code>float</code> DEFAULT: <code>np.inf</code> </p> RETURNS DESCRIPTION <code>float</code> <p>A finite or infinite scalar.</p> See Also <ul> <li><code>l_moment_influence</code></li> <li><code>error_sensitivity</code></li> </ul>"},{"location":"api/#lmo.diagnostic.error_sensitivity","title":"<code>lmo.diagnostic.error_sensitivity(influence_fn, /, domain=(float('-inf'), float('inf')))</code>","text":"<p>Evaluate the gross-error sensitivity of an influence function \\(\\psi_{T|F}(x)\\) given a statistical functional \\(T\\) (e.g. an L-moment) and cumulative distribution function \\(F(x)\\).</p> \\[ \\gamma^*_{T|F} = \\max_{x} \\left| \\psi_{T|F}(x) \\right| \\] <p>Examples:</p> <p>Evaluate the gross-error sensitivity of the standard exponential distribution's LL-skewness (\\(\\tau^{(0, 1)}_3\\)) and LL-kurtosis (\\(\\tau^{(0, 1)}_4\\)) coefficients:</p> <pre><code>&gt;&gt;&gt; from lmo.diagnostic import error_sensitivity\n&gt;&gt;&gt; from scipy.stats import expon\n&gt;&gt;&gt; ll_skew_if = expon.l_ratio_influence(3, 2, trim=(0, 1))\n&gt;&gt;&gt; ll_kurt_if = expon.l_ratio_influence(4, 2, trim=(0, 1))\n&gt;&gt;&gt; error_sensitivity(ll_skew_if, domain=(0, float('inf')))\n1.814657...\n&gt;&gt;&gt; error_sensitivity(ll_kurt_if, domain=(0, float('inf')))\n1.377743...\n</code></pre> PARAMETER  DESCRIPTION <code>influence_fn</code> <p>Univariate influence function.</p> <p> TYPE: <code>Callable[[float], float]</code> </p> <code>domain</code> <p>Domain of the CDF. Defaults to \\((-\\infty, \\infty)\\).</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>(float('-inf'), float('inf'))</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Gross-error sensitivity \\(\\gamma^*_{T|F}\\) .</p> See Also <ul> <li><code>l_moment_influence</code></li> <li><code>rejection_point</code></li> </ul>"},{"location":"api/#lmo.diagnostic.shift_sensitivity","title":"<code>lmo.diagnostic.shift_sensitivity(influence_fn, /, domain=(float('-inf'), float('inf')))</code>","text":"<p>Evaluate the local-shift sensitivity of an influence function \\(\\psi_{T|F}(x)\\) given a statistical functional \\(T\\) (e.g. an L-moment) and cumulative distribution function \\(F(x)\\).</p> \\[ \\lambda^*_{T|F} = \\max_{x \\neq y} \\left| \\frac{ \\psi_{T|F}(y) - \\psi_{T|F}(x) }{ y - x } \\right| \\] <p>Represents the effect of shifting an observation slightly from \\(x\\), to a neighbouring point \\(y\\). For instance, adding an observation at \\(y\\) and removing one at \\(x\\).</p> <p>Examples:</p> <p>Evaluate the local-shift sensitivity of the standard exponential distribution's LL-skewness (\\(\\tau^{(0, 1)}_3\\)) and LL-kurtosis (\\(\\tau^{(0, 1)}_4\\)) coefficients:</p> <pre><code>&gt;&gt;&gt; from lmo.diagnostic import shift_sensitivity\n&gt;&gt;&gt; from scipy.stats import expon\n&gt;&gt;&gt; ll_skew_if = expon.l_ratio_influence(3, 2, trim=(0, 1))\n&gt;&gt;&gt; ll_kurt_if = expon.l_ratio_influence(4, 2, trim=(0, 1))\n&gt;&gt;&gt; domain = 0, float('inf')\n&gt;&gt;&gt; shift_sensitivity(ll_skew_if, domain)\n0.837735...\n&gt;&gt;&gt; shift_sensitivity(ll_kurt_if, domain)\n1.442062...\n</code></pre> <p>Let's compare these with the untrimmed ones:</p> <pre><code>&gt;&gt;&gt; shift_sensitivity(expon.l_ratio_influence(3, 2), domain)\n1.920317...\n&gt;&gt;&gt; shift_sensitivity(expon.l_ratio_influence(4, 2), domain)\n1.047565...\n</code></pre> PARAMETER  DESCRIPTION <code>influence_fn</code> <p>Univariate influence function.</p> <p> TYPE: <code>Callable[[float], float]</code> </p> <code>domain</code> <p>Domain of the CDF. Defaults to \\((-\\infty, \\infty)\\).</p> <p> TYPE: <code>tuple[float, float]</code> DEFAULT: <code>(float('-inf'), float('inf'))</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Local-shift sensitivity \\(\\lambda^*_{T|F}\\) .</p> See Also <ul> <li><code>l_moment_influence</code></li> <li><code>error_sensitivity</code></li> </ul> References <ul> <li>Frank R. Hampel (1974) - The Influence Curve and its Role in     Robust Estimation</li> </ul>"},{"location":"api/#low-level-api","title":"Low-level API","text":""},{"location":"api/#lmo.l_weights","title":"<code>lmo.l_weights(r, n, /, trim=(0, 0), dtype=np.float_, *, cache=False)</code>","text":"<p>Projection matrix of the first \\(r\\) (T)L-moments for \\(n\\) samples.</p> <p>For integer trim is the matrix is a linear combination of the Power Weighted Moment (PWM) weights (the sample estimator of \\(\\beta_{r_1}\\)), and the shifted Legendre polynomials.</p> <p>If the trimmings are nonzero and integers, a linearized (and corrected) adaptation of the recurrence relations from Hosking (2007) are applied, as well.</p> \\[ (2k + s + t - 1) \\lambda^{(s, t)}_k     = (k + s + t) \\lambda^{(s - 1, t)}_k     + \\frac{1}{k} (k + 1) (k + t) \\lambda^{(s - 1, t)}_{k+1} \\] <p>for \\(s &gt; 0\\), and</p> \\[ (2k + s + t - 1) \\lambda^{(s, t)}_k     = (k + s + t) \\lambda^{(s, t - 1)}_k     - \\frac{1}{k} (k + 1) (k + s) \\lambda^{(s, t - 1)}_{k+1} \\] <p>for \\(t &gt; 0\\).</p> <p>If the trim values are floats instead, the weights are calculated directly from the (generalized) order statistics. At the time of writing (07-2023), these \"generalized trimmed L-moments\" have not been discussed in the literature or the R-packages. It's probably a good idea to publish this...</p> TLDR <p>This matrix (linearly) transforms \\(x_{i:n}\\) (i.e. the sorted observation vector(s) of size \\(n\\)), into (an unbiased estimate of) the generalized trimmed L-moments, with orders \\(\\le r\\).</p> RETURNS DESCRIPTION <code>P_r</code> <p>2-D array of shape <code>(r, n)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import lmo\n&gt;&gt;&gt; lmo.l_weights(3, 4)\narray([[ 0.25      ,  0.25      ,  0.25      ,  0.25      ],\n       [-0.25      , -0.08333333,  0.08333333,  0.25      ],\n       [ 0.25      , -0.25      , -0.25      ,  0.25      ]])\n&gt;&gt;&gt; _ @ [-1, 0, 1 / 2, 3 / 2]\narray([0.25      , 0.66666667, 0.        ])\n</code></pre> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/#theoretical","title":"<code>theoretical</code>","text":"<p>Theoretical (population) L-moments of known univariate probability distributions.</p>"},{"location":"api/#lmo.theoretical.l_moment_from_cdf","title":"<code>lmo.theoretical.l_moment_from_cdf(cdf, r, /, trim=(0, 0), *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<p>Evaluate the population L-moment of a continuous probability distribution, using its Cumulative Distribution Function (CDF) \\(F_X(x) = P(X \\le x)\\).</p> \\[ \\lambda^{(s, t)}_r = \\begin{cases}     1 &amp; r = 0 \\\\     \\int_{-\\infty}^{\\infty}         \\left(H(x) - I_{F(x)}(s+1, \\,t+1)\\right)         \\,\\mathrm{d} x     &amp; r = 1 \\\\     \\frac{c^{(s,t)}_r}{r}     \\int_{-\\infty}^{\\infty}         F(x)^{s+1}         \\left(1 - F(x)\\right)^{t+1}         \\,\\tilde{P}^{(t+1, s+1)}_{r-2}\\big(F(x)\\big)         \\,\\mathrm{d} x     &amp; r &gt; 1 \\;, \\end{cases} \\] <p>where</p> \\[ c^{(s,t)}_r = \\frac{r+s+t}{r} \\frac{B(r,\\,r+s+t)}{B(r+s,\\,r+t)} \\;, \\] <p>\\(\\tilde{P}^{(a,b)}_n(x)\\) the shifted (\\(x \\mapsto 2x-1\\)) Jacobi polynomial, \\(H(x)\\) the Heaviside step function, and \\(I_x(\\alpha, \\beta)\\) the regularized incomplete gamma function.</p> Notes <p>Numerical integration is performed with <code>scipy.integrate.quad</code>, which cannot verify whether the integral exists and is finite. If it returns an error message, an <code>IntegrationWarning</code> is issues, and <code>nan</code> is returned (even if <code>quad</code> returned a finite result).</p> <p>Examples:</p> <p>Evaluate the first 4 L- and TL-moments of the standard normal distribution:</p> <pre><code>&gt;&gt;&gt; from scipy.special import ndtr  # standard normal CDF\n&gt;&gt;&gt; l_moment_from_cdf(ndtr, [1, 2, 3, 4])\narray([0.        , 0.56418958, 0.        , 0.06917061])\n&gt;&gt;&gt; l_moment_from_cdf(ndtr, [1, 2, 3, 4], trim=1)\narray([0.        , 0.29701138, 0.        , 0.01855727])\n</code></pre> <p>Evaluate the first 4 TL-moments of the standard Cauchy distribution:</p> <pre><code>&gt;&gt;&gt; def cdf_cauchy(x: float) -&gt; float:\n...     return np.arctan(x) / np.pi + 1 / 2\n&gt;&gt;&gt; l_moment_from_cdf(cdf_cauchy, [1, 2, 3, 4], trim=1)\narray([0.        , 0.69782723, 0.        , 0.23922105])\n</code></pre> PARAMETER  DESCRIPTION <code>cdf</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> <p> TYPE: <code>UnivariateCDF</code> </p> <code>r</code> <p>L-moment order(s), non-negative integer or array-like of integers.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right- trim, either as a \\((s, t)\\) tuple with \\(s, t &gt; -1/2\\), or \\(t\\) as alias for \\((t, t)\\).</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>. Generally it's not needed to provide this, as it will be guessed automatically.</p> <p> TYPE: <code>Pair[float] | None</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> <code>alpha</code> <p>Split the integral into integrals with limits \\([a, F^{-1}(\\alpha)]\\), \\([F(\\alpha), F^{-1}(1 - \\alpha)]\\) and \\([F^{-1}(1 - \\alpha), b]\\) to improve numerical stability. So \\(\\alpha\\) can be consideresd the size of the tail. Numerical experiments have found 0.05 to give good results for different distributions.</p> <p> TYPE: <code>float</code> </p> <code>ppf</code> <p>The inverse of the cdf, used with <code>alpha</code> to calculate the integral split points (if provided).</p> <p> TYPE: <code>UnivariatePPF | None</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p><code>r</code> is not integer-valued or negative</p> <code>ValueError</code> <p><code>r</code> is negative</p> RETURNS DESCRIPTION <code>lmbda</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>. If <code>nan</code>, consult the related <code>IntegrationWarning</code> message.</p> <p> TYPE: <code>np.float_ | npt.NDArray[np.float_]</code> </p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul> See Also <ul> <li><code>theoretical.l_moment_from_ppf</code>:   population L-moment, using the inverse CDF</li> <li><code>l_moment</code>: sample L-moment</li> </ul>"},{"location":"api/#lmo.theoretical.l_moment_from_ppf","title":"<code>lmo.theoretical.l_moment_from_ppf(ppf, r, /, trim=(0, 0), *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<p>Evaluate the population L-moment of a univariate probability distribution, using its Percentile Function (PPF) \\(x(F)\\), also commonly known as the quantile function, which is the inverse of the Cumulative Distribution Function (CDF).</p> \\[ \\lambda^{(s, t)}_r = c^{(s,t)}_r \\int_0^1     F^s (1 - F)^t     \\,\\tilde{P}^{(t, s)}_{r-1}(F)     \\,x(F)     \\,\\mathrm{d} F \\;, \\] <p>where</p> \\[ c^{(s,t)}_r = \\frac{r+s+t}{r} \\frac{B(r,\\,r+s+t)}{B(r+s,\\,r+t)} \\;, \\] <p>and \\(\\tilde{P}^{(a,b)}_n(x)\\) the shifted (\\(x \\mapsto 2x-1\\)) Jacobi polynomial.</p> Notes <p>Numerical integration is performed with <code>scipy.integrate.quad</code>, which cannot verify whether the integral exists and is finite. If it returns an error message, an <code>IntegrationWarning</code> is issues, and <code>nan</code> is returned (even if <code>quad</code> returned a finite result).</p> <p>Examples:</p> <p>Evaluate the first 4 L- and TL-moments of the standard normal distribution:</p> <pre><code>&gt;&gt;&gt; from scipy.special import ndtri  # standard normal inverse CDF\n&gt;&gt;&gt; l_moment_from_ppf(ndtri, [1, 2, 3, 4])\narray([0.        , 0.56418958, 0.        , 0.06917061])\n&gt;&gt;&gt; l_moment_from_ppf(ndtri, [1, 2, 3, 4], trim=1)\narray([0.        , 0.29701138, 0.        , 0.01855727])\n</code></pre> PARAMETER  DESCRIPTION <code>ppf</code> <p>The quantile function \\(x(F)\\), a monotonically continuous increasing function with signature <code>(float) -&gt; float</code>, that maps a probability in \\([0, 1]\\), to the domain of the distribution.</p> <p> TYPE: <code>UnivariatePPF</code> </p> <code>r</code> <p>L-moment order(s), non-negative integer or array-like of integers. E.g. 0 gives 1, 1 the L-location, 2 the L-scale, etc.</p> <p> TYPE: <code>AnyInt | IntVector</code> </p> <code>trim</code> <p>Left- and right- trim, either as a \\((s, t)\\) tuple with \\(s, t &gt; -1/2\\), or \\(t\\) as alias for \\((t, t)\\).</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>support</code> <p>Integration limits. Defaults to (0, 1), as it should. There is no need to change this to anything else, and only exists to make the function signature consistent with the <code>*_from_cdf</code> analogue.</p> <p> TYPE: <code>Pair[float]</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> <code>alpha</code> <p>Split the integral into integrals with limits \\([0, \\alpha]\\), \\([\\alpha, 1-\\alpha]\\) and \\([1-\\alpha, 0]\\) to improve numerical stability. So \\(\\alpha\\) can be consideresd the size of the tail. Numerical experiments have found 0.1 to give good results for different distributions.</p> <p> TYPE: <code>float</code> </p> RAISES DESCRIPTION <code>TypeError</code> <p>Invalid <code>r</code> or <code>trim</code> types.</p> <code>ValueError</code> <p>Invalid <code>r</code> or <code>trim</code> values.</p> RETURNS DESCRIPTION <code>lmbda</code> <p>The population L-moment(s), a scalar or float array like <code>r</code>. If <code>nan</code>, consult the related <code>IntegrationWarning</code> message.</p> <p> TYPE: <code>np.float_ | npt.NDArray[np.float_]</code> </p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul> See Also <ul> <li><code>theoretical.l_moment_from_cdf</code>:   population L-moment, using the CDF (i.e. the inverse PPF)</li> <li><code>l_moment</code>: sample L-moment</li> </ul>"},{"location":"api/#lmo.theoretical.l_ratio_from_cdf","title":"<code>lmo.theoretical.l_ratio_from_cdf(cdf, r, s, /, trim=(0, 0), *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<p>Population L-ratio's from a CDF.</p> See Also <ul> <li><code>l_ratio_from_ppf</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/#lmo.theoretical.l_ratio_from_ppf","title":"<code>lmo.theoretical.l_ratio_from_ppf(ppf, r, s, /, trim=(0, 0), *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<p>Population L-ratio's from a PPF.</p> See Also <ul> <li><code>l_ratio_from_cdf</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/#lmo.theoretical.l_stats_from_cdf","title":"<code>lmo.theoretical.l_stats_from_cdf(cdf, num=4, /, trim=(0, 0), *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<p>Calculates the theoretical- / population- L-moments (for \\(r \\le 2\\)) and L-ratio's (for \\(r &gt; 2\\)) of a distribution, from its CDF.</p> <p>By default, the first <code>num = 4</code> population L-stats are calculated:</p> <ul> <li>\\(\\lambda^{(s,t)}_1\\) - L-location</li> <li>\\(\\lambda^{(s,t)}_2\\) - L-scale</li> <li>\\(\\tau^{(s,t)}_3\\) - L-skewness coefficient</li> <li>\\(\\tau^{(s,t)}_4\\) - L-kurtosis coefficient</li> </ul> <p>This function is equivalent to <code>l_ratio_from_cdf(cdf, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code>.</p> Note <p>This should not be confused with the term L-statistic, which is sometimes used to describe any linear combination of order statistics.</p> See Also <ul> <li><code>l_stats_from_ppf</code> - Population     L-stats from the quantile function.</li> <li><code>l_ratio_from_cdf</code> - Generalized     population L-ratio's from the CDF.</li> <li><code>lmo.l_stats</code> - Unbiased sample estimation of L-stats.</li> </ul>"},{"location":"api/#lmo.theoretical.l_stats_from_ppf","title":"<code>lmo.theoretical.l_stats_from_ppf(ppf, num=4, /, trim=(0, 0), *, support=(0, 1), quad_opts=None, alpha=ALPHA)</code>","text":"<p>Calculates the theoretical- / population- L-moments (for \\(r \\le 2\\)) and L-ratio's (for \\(r &gt; 2\\)) of a distribution, from its quantile function.</p> <p>By default, the first <code>num = 4</code> population L-stats are calculated:</p> <ul> <li>\\(\\lambda^{(s,t)}_1\\) - L-location</li> <li>\\(\\lambda^{(s,t)}_2\\) - L-scale</li> <li>\\(\\tau^{(s,t)}_3\\) - L-skewness coefficient</li> <li>\\(\\tau^{(s,t)}_4\\) - L-kurtosis coefficient</li> </ul> <p>This function is equivalent to <code>l_ratio_from_cdf(cdf, [1, 2, 3, 4], [0, 0, 2, 2], *, **)</code>.</p> Note <p>This should not be confused with the term L-statistic, which is sometimes used to describe any linear combination of order statistics.</p> See Also <ul> <li><code>l_stats_from_cdf</code> - Population     L-stats from the CDF.</li> <li><code>l_ratio_from_ppf</code> - Generalized     population L-ratio's from the quantile function.</li> <li><code>lmo.l_stats</code> - Unbiased sample estimation of L-stats.</li> </ul>"},{"location":"api/#lmo.theoretical.l_moment_cov_from_cdf","title":"<code>lmo.theoretical.l_moment_cov_from_cdf(cdf, r_max, /, trim=(0, 0), *, support=None, quad_opts=None)</code>","text":"<p>L-moments that are estimated from \\(n\\) samples of a distribution with CDF \\(F\\), converge to the multivariate normal distribution as the sample size \\(n \\rightarrow \\infty\\).</p> \\[ \\sqrt{n} \\left(     \\vec{l}^{(s, t)} - \\vec{\\lambda}^{(s, t)} \\right) \\sim \\mathcal{N}(     \\vec{0},     \\mathbf{\\Lambda}^{(s, t)} ) \\] <p>Here, \\(\\vec{l}^{(s, t)} = \\left[l^{(s, t)}_r, \\dots, l^{(s, t)}_{r_{max}} \\right]^T\\) is a vector of estimated sample L-moments, and \\(\\vec{\\lambda}^{(s, t)}\\) its theoretical (\"true\") counterpart.</p> <p>This function calculates the covariance matrix</p> \\[ \\begin{align} \\bf{\\Lambda}^{(s,t)}_{k, r}     &amp;= \\mathrm{Cov}[l^{(s, t)}_k, l^{(s, t)}_r] \\\\     &amp;= c_k c_r     \\iint\\limits_{x &lt; y} \\Big[         p_k\\big(F(x)\\big) \\, p_r\\big(F(y)\\big) +         p_r\\big(F(x)\\big) \\, p_k\\big(F(y)\\big)     \\Big]     w^{(s+1,\\, t)}\\big(F(x)\\big) \\,     w^{(s,\\, t+1)}\\big(F(y)\\big) \\,     \\mathrm{d}x \\, \\mathrm{d}y     \\;, \\end{align} \\] <p>where</p> \\[ c_n = \\frac{\\Gamma(n) \\Gamma(n+s+t+1)}{n \\Gamma(n+s) \\Gamma(n+t)}\\;, \\] <p>the shifted Jacobi polynomial \\(p_n(u) = P^{(t, s)}_{n-1}(2u - 1)\\), \\(P^{(t, s)}_m\\), and \\(w^{(s,t)}(u) = u^s (1-u)^t\\) its weight function.</p> Notes <p>This function uses <code>scipy.integrate.nquad</code> for numerical integration. Unexpected results may be returned if the integral does not exist, or does not converge. The results are rounded to match the order of magnitude of the absolute error of <code>scipy.integrate.nquad</code>.</p> <p>This function is not vectorized or parallelized.</p> <p>For small sample sizes (\\(n &lt; 100\\)), the covariances of the higher-order L-moments (\\(r &gt; 2\\)) can be biased. But this bias quickly disappears at roughly \\(n &gt; 200\\) (depending on the trim- and L-moment orders).</p> PARAMETER  DESCRIPTION <code>cdf</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> <p> TYPE: <code>UnivariateCDF</code> </p> <code>r_max</code> <p>The amount of L-moment orders to consider. If for example <code>r_max = 4</code>, the covariance matrix will be of shape <code>(4, 4)</code>, and the columns and rows correspond to the L-moments of order \\(r = 1, \\dots, r_{max}\\).</p> <p> TYPE: <code>int</code> </p> <code>trim</code> <p>Left- and right- trim. Must be a tuple of two non-negative ints or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>. Generally it's not needed to provide this, as it will be guessed automatically.</p> <p> TYPE: <code>Pair[float] | None</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> RETURNS DESCRIPTION <code>cov</code> <p>Covariance matrix, with shape <code>(r_max, r_max)</code>.</p> <p> TYPE: <code>npt.NDArray[np.float_]</code> </p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If the covariance matrix is invalid.</p> See Also <ul> <li><code>l_moment_from_cdf</code> -     Population L-moments from the cumulative distribution function</li> <li><code>l_moment_from_ppf</code> -     Population L-moments from the quantile function</li> <li><code>lmo.l_moment</code> - Unbiased L-moment estimation from     samples</li> <li><code>lmo.l_moment_cov</code> - Distribution-free exact     L-moment exact covariance estimate.</li> </ul> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/#lmo.theoretical.l_stats_cov_from_cdf","title":"<code>lmo.theoretical.l_stats_cov_from_cdf(cdf, num=4, /, trim=(0, 0), *, support=None, quad_opts=None, alpha=ALPHA, ppf=None)</code>","text":"<p>Similar to <code>l_moment_from_cdf</code>, but for the <code>lmo.l_stats</code>.</p> <p>As the sample size \\(n \\rightarrow \\infty\\), the L-moment ratio's are also distributed (multivariate) normally. The L-stats are defined to be L-moments for \\(r\\le 2\\), and L-ratio coefficients otherwise.</p> <p>The corresponding covariance matrix has been found to be</p> \\[ \\bf{T}^{(s, t)}_{k, r} = \\begin{cases}     \\bf{\\Lambda}^{(s, t)}_{k, r}         &amp; k \\le 2 \\wedge r \\le 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}     }{         \\lambda^{(s,t)}_{2}     }         &amp; k \\le 2 \\wedge r &gt; 2 \\\\     \\frac{         \\bf{\\Lambda}^{(s, t)}_{k, r}         - \\tau_k \\bf{\\Lambda}^{(s, t)}_{2, r}         - \\tau_r \\bf{\\Lambda}^{(s, t)}_{k, 2}         + \\tau_k \\tau_r \\bf{\\Lambda}^{(s, t)}_{2, 2}     }{         \\Big( \\lambda^{(s,t)}_{2} \\Big)^2     }         &amp; k &gt; 2 \\wedge r &gt; 2 \\end{cases} \\] <p>where \\(\\bf{\\Lambda}^{(s, t)}\\) is the covariance matrix of the L-moments from <code>l_moment_cov_from_cdf</code>, and \\(\\tau^{(s,t)}_r = \\lambda^{(s,t)}_r / \\lambda^{(s,t)}_2\\) the population L-ratio.</p> PARAMETER  DESCRIPTION <code>cdf</code> <p>Cumulative Distribution Function (CDF), \\(F_X(x) = P(X \\le x)\\). Must be a continuous monotone increasing function with signature <code>(float) -&gt; float</code>, whose return value lies in \\([0, 1]\\).</p> <p> TYPE: <code>UnivariateCDF</code> </p> <code>num</code> <p>The amount of L-statistics to return. Defaults to 4.</p> <p> TYPE: <code>int</code> DEFAULT: <code>4</code> </p> <code>trim</code> <p>Left- and right- trim. Must be a tuple of two non-negative ints or floats.</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>. Generally it's not needed to provide this, as it will be guessed automatically.</p> <p> TYPE: <code>Pair[float] | None</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> <code>alpha</code> <p>Two-sided quantile to split the integral at.</p> <p> TYPE: <code>float</code> </p> <code>ppf</code> <p>Quantile function, for calculating the split integral limits.</p> <p> TYPE: <code>UnivariatePPF | None</code> </p> References <ul> <li>J.R.M. Hosking (1990) - L-moments: Analysis and Estimation of     Distributions Using Linear Combinations of Order Statistics     </li> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/#lmo.theoretical.l_moment_influence_from_cdf","title":"<code>lmo.theoretical.l_moment_influence_from_cdf(cdf, r, /, trim=(0, 0), *, support=None, l_moment=None, quad_opts=None, alpha=ALPHA, tol=1e-08)</code>","text":"<p>Influence Function (IF) of a theoretical L-moment.</p> \\[ \\psi_{\\lambda^{(s, t)}_r | F}(x)     = c^{(s,t)}_r     \\, F(x)^s     \\, \\big( 1-{F}(x) \\big)^t     \\, \\tilde{P}^{(s,t)}_{r-1} \\big( F(x) \\big)     \\, x     - \\lambda^{(s,t)}_r     \\;, \\] <p>with \\(F\\) the CDF, \\(\\tilde{P}^{(s,t)}_{r-1}\\) the shifted Jacobi polynomial, and</p> \\[ c^{(s,t)}_r     = \\frac{r+s+t}{r} \\frac{B(r, \\, r+s+t)}{B(r+s, \\, r+t)}     \\;, \\] <p>where \\(B\\) is the (complete) Beta function.</p> <p>The proof is trivial, because population L-moments are linear functionals.</p> Notes <p>The order parameter <code>r</code> is not vectorized.</p> PARAMETER  DESCRIPTION <code>cdf</code> <p>Vectorized cumulative distribution function (CDF).</p> <p> TYPE: <code>Callable[[npt.NDArray[np.float_]], npt.NDArray[np.float_]]</code> </p> <code>r</code> <p>The L-moment order. Must be a non-negative integer.</p> <p> TYPE: <code>AnyInt</code> </p> <code>trim</code> <p>Left- and right- trim lengths. Defaults to (0, 0).</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>.</p> <p> TYPE: <code>Pair[float] | None</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> <code>l_moment</code> <p>The relevant L-moment to use. If not provided, it is calculated from the CDF.</p> <p> TYPE: <code>float | np.float_ | None</code> </p> <code>alpha</code> <p>Two-sided quantile to split the integral at.</p> <p> TYPE: <code>float</code> </p> <code>tol</code> <p>Zero-roundoff absolute threshold.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>influence_function</code> <p>The influence function, with vectorized signature <code>() -&gt; ()</code>.</p> <p> TYPE: <code>Callable[[V], V]</code> </p> See Also <ul> <li><code>l_moment_from_cdf</code></li> <li><code>lmo.l_moment</code></li> </ul>"},{"location":"api/#lmo.theoretical.l_ratio_influence_from_cdf","title":"<code>lmo.theoretical.l_ratio_influence_from_cdf(cdf, r, k=2, /, trim=(0, 0), *, support=None, l_moments=None, quad_opts=None, alpha=ALPHA, tol=1e-08)</code>","text":"<p>Construct the influence function of a theoretical L-moment ratio.</p> \\[ \\psi_{\\tau^{(s, t)}_{r,k}|F}(x) = \\frac{     \\psi_{\\lambda^{(s, t)}_r|F}(x)     - \\tau^{(s, t)}_{r,k} \\, \\psi_{\\lambda^{(s, t)}_k|F}(x) }{     \\lambda^{(s,t)}_k } \\;, \\] <p>where the generalized L-moment ratio is defined as</p> \\[ \\tau^{(s, t)}_{r,k} = \\frac{     \\lambda^{(s, t)}_r }{     \\lambda^{(s, t)}_k } \\;. \\] <p>Because IF's are a special case of the general G\u00e2teuax derivative, the L-ratio IF is derived by applying the chain rule to the L-moment IF.</p> PARAMETER  DESCRIPTION <code>cdf</code> <p>Vectorized cumulative distribution function (CDF).</p> <p> TYPE: <code>Callable[[npt.NDArray[np.float_]], npt.NDArray[np.float_]]</code> </p> <code>r</code> <p>L-moment ratio order, i.e. the order of the numerator L-moment.</p> <p> TYPE: <code>AnyInt</code> </p> <code>k</code> <p>Denominator L-moment order, defaults to 2.</p> <p> TYPE: <code>AnyInt</code> DEFAULT: <code>2</code> </p> <code>trim</code> <p>Left- and right- trim lengths. Defaults to (0, 0).</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>support</code> <p>The subinterval of the nonzero domain of <code>cdf</code>.</p> <p> TYPE: <code>Pair[float] | None</code> </p> <code>l_moments</code> <p>The L-moments corresponding to \\(r\\) and \\(k\\). If not provided, they are calculated from the CDF.</p> <p> TYPE: <code>Pair[float] | Pair[np.float_] | None</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> <code>alpha</code> <p>Two-sided quantile to split the integral at.</p> <p> TYPE: <code>float</code> </p> <code>tol</code> <p>Zero-roundoff absolute threshold.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>influence_function</code> <p>The influence function, with vectorized signature <code>() -&gt; ()</code>.</p> <p> TYPE: <code>Callable[[V], V]</code> </p> See Also <ul> <li><code>l_ratio_from_cdf</code></li> <li><code>lmo.l_ratio</code></li> </ul>"},{"location":"api/#lmo.theoretical.l_comoment_from_pdf","title":"<code>lmo.theoretical.l_comoment_from_pdf(pdf, cdfs, r, /, trim=(0, 0), *, supports=None, quad_opts=None)</code>","text":"<p>Evaluate the theoretical L-comoment matrix of a multivariate probability distribution, using the joint PDF \\(f_{\\vec{X}}(\\vec{x})\\) and \\(n\\) marginal CDFs \\(F_X(x)\\) of random vector \\(\\vec{X}\\).</p> <p>The L-comoment matrix is defined as</p> \\[ \\Lambda_{r}^{(s, t)} =     \\left[         \\lambda_{r [ij]}^{(s, t)}     \\right]_{n \\times n} \\;, \\] <p>with elements</p> \\[ \\begin{align} \\lambda_{r [ij]}^{(s, t)}     &amp;= c^{(s,t)}_r \\int_{\\mathbb{R^n}}         x_i         \\,F_j(x_j)^s \\,\\bar{F}_j(x_j)^t         \\,\\tilde{P}^{(s, t)}_r \\big(F_j(x_j) \\big)         \\,f(\\vec{x})         \\, d \\vec{x} \\\\     &amp;= c^{(s,t)}_r \\, \\mathbb{E}_{\\vec{X}} \\left[         X_i         \\,F_j(X_j)^s \\,\\bar{F}_j(X_j)^t         \\,\\tilde{P}^{(s, t)}_r \\big(F_j(X_j) \\big)         \\,f(\\vec{X})     \\right]     \\;, \\end{align} \\] <p>with vector \\(\\vec{x} = \\begin{bmatrix} x_1 &amp; \\cdots &amp; x_n \\end{bmatrix}^T\\), \\(f\\) the joint PDF, \\(F_i\\) the marginal CDF of \\(X_i\\) and \\(\\bar{F}_i\\) its complement (the Survival Function), \\(\\tilde{P}^{(s, t)}_n\\) the shifted Jacobi polynomial, and</p> \\[ c^{(s,t)}_r = \\frac{r+s+t}{r} \\frac{B(r,\\,r+s+t)}{B(r+s,\\,r+t)} \\;, \\] <p>a positive constant.</p> <p>For \\(r \\ge 2\\), it can also be expressed as</p> \\[ \\lambda_{r [ij]}^{(s, t)}     = c^{(s,t)}_r \\mathrm{Cov} \\left[         X_i ,\\;         F_j(X_j)^s         \\,\\bar{F}_j(X_j)^t         \\,\\tilde{P}^{(s, t)}_r \\big(F_j(X_j) \\big)         \\,f(\\vec{X})     \\right]     \\;, \\] <p>and without trim (\\(s = t = 0\\)), this simplifies to</p> \\[ \\lambda_{r [ij]}     = \\mathrm{Cov} \\left[         X_i ,\\;         \\,\\tilde{P}_r \\big(F_j(X_j) \\big)         \\,f(\\vec{X})     \\right]     \\;, \\] <p>with \\(\\tilde{P}_n\\) the shifted Legendre polynomial. This last form is precisely the definition introduced by Serfling &amp; Xiao (2007).</p> <p>Note that the L-comoments along the diagonal, are equivalent to the (univariate) L-moments, i.e.</p> \\[ \\lambda_{r [ii]}^{(s, t)}\\big( \\vec{X} \\big) = \\lambda_{r}^{(s, t)}\\big( X_i \\big) \\;. \\] Notes <p>At the time of writing, trimmed L-comoments have not been explicitly defined in the literature. Instead, the author (@jorenham) derived it by generizing the (untrimmed) L-comoment definition by Serfling &amp; Xiao (2007), analogous to the generalization of L-moments into TL-moments by Elamir &amp; Seheult (2003).</p> <p>Examples:</p> <p>Find the L-coscale and TL-coscale matrices of the multivariate Student's t distribution with 4 degrees of freedom:</p> <pre><code>&gt;&gt;&gt; from lmo.theoretical import l_comoment_from_pdf\n&gt;&gt;&gt; from scipy.stats import multivariate_t, t\n&gt;&gt;&gt; df = 4\n&gt;&gt;&gt; loc = np.array([0.5, -0.2])\n&gt;&gt;&gt; cov = np.array([[2.0, 0.3], [0.3, 0.5]])\n&gt;&gt;&gt; X = multivariate_t(loc, cov, df)\n&gt;&gt;&gt; cdfs = [t(df, loc[i], np.sqrt(cov[i, i])).cdf for i in range(2)]\n&gt;&gt;&gt; l_cov = l_comoment_from_pdf(X.pdf, cdfs, 2)\n&gt;&gt;&gt; l_cov.round(4)\narray([[1.0413, 0.3124],\n       [0.1562, 0.5207]])\n&gt;&gt;&gt; tl_cov = l_comoment_from_pdf(X.pdf, cdfs, 2, trim=1)\n&gt;&gt;&gt; tl_cov.round(4)\narray([[0.4893, 0.1468],\n       [0.0734, 0.2447]])\n</code></pre> <p>The correlation coefficient can be recovered in several ways:</p> <pre><code>&gt;&gt;&gt; cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])  # \"true\" correlation\n0.3\n&gt;&gt;&gt; np.round(l_cov[0, 1] / l_cov[0, 0], 4)\n0.3\n&gt;&gt;&gt; np.round(l_cov[1, 0] / l_cov[1, 1], 4)\n0.3\n&gt;&gt;&gt; np.round(tl_cov[0, 1] / tl_cov[0, 0], 4)\n0.3\n&gt;&gt;&gt; np.round(tl_cov[1, 0] / tl_cov[1, 1], 4)\n0.3\n</code></pre> PARAMETER  DESCRIPTION <code>pdf</code> <p>Joint Probability Distribution Function (PDF), that accepts a float vector of size \\(n\\), and returns a scalar in \\([0, 1]\\).</p> <p> TYPE: <code>Callable[[npt.NDArray[np.float_]], float]</code> </p> <code>cdfs</code> <p>Sequence with \\(n\\) marginal CDF's.</p> <p> TYPE: <code>Sequence[Callable[[float], float]]</code> </p> <code>r</code> <p>Non-negative integer \\(r\\) with the L-moment order.</p> <p> TYPE: <code>AnyInt</code> </p> <code>trim</code> <p>Left- and right- trim, either as a \\((s, t)\\) tuple with \\(s, t &gt; -1/2\\), or \\(t\\) as alias for \\((t, t)\\).</p> <p> TYPE: <code>AnyTrim</code> DEFAULT: <code>(0, 0)</code> </p> PARAMETER DESCRIPTION <code>supports</code> <p>A sequence with \\(n\\) 2-tuples, corresponding to the marginal integration limits. Defaults to \\([(-\\infty, \\infty), \\dots]\\).</p> <p> TYPE: <code>Sequence[Pair[float]] | None</code> </p> <code>quad_opts</code> <p>Optional dict of options to pass to <code>scipy.integrate.quad</code>.</p> <p> TYPE: <code>QuadOptions | None</code> </p> RETURNS DESCRIPTION <code>lmbda</code> <p>The population L-comoment matrix with shape \\(n \\times n\\).</p> <p> TYPE: <code>npt.NDArray[np.float_]</code> </p> References <ul> <li>E. Elamir &amp; A. Seheult (2003) - Trimmed L-moments</li> <li>R. Serfling &amp; P. Xiao (2007) - A Contribution to Multivariate   L-Moments: L-Comoment   Matrices</li> </ul>"},{"location":"api/#lmo.theoretical.l_coratio_from_pdf","title":"<code>lmo.theoretical.l_coratio_from_pdf(pdf, cdfs, r, r0=2, /, trim=(0, 0), *, supports=None, quad_opts=None)</code>","text":"<p>Evaluate the theoretical L-comoment ratio matrix of a multivariate probability distribution, using the joint PDF \\(f_{\\vec{X}}(\\vec{x})\\) and \\(n\\) marginal CDFs \\(F_X(x)\\) of random vector \\(\\vec{X}\\).</p> \\[ \\tilde \\Lambda_{r,r_0}^{(s, t)} =     \\left[         \\left. \\lambda_{r [ij]}^{(s, t)} \\right/         \\lambda_{r_0 [ii]}^{(s, t)}     \\right]_{n \\times n} \\] See Also <ul> <li><code>l_comoment_from_pdf</code></li> <li><code>lmo.l_coratio</code></li> </ul>"},{"location":"api/#linalg","title":"<code>linalg</code>","text":"<p>Linear algebra and linearized orthogonal polynomials.</p>"},{"location":"api/#lmo.linalg.sandwich","title":"<code>lmo.linalg.sandwich(A, X, /, dtype=np.float_)</code>","text":"<p>Calculates the \"sandwich\" matrix product (<code>A @ X @ A.T</code>) along the specified <code>X</code> axis.</p> PARAMETER  DESCRIPTION <code>A</code> <p>2-D array of shape <code>(s, r)</code>, the \"bread\".</p> <p> TYPE: <code>npt.NDArray[np.number[Any]]</code> </p> <code>dtype</code> <p>The data type of the result.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>X</code> <p>Array of shape <code>(r, r, ...)</code>.</p> <p> TYPE: <code>npt.NDArray[T | np.number[Any]]</code> </p> RETURNS DESCRIPTION <code>C</code> <p>Array of shape <code>(s, s, ...)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> See Also <ul> <li>https://wikipedia.org/wiki/Covariance_matrix</li> </ul>"},{"location":"api/#lmo.linalg.pascal","title":"<code>lmo.linalg.pascal(k, /, dtype=np.int_, *, inv=False)</code>","text":"<p>Construct the lower-diagonal Pascal matrix \\(L_{k \\times k\\)}$, or its matrix inverse \\(L^{-1}\\).</p> \\[ \\begin{align} L_{ij} &amp;= \\binom{i}{j} \\\\ L^{-1}_{ij} &amp;= (-1)^{i - j} L_{ij} \\end{align} \\] <p>Implemented using recursion, unlike the slow naive implementation from the equivalent <code>scipy.linalg.pascal</code> and <code>scipy.linalg.invpascal</code> functions using <code>kind='lower'</code>. By using the binomial recurrence relation, assuming \\(0 &lt; j &lt; i\\), \\(\\binom{i}{j} = \\frac{i}{j} \\binom{i-1}{j-1}\\), the following recursive definition is obtained:</p> \\[ L_{ij} = \\begin{cases}     0 &amp; \\text{if } i &lt; j \\text{,} \\\\     1 &amp; \\text{if } i = j \\vee j = 0 \\text{, and} \\\\     (i \\, L_{i-1,\\, j-1}) / j &amp; \\text{otherwise.} \\end{cases} \\] <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from lmo.linalg import pascal\n&gt;&gt;&gt; pascal(4)\narray([[1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 2, 1, 0],\n       [1, 3, 3, 1]])\n&gt;&gt;&gt; pascal(4, inv=True)\narray([[ 1,  0,  0,  0],\n       [-1,  1,  0,  0],\n       [ 1, -2,  1,  0],\n       [-1,  3, -3,  1]])\n&gt;&gt;&gt; np.rint(np.linalg.inv(pascal(4))).astype(np.int_)\narray([[ 1,  0,  0,  0],\n       [-1,  1,  0,  0],\n       [ 1, -2,  1,  0],\n       [-1,  3, -3,  1]])\n</code></pre> <p>Now, let's compare with scipy:</p> <pre><code>&gt;&gt;&gt; from scipy.linalg import invpascal\n&gt;&gt;&gt; invpascal(4, kind='lower')\narray([[ 1,  0,  0,  0],\n       [-1,  1,  0,  0],\n       [ 1, -2,  1,  0],\n       [-1,  3, -3,  1]])\n</code></pre>"},{"location":"api/#lmo.linalg.ir_pascal","title":"<code>lmo.linalg.ir_pascal(k, /, dtype=np.float_)</code>","text":"<p>Inverse regulatized lower-diagonal Pascal matrix, \\(\\bar{L}_{ij} = L^{-1}_ij / i\\).</p> <p>Used to linearly combine order statistics order statistics into L-moments.</p>"},{"location":"api/#lmo.linalg.sh_legendre","title":"<code>lmo.linalg.sh_legendre(k, /, dtype=np.int_)</code>","text":"<p>Shifted Legendre polynomial coefficient matrix \\(\\widetilde{P}\\) of shape <code>(k, k)</code>.</p> <p>The \\(j\\)-th coefficient of the shifted Legendre polynomial of degree \\(k\\) is at \\((k, j)\\):</p> \\[ \\widetilde{p}_{k, j} = (-1)^{k - j} \\binom{k}{j} \\binom{k + j}{j} \\] <p>Useful for transforming probability-weighted moments into L-moments.</p> PARAMETER  DESCRIPTION <code>k</code> <p>The size of the matrix, and the max degree of the shifted Legendre polynomial.</p> <p> TYPE: <code>int</code> </p> <code>dtype</code> <p>Desired output data type, e.g, <code>numpy.float64</code>. Default is <code>numpy.int64</code>.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.int_</code> </p> RETURNS DESCRIPTION <code>P</code> <p>2-D array of the lower-triangular square matrix of size \\(k^2\\)`.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <p>Calculate \\(\\widetilde{P}_{4 \\times 4}\\):</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import sh_legendre\n&gt;&gt;&gt; sh_legendre(4)\narray([[  1,   0,   0,   0],\n       [ -1,   2,   0,   0],\n       [  1,  -6,   6,   0],\n       [ -1,  12, -30,  20]])\n</code></pre> See Also <ul> <li>https://wikipedia.org/wiki/Legendre_polynomials</li> <li>https://wikipedia.org/wiki/Pascal_matrix</li> </ul>"},{"location":"api/#lmo.linalg.sh_jacobi","title":"<code>lmo.linalg.sh_jacobi(k, a, b, /, dtype=None)</code>","text":"<p>Shifted Jacobi polynomial coefficient matrix \\(\\widetilde{P}^{(a,b)}\\) of shape <code>(k, k)</code>.</p> <p>The \\(j\\)-th coefficient of the shifted Jacobi polynomial of degree \\(k\\) is at \\((k, j)\\):</p> <p>The \"shift\" refers to the change of variables \\(x \\mapsto 2x - 1\\) in the (unshifted) Jacobi (or hypergeometric) polynomials.</p> <p>The (shifted) Jacobi polynomials \\(\\widetilde{P}^{(a,b)}\\) generalize  the (shifted) Legendre polynomials \\(\\widetilde{P}\\): \\(\\widetilde{P}^{(0, 0)} = \\widetilde{P}\\)</p> PARAMETER  DESCRIPTION <code>k</code> <p>The size of the matrix, and the max degree of the polynomial.</p> <p> TYPE: <code>AnyInt</code> </p> <code>a</code> <p>The \\(\\alpha\\) parameter, must be \\(\\ge 0\\).</p> <p> TYPE: <code>AnyFloat</code> </p> <code>b</code> <p>The \\(\\beta\\) parameter, must be \\(\\ge 0\\).</p> <p> TYPE: <code>AnyFloat</code> </p> <code>dtype</code> <p>Desired output data type, e.g, <code>numpy.float64</code>. Default is <code>numpy.int64</code> if <code>a</code> and <code>b</code> are integers, otherwise <code>np.float64</code>.</p> <p> TYPE: <code>np.dtype[T] | type[T] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>P</code> <p>2-D array of the lower-triangular square matrix of size \\(k^2\\)`.</p> <p> TYPE: <code>npt.NDArray[T | np.int_]</code> </p> <p>Examples:</p> <p>Calculate \\(\\widetilde{P}^{(1, 1)}_{4 \\times 4}\\):</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import sh_jacobi\n&gt;&gt;&gt; sh_jacobi(4, 1, 1)\narray([[  1,   0,   0,   0],\n       [ -2,   4,   0,   0],\n       [  3, -15,  15,   0],\n       [ -4,  36, -84,  56]])\n</code></pre> <p>Let's compare \\(\\widetilde{P}^(1, \\pi)_3\\) with the scipy Jacobi poly1d. This requires manual shifting \\(x \\mapsto f(x)\\), with \\(f(x) = 2x - 1\\):</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scipy.special as sc\n&gt;&gt;&gt; f_x = np.poly1d([2, -1])  # f(x) = 2*x + 1\n&gt;&gt;&gt; sc.jacobi(3, 1, np.pi)(f_x)\npoly1d([ 125.80159497, -228.55053774,  128.54584648,  -21.79690371])\n&gt;&gt;&gt; sh_jacobi(4, 1, np.pi)[3]\narray([ -21.79690371,  128.54584648, -228.55053774,  125.80159497])\n</code></pre> <p>Apart from the reversed coefficients of <code>numpy.poly1d</code> (an awkward design choice, but it's fixed in the new <code>numpy.polynomial</code> module.)</p> See Also <ul> <li>https://mathworld.wolfram.com/JacobiPolynomial.html</li> <li><code>scipy.special.jacobi</code></li> </ul>"},{"location":"api/#lmo.linalg.succession_matrix","title":"<code>lmo.linalg.succession_matrix(c)</code>","text":"<p>A toeplitz-like transformation matrix construction, that prepends \\(i\\) zeroes to \\(i\\)-th row, so that the input shape is mapped from <code>(n, k)</code> to <code>(n, k + n)</code>.</p> <p>So all values \\(i &gt; j \\vee i + j \\ge k\\) are zero in the succession matrix.</p> PARAMETER  DESCRIPTION <code>c</code> <p>Dense matrix of shape <code>(n, k)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> RETURNS DESCRIPTION <code>S</code> <p>Matrix of shape <code>(n, k + n)</code></p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import succession_matrix\n&gt;&gt;&gt; succession_matrix(np.arange(1, 9).reshape(4, 2))\narray([[1, 2, 0, 0, 0],\n       [0, 3, 4, 0, 0],\n       [0, 0, 5, 6, 0],\n       [0, 0, 0, 7, 8]])\n</code></pre>"},{"location":"api/#lmo.linalg.trim_matrix","title":"<code>lmo.linalg.trim_matrix(r, /, trim, dtype=np.float_)</code>","text":"<p>Linearization of the trimmed L-moment recurrence relations, following the (corrected) derivation by Hosking (2007) from the (shifted) Jacobi Polynomials.</p> <p>This constructs a \\(r \\times r + t_1 + t_2\\) matrix \\(T^{(t_1, t_2)}\\) that \"trims\" conventional L-moments. E.g. the first 3 \\((1, 1)\\) trimmed L-moments can be obtained from the first \\(3+1+1=5\\) (untrimmed) L-moments (assuming they exist) with <code>trim_matrix(3, (1, 1)) @ l_moment(x, np.ogrid[:5] + 1)</code>.</p> <p>The big \"L\" in \"L-moment\", referring to it being a Linear combination of order statistics, has been prominently put in the name by Hosking (1990) for a good reason. It means that transforming order statistics to a bunch of L-moments, can be done using a single matrix multiplication (see <code>lmo.linalg.sh_legendre</code>). By exploiting liniarity, it can easily be chained with this trim matrix, to obtain a reusable order-statistics -&gt; trimmed L-moments transformation (matrix).</p> <p>Note that these linear transformations can be used in exactly the same way to e.g. calculate several population TL-moments of some random varianble, using nothing but its theoretical probablity-weighted moments (PWMs).</p> PARAMETER  DESCRIPTION <code>r</code> <p>The max (trimmed) L-moment order.</p> <p> TYPE: <code>int</code> </p> <code>trim</code> <p>Left- and right-trim orders \\((t_1, t_2)\\), integers \\(\\ge 0\\). If set to (0, 0), the identity matrix is returned.</p> <p> TYPE: <code>tuple[int, int]</code> </p> <code>dtype</code> <p>Desired output data type, e.g, <code>numpy.float64</code> (default).</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> RETURNS DESCRIPTION <code>npt.NDArray[T]</code> <p>Toeplitz-like matrix of shape \\((r, r + t_1 + t_2)\\).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo.linalg import trim_matrix\n&gt;&gt;&gt; trim_matrix(3, (0, 1))\narray([[ 1.        , -1.        ,  0.        ,  0.        ],\n       [ 0.        ,  0.75      , -0.75      ,  0.        ],\n       [ 0.        ,  0.        ,  0.66666667, -0.66666667]])\n&gt;&gt;&gt; trim_matrix(3, (1, 0))\narray([[1.        , 1.        , 0.        , 0.        ],\n       [0.        , 0.75      , 0.75      , 0.        ],\n       [0.        , 0.        , 0.66666667, 0.66666667]])\n</code></pre> References <ul> <li>J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</li> </ul>"},{"location":"api/#order-statistics","title":"Order statistics","text":"<p>Order statistics \\(X_{i:n}\\), with \\(i \\in [0, n)\\).</p> <p>Primarily used as an intermediate step for L-moment estimation.</p> References <p>H.A. David &amp; H.N. Nagaraja (2004) \u2013 Order statistics </p>"},{"location":"api/#lmo.ostats.weights","title":"<code>lmo.ostats.weights(i, n, N, /, *, cached=False)</code>","text":"<p>Compute the linear weights \\(w_{i:n|j:N}\\) for \\(j = 0, \\dots, N-1\\).</p> <p>The unbiased sample estimator \\(\\mu_{i:n}\\) is then derived from</p> \\[ E[X_{i:n}] = \\sum_{j=0}^{N-1} w_{i:n|j:N} X_{j:N} \\, , \\] <p>where</p> \\[ \\begin{aligned} w_{i:n|j:N} &amp;= \\binom{j}{i} \\binom{N - j - 1}{n - i - 1} / \\binom{N}{n} \\\\ &amp;= \\frac{1}{N - n + 1} \\frac{     B(j + 1, N - j) }{     B(i + 1, n - i) B(j - i + 1, N - j - n + i + 1) } \\end{aligned} \\] <p>Here, \\(B\\) denotes the Beta function, \\(B(a,b) = \\Gamma(a) \\Gamma(b) / \\Gamma(a + b)\\).</p> Notes <p>This function uses \"Python-style\" 0-based indexing for \\(i\\), instead of the conventional 1-based indexing that is generally used in the literature.</p> PARAMETER  DESCRIPTION <code>i</code> <p>0-indexed sample (fractional) index, \\(0 \\le i \\lt n\\). Negative indexing is allowed.</p> <p> TYPE: <code>float</code> </p> <code>n</code> <p>Subsample size, optionally fractional, \\(0 \\le n0\\)</p> <p> TYPE: <code>float</code> </p> <code>N</code> <p>Sample size, i.e. the observation count.</p> <p> TYPE: <code>int</code> </p> <code>cached</code> <p>Cache the result for <code>(i, n, n0)</code>. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>npt.NDArray[np.float_]</code> <p>1d array of size \\(N\\) with (ordered) sample weights.</p>"},{"location":"api/#lmo.ostats.from_cdf","title":"<code>lmo.ostats.from_cdf(F, i, n)</code>","text":"<p>Transform \\(F(X)\\) to \\(F_{i:n}(X)\\), of the \\(i\\)th variate within subsamples of size, i.e. \\(0 \\le i \\le n - 1\\).</p> PARAMETER  DESCRIPTION <code>F</code> <p>Scalar or array-like with the returned value of some cdf, i.e. \\(F_X(x) = P(X \\le x)\\). Must be between 0 and 1.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>i</code> <p>0-indexed sample (fractional) index, \\(0 \\le i &lt; n\\).</p> <p> TYPE: <code>float</code> </p> <code>n</code> <p>Subsample size, optionally fractional, \\(0 \\le n0\\)</p> <p> TYPE: <code>float</code> </p>"},{"location":"api/#pwms","title":"\u03b2 PWMs","text":"<p>Power-Weighted Moment (PWM) \\(\\beta_k = M_{1,k,0}\\).</p> <p>Primarily used as an intermediate step for L-moment estimation.</p>"},{"location":"api/#lmo.pwm_beta.weights","title":"<code>lmo.pwm_beta.weights(r, n, /, dtype=np.float_)</code>","text":"<p>Probability Weighted moment (PWM) projection matrix \\(B\\) of the unbiased estimator for \\(\\beta_k = M_{1,k,0}\\) for \\(k = 0, \\dots, r - 1\\).</p> <p>The PWM's are estimated by linear projection of the sample of order statistics, i.e. \\(b = B x_{i:n}\\)</p> PARAMETER  DESCRIPTION <code>r</code> <p>The amount of orders to evaluate, i.e. \\(k = 0, \\dots, r - 1\\).</p> <p> TYPE: <code>int</code> </p> <code>n</code> <p>Sample count.</p> <p> TYPE: <code>int</code> </p> <code>dtype</code> <p>Desired output floating data type.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> RETURNS DESCRIPTION <code>P_b</code> <p>Upper-triangular projection matrix of shape <code>(r, n)</code>.</p> <p> TYPE: <code>npt.NDArray[T]</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from lmo import pwm_beta\n&gt;&gt;&gt; pwm_beta.weights(4, 5)\narray([[0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n       [0.        , 0.05      , 0.1       , 0.15      , 0.2       ],\n       [0.        , 0.        , 0.03333333, 0.1       , 0.2       ],\n       [0.        , 0.        , 0.        , 0.05      , 0.2       ]])\n</code></pre>"},{"location":"api/#lmo.pwm_beta.cov","title":"<code>lmo.pwm_beta.cov(a, r, /, axis=None, dtype=np.float_, **kwargs)</code>","text":"<p>Distribution-free variance-covariance matrix of the probability weighted moment (PWM) point estimates \\(\\beta_k = M_{1,k,0}\\), with orders \\(k = 0, \\dots, r - 1\\).</p> PARAMETER  DESCRIPTION <code>a</code> <p>Array-like with observations.</p> <p> TYPE: <code>npt.ArrayLike</code> </p> <code>r</code> <p>The amount of orders to evaluate, i.e. \\(k = 0, \\dots, r - 1\\).</p> <p> TYPE: <code>int</code> </p> <code>axis</code> <p>The axis along which to calculate the covariance matrices.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>dtype</code> <p>Desired output floating data type.</p> <p> TYPE: <code>np.dtype[T] | type[T]</code> DEFAULT: <code>np.float_</code> </p> <code>**kwargs</code> <p>Additional keywords to pass to <code>lmo.stats.ordered</code>.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>S_b</code> <p>Variance-covariance matrix/tensor of shape <code>(r, ...)</code></p> <p> TYPE: <code>npt.NDArray[T]</code> </p> See Also <ul> <li>https://wikipedia.org/wiki/Covariance_matrix</li> </ul> References <ul> <li>E. Elmamir &amp; A. Seheult (2004) - Exact variance structure of sample     L-moments</li> </ul>"},{"location":"contributing/","title":"Contributing to Lmo","text":"<p>Any contributions to Lmo are appreciated!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as issues.</p> <p>When reporting a bug, make sure to include the versions of <code>lmo</code>, <code>python</code>,  <code>numpy</code> and <code>scipy</code> you are using, and provide a reproducible example of  the bug.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>Ensure you have poetry  installed, then clone your fork, and install with</p> <pre><code>poetry install --sync\n</code></pre> <p>It can help to use Lmo's lowest-supported Python version, so that you don't accidentally use those bleeding-edge Python features that you shouldn't,  <code>poetry env use python3.x</code></p> <p>Now you can go ahead and do your thing.  And don't forget the type annotations, add tests, and to lint it all. </p> <p>If you're a 10x developer that doesn't wait on CI workflows, you can use the  following 1337 shellscript (keep in mind that the CI runs this on all supported Python versions):</p> <pre><code>poetry run codespell check lmo\npoetry run ruff check lmo\npoetry run pyright\npoetry run py.test\n</code></pre> <p>If your change involves documentation updates, you can conjure up a live  preview:</p> <pre><code>poetry run mkdocs serve\n</code></pre> <p>But don't worry about building the docs, or bumping the version; Lmo's personal assistant will do that on release.</p>"}]}