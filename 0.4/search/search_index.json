{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#lmo","title":"Lmo","text":"<p>Streamlined calculation of L-moments and TL-moments.</p> <p>Lmo is a lightweight library with pythonic syntax. Some features include:</p> <ul> <li>Robust alternatives to conventional moments: even the Cauchy distribution poses no threat!</li> <li>Lightweight; it only requires numpy</li> <li>Clean code style: linted with ruff</li> <li>Fully type-annotated, valid in pyright's strict mode.</li> <li>Hypothesis-tested</li> <li>Red and fluffy</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install lmo\n</code></pre>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> Sample L-, and TL-moment estimators</li> <li> Sample L- and TL- co-moments (multivariate) estimators</li> <li> Variance structure of sample (T)L moments #4</li> <li> Fitting of distributions with known TL- or L-moments #5</li> <li> Population (T)L-moment estimation from quantile functions #6</li> </ul>"},{"location":"contributing/","title":"Contributing to lmo","text":"<p>Any contributions to lmo are appreciated!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as issues.</p> <p>When reporting a bug, make sure to include the versions of <code>lmo</code>, <code>python</code> and <code>numpy</code> you are using, and provide a reproducable example of the bug.</p>"},{"location":"contributing/#development","title":"Development","text":"<p>Ensure you have poetry installed, then</p> <pre><code>poetry install\n</code></pre>"},{"location":"reference/","title":"Lmo reference","text":""},{"location":"reference/#univariate","title":"Univariate","text":""},{"location":"reference/#l","title":"L","text":""},{"location":"reference/#lmo.l_moment","title":"<code>lmo.l_moment(a, r, /, axis=None, **kwargs)</code>","text":"<p>The \\(r\\)-th sample L-moment, \\(\\lambda_r\\). Alias of <code>lmo.tl_moment(..., trim=0)</code>.</p> <p>According to Wikipedia:</p> <p>L-moments are far more meaningful when dealing with outliers in data than conventional moments.</p> <p>Note that L-moments are robust to outliers, but not resistant to extreme values.</p> <p>Often the Method of L-moment (LMM) outperforms the conventional method of moments (MM) and maximum likelihood estimation (MLE), e.g. ftting of the <code>scipy.stats.genextreme</code> (generalized extreme value, GED) distribution.</p> See Also <ul> <li>J.R.M. Hosking (1990)</li> <li>L-moment - Wikipedia</li> </ul>"},{"location":"reference/#lmo.l_ratio","title":"<code>lmo.l_ratio(a, r, /, k=2, axis=None, **kwargs)</code>","text":"<p>Ratio of the r-th and k-th (2nd by default) sample L-moments:</p> \\[ \\tau_{r, k} = \\frac{\\lambda_{r}}{\\lambda_{k}} \\] <p>Alias of <code>lmo.tl_ratio(..., trim=0)</code>.</p> Notes <p>Tthe L-moment ratio's are bounded within the interval \\([-1, 1)\\).</p>"},{"location":"reference/#lmo.l_loc","title":"<code>lmo.l_loc(a, /, axis=None, **kwargs)</code>","text":"<p>L-location: the first sample L-moment. Equivalent to <code>lmo.tl_loc(a, 0, **kwargs)</code>.</p> Notes <p>The L-location is equivalent to the (arithmetic) sample mean.</p>"},{"location":"reference/#lmo.l_scale","title":"<code>lmo.l_scale(a, /, axis=None, **kwargs)</code>","text":"<p>L-scale: the second L-moment. Equivalent to <code>lmo.tl_scale(a, 0, **kwargs)</code>.</p> Notes <p>The L-scale is equivalent to half the mean absolute difference.</p>"},{"location":"reference/#lmo.l_skew","title":"<code>lmo.l_skew(a, /, axis=None, **kwargs)</code>","text":"<p>L-skewness coefficient; the 3rd sample L-moment ratio. Equivalent to <code>lmo.tl_skew(a, 0, **kwargs)</code>.</p>"},{"location":"reference/#lmo.l_kurt","title":"<code>lmo.l_kurt(a, /, axis=None, **kwargs)</code>","text":"<p>L-kurtosis coefficient; the 4th sample L-moment ratio. Equivalent to <code>lmo.tl_kurt(a, 0, **kwargs)</code>.</p> Notes <p>The L-kurtosis \\(\\tau_4\\) lies within the interval \\([-\\frac{1}{4}, 1)\\), and by the L-skewness \\(\\tau_3\\) as \\(5 \\tau_3^2 - 1 \\le 4 \\tau_4\\).</p>"},{"location":"reference/#tl","title":"TL","text":""},{"location":"reference/#lmo.tl_moment","title":"<code>lmo.tl_moment(a, r, /, trim=1, axis=None, *, weights=None, sort=None)</code>","text":"<p>Estimate the \\(r\\)-th sample TL-moment, \\(\\lambda_{r}^{(t_1, t_2)}\\), for left and right trim lengths \\(t_1\\) and \\(t_2\\).</p> PARAMETER DESCRIPTION <code>a</code> <p>Array containing numbers whose TL-moment is desired. If <code>a</code> is not an array, a conversion is attempted.</p> <p> TYPE: <code>array_like</code> </p> <code>r</code> <p>The order of the TL-moment. Some special cases cases include</p> <ul> <li><code>0</code>: Like the zeroth moment, the zeroth TL-moment  is always <code>1</code>.</li> <li><code>1</code>: The TL-location, the analogue of the mean. See     <code>tl_loc</code>.</li> <li><code>2</code>: The TL-scale, analogous to the standard deviation. See     <code>tl_scale</code>.</li> </ul> <p> TYPE: <code>int</code> </p> <code>trim</code> <p>Amount of samples to trim as either</p> <ul> <li><code>t: int</code> for symmetric trimming, equivalent to <code>(t, t)</code>.</li> <li><code>(t1: int, t2: int)</code> for asymmetric trimming, or</li> </ul> <p>If <code>0</code> is passed, the L-moment is returned.</p> <p> TYPE: <code>int | tuple[int, int]</code> DEFAULT: <code>1</code> </p> <code>axis</code> <p>Axis along wich to calculate the TL-moments. If <code>None</code> (default), all samples in the array will be used.</p> <p> TYPE: <code>int?</code> DEFAULT: <code>None</code> </p> <code>weights</code> <p>An array of weights associated with the values in <code>a</code>. Each value in <code>a</code> contributes to the average according to its associated weight. The weights array can either be 1-D (in which case its length must be the size of a along the given axis) or of the same shape as <code>a</code>. If <code>weights=None</code>, then all data in <code>a</code> are assumed to have a weight equal to one.</p> <p>All <code>weights</code> must be <code>&gt;=0</code>, and the sum must be nonzero.</p> <p>The algorithm is similar to that of the weighted median. See <code>lmo.weights.reweight</code> for details.</p> <p> TYPE: <code>array_like</code> DEFAULT: <code>None</code> </p> PARAMETER DESCRIPTION <code>sort</code> <p>Sorting algorithm, see <code>numpy.sort</code>.</p> <p> TYPE: <code>quick | heap | stable | merge</code> </p> RETURNS DESCRIPTION <code>ScalarOrArray[np.float_]</code> <p>Scalar or array; the \\(r\\)-th TL-moment(s).</p> See Also <p>*     E. Elmamir &amp; A. Seheult (2003) - Trimmed L-moments *     J.R.M. Hosking (2007) - Some theory and practical uses of trimmed     L-moments</p>"},{"location":"reference/#lmo.tl_ratio","title":"<code>lmo.tl_ratio(a, r, /, k=2, trim=1, axis=None, **kwargs)</code>","text":"<p>Ratio of the r-th and k-th (2nd by default) sample TL-moments:</p> \\[ \\tau_{r, k}^{(t_1, t_2)} = \\frac{     \\lambda_{r}^{(t_1, t_2)} }{     \\lambda_{k}^{(t_1, t_2)} } \\] <p>By default, \\(k = 2\\) and \\(t_1 = t_2 = 1\\) are used, i.e. \\(\\tau_{r, 2}^{(1, 1)}\\), or \\(\\tau_r^{(1)}\\) for short.</p>"},{"location":"reference/#lmo.tl_loc","title":"<code>lmo.tl_loc(a, /, trim=1, axis=None, **kwargs)</code>","text":"<p>Sample estimator of the TL-location, \\(\\lambda_1^{(t_1, t_2)}\\); the first TL-moment.</p> See Also <p>lmo.tl_moment</p>"},{"location":"reference/#lmo.tl_scale","title":"<code>lmo.tl_scale(a, /, trim=1, axis=None, **kwargs)</code>","text":"<p>Sample TL-scale estimator, \\(\\lambda_2^{(t_1, t_2)}\\), the second TL-moment. A robust alternative of the sample standard deviation.</p>"},{"location":"reference/#lmo.tl_skew","title":"<code>lmo.tl_skew(a, /, trim=1, axis=None, **kwargs)</code>","text":"<p>TL-skewness coefficient, \\(\\tau_3^{(t_1, t_2)}\\); the 3rd sample TL-moment ratio.</p>"},{"location":"reference/#lmo.tl_kurt","title":"<code>lmo.tl_kurt(a, /, trim=1, axis=None, **kwargs)</code>","text":"<p>TL-kurtosis coefficient, \\(\\tau_4^{(t_1, t_2)}\\); the 4th sample TL-moment ratio.</p>"},{"location":"reference/#multivariate","title":"Multivariate","text":""},{"location":"reference/#l_1","title":"L","text":""},{"location":"reference/#tl_1","title":"TL","text":""},{"location":"reference/#low-level","title":"Low-level","text":""},{"location":"reference/#weights","title":"Weights","text":""},{"location":"reference/#lmo.weights.tl_weights","title":"<code>lmo.weights.tl_weights(n, r, /, trim=1, *, dtype=np.float_)</code>","text":"<p>Linear sample weights for calculation of the r-th TL-moment.</p> PARAMETER DESCRIPTION <code>n</code> <p>Sample size.</p> <p> TYPE: <code>int</code> </p> <code>r</code> <p>L-moment order, e.g. 1 for location, and 2 for scale.</p> <p> TYPE: <code>int</code> </p> <code>trim</code> <p>Amount of samples to trim as either</p> <ul> <li><code>(t1: int, t2: int)</code> for left and right trimming,</li> <li><code>t: int</code>, or <code>(t: int)</code> as alias for <code>(t, t)</code>, or</li> <li><code>()</code> as alias for <code>(0, 0)</code>.</li> </ul> <p>If not provided, <code>1</code> will be used by default.</p> <p> TYPE: <code>Trimming</code> DEFAULT: <code>1</code> </p> PARAMETER DESCRIPTION <code>dtype</code> <p>Desired output floating type for the weights, e.g, <code>numpy.float128</code>. Default is <code>numpy.float64</code>. Must be a (strict) subclass of <code>numpy.floating</code>.</p> <p> TYPE: <code>type[np.floating[_T]] | np.dtype[np.floating[_T]]</code> </p> RETURNS DESCRIPTION <code>w_r</code> <p>A vector of size <code>n</code>, with linear weights for each of the (ordered) samples.</p> <p> TYPE: <code>npt.NDArray[np.floating[_T]]</code> </p> Source code in <code>lmo/weights.py</code> <pre><code>def tl_weights(\n    n: int,\n    r: int,\n    /,\n    trim: Trimming = 1,\n    *,\n    dtype: type[np.floating[_T]] | np.dtype[np.floating[_T]] = np.float_,\n) -&gt; npt.NDArray[np.floating[_T]]:\n\"\"\"\n    Linear sample weights for calculation of the r-th TL-moment.\n\n    Parameters:\n        n: Sample size.\n        r: L-moment order, e.g. 1 for location, and 2 for scale.\n        trim:\n            Amount of samples to trim as either\n\n            - `(t1: int, t2: int)` for left and right trimming,\n            - `t: int`, or `(t: int)` as alias for `(t, t)`, or\n            - `()` as alias for `(0, 0)`.\n\n            If not provided, `1` will be used by default.\n\n    Other parameters:\n        dtype:\n            Desired output floating type for the weights, e.g,\n            `numpy.float128`. Default is `numpy.float64`.\n            Must be a (strict) subclass of `numpy.floating`.\n\n    Returns:\n        w_r:\n            A vector of size `n`, with linear weights for each of the\n            (ordered) samples.\n\n    \"\"\"\n\n    if not issubclass(  # pyright: ignore [reportUnnecessaryIsInstance]\n        np.dtype(dtype).type,\n        np.floating\n    ):\n        raise TypeError(\n            f'dtype must be a subclass of numpy.floating, got {dtype!r}'\n        )\n\n    if r &lt;= 0:\n        raise ValueError(f'expected r &gt; 0, got {r} &lt;= 0')\n\n    tl, tr = expand_trimming(trim)\n\n    if n &lt; r + tl + tr:\n        raise ValueError(f'expected n &gt;= r + s + t, got {n} &lt; {r + tl + tr}')\n\n    # pre-calculate the terms that are independent on j\n    m = r * comb(n, r + tl + tr)\n\n    # https://github.com/numpy/numpy/issues/23783\n    # w_k = np.empty(r, dtype=dtype)\n    w_k = np.empty(r)\n\n    for k in range(r):\n        w_k[k] = (-1) ** k * comb(r - 1, k) / m\n\n    # sample weights\n    w_r = np.zeros(n, dtype=dtype)\n    for j in range(tl, n - tr):\n        # divide inside the loop, to avoid overflows\n        w_r[j] = fsum(\n            comb(j, r + tl - k - 1) * comb(n - j - 1, tr + k) * w_k[k]\n            for k in range(r)\n        )\n\n    return w_r\n</code></pre>"},{"location":"reference/#lmo.weights.l_weights","title":"<code>lmo.weights.l_weights(n, r, /, *, dtype=np.float_)</code>","text":"<p>Alias for <code>tl_weights(n, r, 0)</code>.</p> Source code in <code>lmo/weights.py</code> <pre><code>def l_weights(\n    n: int,\n    r: int,\n    /,\n    *,\n    dtype: type[np.floating[_T]] = np.float_,\n) -&gt; npt.NDArray[np.floating[_T]]:\n\"\"\"\n    Alias for [`tl_weights(n, r, 0)`][lmo.weights.tl_weights].\n    \"\"\"\n    return tl_weights(n, r, 0, dtype=dtype)\n</code></pre>"},{"location":"reference/#lmo.weights.reweight","title":"<code>lmo.weights.reweight(w_r, w_x)</code>","text":"<p>Redistributes the TL-weights relative to the sample weights.</p> <p>Relatively large sample weights \"absorb\" TL-weights of the neighbours, whereas small weights result in a fraction of the local TL-weights.</p> <p>The TL-weights can be thought of as vertical bars, with heights proportional to the weights. Similarly, the sample weights are the horizontal component, effectively squeezing or stretching the width of each sample. The reweighted TL-weights are the resulting areas per sample.</p> <p>To my (Joren Hammudoglu, @jorenham) knowledge, this algorithm for weighted (T)L-moments is the first of its kind.</p> <p>Both time- and space- complexity are <code>O(n)</code>.</p> PARAMETER DESCRIPTION <code>w_r</code> <p>1-D array of TL-weights, see <code>tl_weights</code>.</p> <p> TYPE: <code>npt.NDArray[np.floating[_T]]</code> </p> <code>w_x</code> <p>1-D array of observation (reliability) weights, relative to the sorted observations vector <code>x</code>. All weights must be finite and positive. Larger weights indicate a more important sample. If all weights are equal, the reweighted TL-weights will be equal to the original TL-weights.</p> <p> TYPE: <code>npt.NDArray[np.bool_ | np.integer[Any] | np.floating[Any]]</code> </p> RETURNS DESCRIPTION <code>v_r</code> <p>1-D array of reweighted TL-weights.</p> <p> TYPE: <code>npt.NDArray[np.floating[_T]]</code> </p> Source code in <code>lmo/weights.py</code> <pre><code>def reweight(\n    w_r: npt.NDArray[np.floating[_T]],\n    w_x: npt.NDArray[np.bool_ | np.integer[Any] | np.floating[Any]],\n) -&gt; npt.NDArray[np.floating[_T]]:\n\"\"\"\n    Redistributes the TL-weights relative to the sample weights.\n\n    Relatively large sample weights \"absorb\" TL-weights of the neighbours,\n    whereas small weights result in a fraction of the local TL-weights.\n\n    The TL-weights can be thought of as vertical bars, with heights\n    proportional to the weights. Similarly, the sample weights are the\n    horizontal component, effectively squeezing or stretching the width of each\n    sample. The reweighted TL-weights are the resulting areas per sample.\n\n    To my (Joren Hammudoglu, @jorenham) knowledge, this algorithm for weighted\n    (T)L-moments is the first of its kind.\n\n    Both time- and space- complexity are `O(n)`.\n\n    Args:\n        w_r:\n            1-D array of TL-weights, see [`tl_weights`][lmo.weights.tl_weights].\n        w_x:\n            1-D array of observation (reliability) weights, relative to\n            the *sorted* observations vector `x`. All weights must be finite\n            and positive. Larger weights indicate a more important sample.\n            If all weights are equal, the reweighted TL-weights will be equal\n            to the original TL-weights.\n\n    Returns:\n        v_r: 1-D array of reweighted TL-weights.\n\n    \"\"\"\n    if w_r.ndim != 1:\n        raise TypeError('weights must be 1-D')\n    if w_r.shape != w_x.shape:\n        raise TypeError('shape mismatch')\n\n    n = len(w_r)\n    v_r = np.zeros_like(w_r)\n\n    # integrate, and rescale so that `s.max() == s[-1] == n`\n    s = np.cumsum(w_x, dtype=np.float_)\n    s *= n / s[-1]\n\n    n_j, s_j = 0, 0.0\n    for k in range(n):\n        s_k = s[k]\n\n        if s_k &lt; s_j:\n            raise ValueError('negative weights are not allowed')\n        if s_k == s_j:\n            if s_k == s[-1]:\n                break\n            continue\n\n        n_k = int(s_k)\n\n        ds = s_k - s_j\n        dn = n_k - n_j\n\n        assert ds &gt; 0\n        assert 0 &lt;= dn &lt;= ds + 1\n\n        if dn:\n            ds_j = n_j + 1 - s_j\n            ds_k = s_k - n_k\n\n            assert 0 &lt;= ds_j &lt;= 1\n            assert 0 &lt;= ds_k &lt; 1\n            assert (ds - ds_j - ds_k) % 1 == 0\n\n            # left partial indices\n            v_r[k] = ds_j * w_r[n_j]\n\n            # \"inner\" integer indices\n            if dn &gt; 1:\n                assert ds &gt; 1, (ds, dn)\n                v_r[k] += np.sum(  # pyright: ignore [reportUnknownMemberType]\n                    w_r[n_j + 1: n_k]\n                )\n\n            # right partial index\n            if n_k &lt; n:\n                v_r[k] += ds_k * w_r[n_k]\n        else:\n            assert ds &lt; 1\n            assert n_j == n_k\n\n            v_r[k] = ds * w_r[n_k]\n\n        n_j, s_j = n_k, s_k\n\n    return v_r\n</code></pre>"}]}